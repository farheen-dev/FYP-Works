{"cells":[{"cell_type":"markdown","metadata":{"id":"EiWya1nCOWOQ"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7sM_zrHAOibz"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import time\n","import re\n","import pickle\n","import math\n","import glob\n","import matplotlib.pyplot as plt\n","import os\n","import time"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XrseY6krx7FA"},"outputs":[],"source":["from tensorflow.keras import layers\n","from IPython import display\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"GA4bp8QaOwnk"},"source":["# Loading Data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p9AzEkLGO0Nr","outputId":"44e404d2-4cfe-4a62-d4c5-f4ea0fb02471"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\anaconda3\\envs\\summarization_v2\\lib\\site-packages\\gdown\\cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1v9CBx_z-TwrCByZVhjzb7nxPTgEfRjIY\n","To: D:\\FypResearch\\Text Summarizer\\GANs\\version 1\\wikiHowCleanedData.csv\n","\n","  0%|          | 0.00/398M [00:00<?, ?B/s]\n","  0%|          | 524k/398M [00:00<07:04, 936kB/s]\n","  0%|          | 1.05M/398M [00:01<07:12, 919kB/s]\n","  0%|          | 1.57M/398M [00:01<06:09, 1.07MB/s]\n","  1%|          | 2.10M/398M [00:01<05:50, 1.13MB/s]\n","  1%|          | 2.62M/398M [00:02<04:44, 1.39MB/s]\n","  1%|          | 3.15M/398M [00:02<04:18, 1.53MB/s]\n","  1%|          | 3.67M/398M [00:02<05:07, 1.28MB/s]\n","  1%|1         | 4.19M/398M [00:03<05:05, 1.29MB/s]\n","  1%|1         | 4.72M/398M [00:03<04:19, 1.51MB/s]\n","  1%|1         | 5.24M/398M [00:03<03:56, 1.66MB/s]\n","  1%|1         | 5.77M/398M [00:04<03:42, 1.76MB/s]\n","  2%|1         | 6.29M/398M [00:04<03:26, 1.90MB/s]\n","  2%|1         | 6.82M/398M [00:04<03:48, 1.71MB/s]\n","  2%|1         | 7.34M/398M [00:05<03:51, 1.69MB/s]\n","  2%|1         | 7.86M/398M [00:05<04:25, 1.47MB/s]\n","  2%|2         | 8.39M/398M [00:06<05:16, 1.23MB/s]\n","  2%|2         | 8.91M/398M [00:06<05:34, 1.16MB/s]\n","  2%|2         | 9.44M/398M [00:06<05:03, 1.28MB/s]\n","  3%|2         | 9.96M/398M [00:07<04:35, 1.41MB/s]\n","  3%|2         | 10.5M/398M [00:07<04:00, 1.61MB/s]\n","  3%|2         | 11.0M/398M [00:07<03:35, 1.80MB/s]\n","  3%|2         | 11.5M/398M [00:07<03:43, 1.73MB/s]\n","  3%|3         | 12.1M/398M [00:08<03:35, 1.79MB/s]\n","  3%|3         | 12.6M/398M [00:08<03:17, 1.95MB/s]\n","  3%|3         | 13.1M/398M [00:08<03:22, 1.90MB/s]\n","  3%|3         | 13.6M/398M [00:09<03:35, 1.78MB/s]\n","  4%|3         | 14.2M/398M [00:09<02:57, 2.16MB/s]\n","  4%|3         | 14.7M/398M [00:09<03:02, 2.10MB/s]\n","  4%|3         | 15.2M/398M [00:09<03:14, 1.97MB/s]\n","  4%|3         | 15.7M/398M [00:10<03:29, 1.83MB/s]\n","  4%|4         | 16.3M/398M [00:10<03:42, 1.72MB/s]\n","  4%|4         | 16.8M/398M [00:10<03:54, 1.63MB/s]\n","  4%|4         | 17.3M/398M [00:10<03:24, 1.86MB/s]\n","  4%|4         | 17.8M/398M [00:11<03:28, 1.82MB/s]\n","  5%|4         | 18.4M/398M [00:11<02:56, 2.15MB/s]\n","  5%|4         | 18.9M/398M [00:11<02:45, 2.29MB/s]\n","  5%|4         | 19.4M/398M [00:12<03:22, 1.87MB/s]\n","  5%|5         | 19.9M/398M [00:12<04:16, 1.47MB/s]\n","  5%|5         | 20.4M/398M [00:12<04:03, 1.55MB/s]\n","  5%|5         | 21.0M/398M [00:13<04:20, 1.45MB/s]\n","  5%|5         | 21.5M/398M [00:13<04:25, 1.42MB/s]\n","  6%|5         | 22.0M/398M [00:14<04:21, 1.44MB/s]\n","  6%|5         | 22.5M/398M [00:14<04:09, 1.50MB/s]\n","  6%|5         | 23.1M/398M [00:14<03:50, 1.63MB/s]\n","  6%|5         | 23.6M/398M [00:14<03:14, 1.92MB/s]\n","  6%|6         | 24.1M/398M [00:15<03:18, 1.88MB/s]\n","  6%|6         | 24.6M/398M [00:15<04:05, 1.52MB/s]\n","  6%|6         | 25.2M/398M [00:15<03:51, 1.61MB/s]\n","  6%|6         | 25.7M/398M [00:16<04:12, 1.48MB/s]\n","  7%|6         | 26.2M/398M [00:16<03:59, 1.55MB/s]\n","  7%|6         | 26.7M/398M [00:16<04:21, 1.42MB/s]\n","  7%|6         | 27.3M/398M [00:17<04:45, 1.30MB/s]\n","  7%|6         | 27.8M/398M [00:17<04:25, 1.39MB/s]\n","  7%|7         | 28.3M/398M [00:18<04:52, 1.26MB/s]\n","  7%|7         | 28.8M/398M [00:18<03:49, 1.61MB/s]\n","  7%|7         | 29.4M/398M [00:18<03:44, 1.64MB/s]\n","  8%|7         | 29.9M/398M [00:18<03:05, 1.99MB/s]\n","  8%|7         | 30.4M/398M [00:19<03:29, 1.75MB/s]\n","  8%|7         | 31.5M/398M [00:19<02:26, 2.49MB/s]\n","  8%|8         | 32.0M/398M [00:19<02:32, 2.40MB/s]\n","  8%|8         | 32.5M/398M [00:19<02:42, 2.25MB/s]\n","  8%|8         | 33.0M/398M [00:20<02:52, 2.11MB/s]\n","  8%|8         | 33.6M/398M [00:20<02:27, 2.47MB/s]\n","  9%|8         | 34.1M/398M [00:20<02:17, 2.65MB/s]\n","  9%|8         | 34.6M/398M [00:20<02:46, 2.19MB/s]\n","  9%|8         | 35.1M/398M [00:20<02:17, 2.63MB/s]\n","  9%|8         | 35.7M/398M [00:21<02:27, 2.45MB/s]\n","  9%|9         | 36.2M/398M [00:21<02:24, 2.51MB/s]\n","  9%|9         | 36.7M/398M [00:21<03:31, 1.71MB/s]\n","  9%|9         | 37.2M/398M [00:22<05:08, 1.17MB/s]\n","  9%|9         | 37.7M/398M [00:22<04:13, 1.42MB/s]\n"," 10%|9         | 38.3M/398M [00:23<04:41, 1.28MB/s]\n"," 10%|9         | 38.8M/398M [00:23<03:46, 1.59MB/s]\n"," 10%|9         | 39.3M/398M [00:23<03:34, 1.67MB/s]\n"," 10%|#         | 39.8M/398M [00:24<03:38, 1.64MB/s]\n"," 10%|#         | 40.4M/398M [00:24<04:11, 1.42MB/s]\n"," 10%|#         | 40.9M/398M [00:24<03:43, 1.60MB/s]\n"," 10%|#         | 41.4M/398M [00:25<04:17, 1.38MB/s]\n"," 11%|#         | 41.9M/398M [00:25<03:24, 1.74MB/s]\n"," 11%|#         | 42.5M/398M [00:25<03:24, 1.74MB/s]\n"," 11%|#         | 43.0M/398M [00:26<03:55, 1.51MB/s]\n"," 11%|#         | 43.5M/398M [00:26<03:18, 1.79MB/s]\n"," 11%|#1        | 44.0M/398M [00:26<03:01, 1.95MB/s]\n"," 11%|#1        | 44.6M/398M [00:26<03:03, 1.93MB/s]\n"," 11%|#1        | 45.1M/398M [00:27<03:11, 1.84MB/s]\n"," 11%|#1        | 45.6M/398M [00:27<02:45, 2.13MB/s]\n"," 12%|#1        | 46.1M/398M [00:27<03:06, 1.89MB/s]\n"," 12%|#1        | 46.7M/398M [00:27<02:58, 1.96MB/s]\n"," 12%|#1        | 47.2M/398M [00:28<03:05, 1.89MB/s]\n"," 12%|#1        | 47.7M/398M [00:28<03:04, 1.90MB/s]\n"," 12%|#2        | 48.2M/398M [00:28<02:56, 1.98MB/s]\n"," 12%|#2        | 48.8M/398M [00:29<02:43, 2.14MB/s]\n"," 12%|#2        | 49.3M/398M [00:29<02:25, 2.40MB/s]\n"," 13%|#2        | 49.8M/398M [00:29<03:14, 1.79MB/s]\n"," 13%|#2        | 50.9M/398M [00:30<03:13, 1.79MB/s]\n"," 13%|#2        | 51.4M/398M [00:30<03:37, 1.59MB/s]\n"," 13%|#3        | 51.9M/398M [00:30<03:00, 1.92MB/s]\n"," 13%|#3        | 52.4M/398M [00:31<03:11, 1.81MB/s]\n"," 13%|#3        | 53.0M/398M [00:31<03:15, 1.76MB/s]\n"," 13%|#3        | 53.5M/398M [00:31<03:24, 1.68MB/s]\n"," 14%|#3        | 54.0M/398M [00:32<03:42, 1.55MB/s]\n"," 14%|#3        | 54.5M/398M [00:32<03:56, 1.45MB/s]\n"," 14%|#3        | 55.1M/398M [00:32<03:10, 1.80MB/s]\n"," 14%|#3        | 55.6M/398M [00:32<02:51, 1.99MB/s]\n"," 14%|#4        | 56.1M/398M [00:33<03:18, 1.73MB/s]\n"," 14%|#4        | 56.6M/398M [00:33<02:59, 1.90MB/s]\n"," 14%|#4        | 57.1M/398M [00:33<02:43, 2.09MB/s]\n"," 14%|#4        | 57.7M/398M [00:33<02:24, 2.36MB/s]\n"," 15%|#4        | 58.2M/398M [00:34<02:33, 2.21MB/s]\n"," 15%|#4        | 58.7M/398M [00:34<02:44, 2.06MB/s]\n"," 15%|#4        | 59.2M/398M [00:34<02:53, 1.96MB/s]\n"," 15%|#5        | 59.8M/398M [00:35<04:25, 1.27MB/s]\n"," 15%|#5        | 60.8M/398M [00:35<03:21, 1.68MB/s]\n"," 15%|#5        | 61.3M/398M [00:36<03:27, 1.63MB/s]\n"," 16%|#5        | 61.9M/398M [00:36<03:24, 1.64MB/s]\n"," 16%|#5        | 62.4M/398M [00:36<03:15, 1.72MB/s]\n"," 16%|#5        | 62.9M/398M [00:37<03:21, 1.66MB/s]\n"," 16%|#5        | 63.4M/398M [00:37<03:29, 1.60MB/s]\n"," 16%|#6        | 64.0M/398M [00:37<03:17, 1.69MB/s]\n"," 16%|#6        | 64.5M/398M [00:38<03:08, 1.76MB/s]\n"," 16%|#6        | 65.0M/398M [00:38<02:56, 1.88MB/s]\n"," 16%|#6        | 65.5M/398M [00:38<02:45, 2.01MB/s]\n"," 17%|#6        | 66.1M/398M [00:38<02:34, 2.15MB/s]\n"," 17%|#6        | 66.6M/398M [00:39<03:15, 1.69MB/s]\n"," 17%|#6        | 67.1M/398M [00:39<03:25, 1.61MB/s]\n"," 17%|#6        | 67.6M/398M [00:39<03:16, 1.68MB/s]\n"," 17%|#7        | 68.2M/398M [00:39<02:51, 1.93MB/s]\n"," 17%|#7        | 68.7M/398M [00:40<02:44, 2.00MB/s]\n"," 17%|#7        | 69.2M/398M [00:40<02:24, 2.28MB/s]\n"," 18%|#7        | 69.7M/398M [00:41<03:49, 1.43MB/s]\n"," 18%|#7        | 70.3M/398M [00:41<03:11, 1.71MB/s]\n"," 18%|#7        | 70.8M/398M [00:41<03:12, 1.70MB/s]\n"," 18%|#7        | 71.3M/398M [00:41<03:15, 1.67MB/s]\n"," 18%|#8        | 71.8M/398M [00:42<03:10, 1.71MB/s]\n"," 18%|#8        | 72.4M/398M [00:42<02:52, 1.89MB/s]\n"," 18%|#8        | 72.9M/398M [00:42<02:46, 1.95MB/s]\n"," 18%|#8        | 73.4M/398M [00:43<03:16, 1.65MB/s]\n"," 19%|#8        | 73.9M/398M [00:43<02:47, 1.93MB/s]\n"," 19%|#8        | 74.4M/398M [00:43<03:28, 1.55MB/s]\n"," 19%|#8        | 75.5M/398M [00:43<02:23, 2.25MB/s]\n"," 19%|#9        | 76.0M/398M [00:44<02:23, 2.24MB/s]\n"," 19%|#9        | 76.5M/398M [00:44<02:28, 2.17MB/s]\n"," 19%|#9        | 77.1M/398M [00:44<02:54, 1.84MB/s]\n"," 19%|#9        | 77.6M/398M [00:44<02:26, 2.18MB/s]\n"," 20%|#9        | 78.1M/398M [00:45<02:26, 2.18MB/s]\n"," 20%|#9        | 78.6M/398M [00:45<02:30, 2.12MB/s]\n"," 20%|#9        | 79.2M/398M [00:45<03:22, 1.57MB/s]\n"," 20%|##        | 79.7M/398M [00:46<04:23, 1.21MB/s]\n"," 20%|##        | 80.2M/398M [00:46<03:23, 1.56MB/s]\n"," 20%|##        | 80.7M/398M [00:47<03:41, 1.43MB/s]\n"," 20%|##        | 81.3M/398M [00:47<03:03, 1.73MB/s]\n"," 21%|##        | 81.8M/398M [00:47<03:10, 1.66MB/s]\n"," 21%|##        | 82.3M/398M [00:48<03:54, 1.35MB/s]\n"," 21%|##        | 82.8M/398M [00:48<03:03, 1.72MB/s]\n"," 21%|##        | 83.4M/398M [00:48<02:36, 2.01MB/s]\n"," 21%|##1       | 83.9M/398M [00:48<02:45, 1.90MB/s]\n"," 21%|##1       | 84.4M/398M [00:49<03:17, 1.59MB/s]\n"," 21%|##1       | 85.5M/398M [00:49<02:25, 2.15MB/s]\n"," 22%|##1       | 86.0M/398M [00:50<03:01, 1.72MB/s]\n"," 22%|##1       | 87.0M/398M [00:50<02:52, 1.80MB/s]\n"," 22%|##2       | 87.6M/398M [00:50<02:44, 1.89MB/s]\n"," 22%|##2       | 88.1M/398M [00:51<02:39, 1.94MB/s]\n"," 22%|##2       | 88.6M/398M [00:51<02:22, 2.17MB/s]\n"," 22%|##2       | 89.1M/398M [00:51<02:33, 2.01MB/s]\n"," 23%|##2       | 89.7M/398M [00:51<02:35, 1.99MB/s]\n"," 23%|##2       | 90.2M/398M [00:52<02:22, 2.15MB/s]\n"," 23%|##2       | 90.7M/398M [00:52<02:08, 2.40MB/s]\n"," 23%|##2       | 91.2M/398M [00:52<02:50, 1.80MB/s]\n"," 23%|##3       | 92.3M/398M [00:52<02:00, 2.54MB/s]\n"," 23%|##3       | 92.8M/398M [00:52<01:48, 2.82MB/s]\n"," 23%|##3       | 93.3M/398M [00:53<02:29, 2.03MB/s]\n"," 24%|##3       | 94.4M/398M [00:54<03:11, 1.59MB/s]\n"," 24%|##3       | 95.4M/398M [00:54<02:21, 2.14MB/s]\n"," 24%|##4       | 95.9M/398M [00:55<02:54, 1.73MB/s]\n"," 24%|##4       | 97.0M/398M [00:55<02:52, 1.74MB/s]\n"," 25%|##4       | 97.5M/398M [00:55<02:29, 2.01MB/s]\n"," 25%|##4       | 98.0M/398M [00:55<02:20, 2.13MB/s]\n"," 25%|##4       | 98.6M/398M [00:56<02:48, 1.78MB/s]\n"," 25%|##4       | 99.1M/398M [00:56<02:32, 1.97MB/s]\n"," 25%|##5       | 99.6M/398M [00:56<02:24, 2.06MB/s]\n"," 25%|##5       | 100M/398M [00:57<02:17, 2.16MB/s] \n"," 25%|##5       | 101M/398M [00:57<03:15, 1.52MB/s]\n"]},{"name":"stderr","output_type":"stream","text":[" 25%|##5       | 101M/398M [00:57<02:35, 1.91MB/s]\n"," 26%|##5       | 102M/398M [00:57<02:36, 1.89MB/s]\n"," 26%|##5       | 102M/398M [00:58<03:01, 1.63MB/s]\n"," 26%|##5       | 103M/398M [00:58<03:29, 1.41MB/s]\n"," 26%|##5       | 103M/398M [00:59<02:43, 1.80MB/s]\n"," 26%|##6       | 104M/398M [00:59<02:36, 1.88MB/s]\n"," 26%|##6       | 104M/398M [00:59<02:50, 1.73MB/s]\n"," 26%|##6       | 105M/398M [00:59<02:17, 2.13MB/s]\n"," 26%|##6       | 105M/398M [00:59<02:09, 2.25MB/s]\n"," 27%|##6       | 106M/398M [01:00<02:16, 2.14MB/s]\n"," 27%|##6       | 106M/398M [01:00<02:16, 2.14MB/s]\n"," 27%|##6       | 107M/398M [01:00<01:56, 2.50MB/s]\n"," 27%|##7       | 107M/398M [01:01<02:30, 1.93MB/s]\n"," 27%|##7       | 109M/398M [01:01<02:09, 2.23MB/s]\n"," 27%|##7       | 109M/398M [01:01<02:04, 2.31MB/s]\n"," 28%|##7       | 110M/398M [01:01<02:01, 2.38MB/s]\n"," 28%|##7       | 110M/398M [01:02<02:18, 2.09MB/s]\n"," 28%|##7       | 111M/398M [01:02<01:47, 2.67MB/s]\n"," 28%|##8       | 112M/398M [01:03<02:44, 1.74MB/s]\n"," 28%|##8       | 112M/398M [01:03<02:55, 1.63MB/s]\n"," 28%|##8       | 113M/398M [01:03<02:49, 1.69MB/s]\n"," 28%|##8       | 113M/398M [01:03<02:43, 1.74MB/s]\n"," 29%|##8       | 114M/398M [01:04<02:32, 1.86MB/s]\n"," 29%|##8       | 114M/398M [01:04<02:34, 1.83MB/s]\n"," 29%|##8       | 115M/398M [01:04<02:18, 2.05MB/s]\n"," 29%|##8       | 115M/398M [01:04<01:58, 2.38MB/s]\n"," 29%|##9       | 116M/398M [01:05<02:40, 1.76MB/s]\n"," 29%|##9       | 117M/398M [01:05<01:52, 2.50MB/s]\n"," 30%|##9       | 117M/398M [01:06<02:59, 1.56MB/s]\n"," 30%|##9       | 118M/398M [01:06<02:45, 1.69MB/s]\n"," 30%|##9       | 118M/398M [01:06<02:32, 1.84MB/s]\n"," 30%|##9       | 119M/398M [01:07<03:19, 1.40MB/s]\n"," 30%|###       | 120M/398M [01:07<02:49, 1.64MB/s]\n"," 30%|###       | 120M/398M [01:07<02:33, 1.81MB/s]\n"," 30%|###       | 121M/398M [01:08<04:10, 1.11MB/s]\n"," 31%|###       | 122M/398M [01:10<05:19, 866kB/s] \n"," 31%|###       | 123M/398M [01:10<03:51, 1.19MB/s]\n"," 31%|###       | 123M/398M [01:10<03:52, 1.18MB/s]\n"," 31%|###1      | 124M/398M [01:11<03:28, 1.31MB/s]\n"," 31%|###1      | 124M/398M [01:11<02:59, 1.52MB/s]\n"," 31%|###1      | 125M/398M [01:11<03:04, 1.48MB/s]\n"," 31%|###1      | 125M/398M [01:11<02:29, 1.83MB/s]\n"," 32%|###1      | 126M/398M [01:12<02:21, 1.92MB/s]\n"," 32%|###1      | 126M/398M [01:12<02:37, 1.72MB/s]\n"," 32%|###1      | 127M/398M [01:12<02:41, 1.67MB/s]\n"," 32%|###2      | 128M/398M [01:13<02:30, 1.80MB/s]\n"," 32%|###2      | 129M/398M [01:13<01:48, 2.48MB/s]\n"," 33%|###2      | 129M/398M [01:13<01:40, 2.68MB/s]\n"," 33%|###2      | 130M/398M [01:14<02:16, 1.97MB/s]\n"," 33%|###2      | 131M/398M [01:14<02:38, 1.69MB/s]\n"," 33%|###3      | 132M/398M [01:15<02:22, 1.86MB/s]\n"," 33%|###3      | 132M/398M [01:15<02:27, 1.81MB/s]\n"," 33%|###3      | 133M/398M [01:15<02:23, 1.85MB/s]\n"," 33%|###3      | 133M/398M [01:15<02:28, 1.78MB/s]\n"," 34%|###3      | 134M/398M [01:16<02:29, 1.77MB/s]\n"," 34%|###3      | 134M/398M [01:16<02:18, 1.91MB/s]\n"," 34%|###3      | 135M/398M [01:16<02:42, 1.62MB/s]\n"," 34%|###3      | 135M/398M [01:18<06:16, 698kB/s] \n"," 34%|###4      | 136M/398M [01:18<03:49, 1.14MB/s]\n"," 34%|###4      | 137M/398M [01:20<05:33, 784kB/s] \n"," 35%|###4      | 138M/398M [01:21<04:47, 904kB/s]\n"," 35%|###4      | 138M/398M [01:21<03:53, 1.11MB/s]\n"," 35%|###4      | 139M/398M [01:21<03:26, 1.26MB/s]\n"," 35%|###5      | 140M/398M [01:21<02:20, 1.84MB/s]\n"," 35%|###5      | 141M/398M [01:22<02:33, 1.68MB/s]\n"," 35%|###5      | 141M/398M [01:22<02:56, 1.46MB/s]\n"," 36%|###5      | 142M/398M [01:22<02:52, 1.48MB/s]\n"," 36%|###5      | 142M/398M [01:23<03:04, 1.39MB/s]\n"," 36%|###5      | 143M/398M [01:23<03:06, 1.37MB/s]\n"," 36%|###5      | 143M/398M [01:24<03:34, 1.19MB/s]\n"," 36%|###6      | 144M/398M [01:24<03:20, 1.27MB/s]\n"," 36%|###6      | 144M/398M [01:25<03:31, 1.20MB/s]\n"," 36%|###6      | 145M/398M [01:25<03:23, 1.25MB/s]\n"," 36%|###6      | 145M/398M [01:25<03:10, 1.33MB/s]\n"," 37%|###6      | 146M/398M [01:26<03:29, 1.20MB/s]\n"," 37%|###6      | 146M/398M [01:26<03:11, 1.32MB/s]\n"," 37%|###6      | 147M/398M [01:27<03:22, 1.24MB/s]\n"," 37%|###7      | 147M/398M [01:27<03:21, 1.24MB/s]\n"," 37%|###7      | 148M/398M [01:28<03:07, 1.34MB/s]\n"," 37%|###7      | 148M/398M [01:28<02:53, 1.44MB/s]\n"," 37%|###7      | 149M/398M [01:28<02:53, 1.43MB/s]\n"," 38%|###7      | 149M/398M [01:29<03:03, 1.35MB/s]\n"," 38%|###7      | 150M/398M [01:29<02:47, 1.48MB/s]\n"," 38%|###7      | 150M/398M [01:29<02:47, 1.48MB/s]\n"," 38%|###7      | 151M/398M [01:30<03:00, 1.37MB/s]\n"," 38%|###8      | 152M/398M [01:30<03:04, 1.33MB/s]\n"," 38%|###8      | 153M/398M [01:31<02:50, 1.44MB/s]\n"," 38%|###8      | 153M/398M [01:31<02:44, 1.49MB/s]\n"," 39%|###8      | 154M/398M [01:32<02:53, 1.41MB/s]\n"," 39%|###8      | 154M/398M [01:32<03:07, 1.30MB/s]\n"," 39%|###8      | 155M/398M [01:32<03:08, 1.29MB/s]\n"," 39%|###8      | 155M/398M [01:33<02:42, 1.49MB/s]\n"," 39%|###9      | 156M/398M [01:33<02:21, 1.71MB/s]\n"," 39%|###9      | 156M/398M [01:33<02:28, 1.63MB/s]\n"," 39%|###9      | 157M/398M [01:34<02:23, 1.69MB/s]\n"," 40%|###9      | 157M/398M [01:34<02:15, 1.78MB/s]\n"," 40%|###9      | 158M/398M [01:34<02:11, 1.82MB/s]\n"," 40%|###9      | 158M/398M [01:35<02:43, 1.47MB/s]\n"," 40%|###9      | 159M/398M [01:35<02:45, 1.44MB/s]\n"," 40%|####      | 159M/398M [01:36<03:18, 1.20MB/s]\n"," 40%|####      | 160M/398M [01:36<02:44, 1.45MB/s]\n"," 40%|####      | 160M/398M [01:36<02:16, 1.74MB/s]\n"," 40%|####      | 161M/398M [01:36<02:39, 1.49MB/s]\n"," 41%|####      | 161M/398M [01:37<02:18, 1.71MB/s]\n"," 41%|####      | 162M/398M [01:37<01:56, 2.03MB/s]\n"," 41%|####      | 163M/398M [01:37<02:55, 1.34MB/s]\n"," 41%|####1     | 164M/398M [01:38<01:56, 2.02MB/s]\n"," 41%|####1     | 164M/398M [01:38<02:32, 1.54MB/s]\n"," 41%|####1     | 165M/398M [01:38<01:38, 2.36MB/s]\n"," 42%|####1     | 166M/398M [01:39<01:40, 2.31MB/s]\n"," 42%|####1     | 166M/398M [01:39<01:57, 1.98MB/s]\n"," 42%|####1     | 167M/398M [01:39<01:38, 2.35MB/s]\n"," 42%|####2     | 167M/398M [01:39<01:27, 2.63MB/s]\n"," 42%|####2     | 168M/398M [01:40<01:49, 2.11MB/s]\n"," 42%|####2     | 168M/398M [01:40<01:44, 2.19MB/s]\n"," 42%|####2     | 169M/398M [01:40<01:31, 2.50MB/s]\n"," 43%|####2     | 169M/398M [01:40<01:33, 2.44MB/s]\n"," 43%|####2     | 170M/398M [01:40<01:48, 2.11MB/s]\n"," 43%|####2     | 170M/398M [01:41<02:24, 1.57MB/s]\n"," 43%|####2     | 171M/398M [01:41<02:20, 1.62MB/s]\n"," 43%|####3     | 172M/398M [01:42<01:46, 2.12MB/s]\n"," 43%|####3     | 172M/398M [01:42<02:27, 1.53MB/s]\n"," 43%|####3     | 173M/398M [01:42<02:10, 1.72MB/s]\n"," 44%|####3     | 174M/398M [01:43<02:43, 1.37MB/s]\n"," 44%|####4     | 175M/398M [01:43<01:46, 2.10MB/s]\n"," 44%|####4     | 176M/398M [01:44<01:55, 1.92MB/s]\n"," 44%|####4     | 176M/398M [01:44<01:46, 2.09MB/s]\n"," 44%|####4     | 177M/398M [01:44<01:34, 2.34MB/s]\n"," 45%|####4     | 177M/398M [01:45<02:26, 1.51MB/s]\n"," 45%|####4     | 178M/398M [01:45<02:05, 1.75MB/s]\n"," 45%|####4     | 178M/398M [01:46<03:43, 982kB/s] \n"," 45%|####5     | 180M/398M [01:46<01:33, 2.33MB/s]\n"," 46%|####5     | 181M/398M [01:47<01:42, 2.10MB/s]\n"," 46%|####5     | 182M/398M [01:47<01:37, 2.23MB/s]\n"," 46%|####5     | 182M/398M [01:47<01:27, 2.46MB/s]\n"," 46%|####5     | 183M/398M [01:48<01:54, 1.88MB/s]\n"," 46%|####6     | 184M/398M [01:48<01:49, 1.95MB/s]\n"," 46%|####6     | 184M/398M [01:48<01:41, 2.10MB/s]\n"," 46%|####6     | 185M/398M [01:48<01:45, 2.01MB/s]\n"," 47%|####6     | 185M/398M [01:49<01:48, 1.96MB/s]\n"," 47%|####6     | 186M/398M [01:49<02:18, 1.54MB/s]\n"," 47%|####6     | 186M/398M [01:49<01:51, 1.90MB/s]\n"," 47%|####6     | 187M/398M [01:50<02:41, 1.31MB/s]\n"," 47%|####7     | 188M/398M [01:50<01:48, 1.94MB/s]\n"," 47%|####7     | 188M/398M [01:51<02:10, 1.61MB/s]\n"," 47%|####7     | 189M/398M [01:51<02:08, 1.63MB/s]\n"," 48%|####7     | 189M/398M [01:51<02:10, 1.60MB/s]\n"," 48%|####7     | 190M/398M [01:52<02:05, 1.66MB/s]\n"," 48%|####7     | 190M/398M [01:52<01:51, 1.87MB/s]\n"," 48%|####7     | 191M/398M [01:52<01:48, 1.90MB/s]\n"," 48%|####8     | 191M/398M [01:53<01:58, 1.74MB/s]\n"," 48%|####8     | 192M/398M [01:53<01:21, 2.51MB/s]\n"," 48%|####8     | 193M/398M [01:53<02:12, 1.54MB/s]\n"," 49%|####8     | 194M/398M [01:54<01:26, 2.36MB/s]\n"," 49%|####8     | 195M/398M [01:54<01:36, 2.11MB/s]\n"," 49%|####9     | 195M/398M [01:55<02:15, 1.50MB/s]\n"," 49%|####9     | 196M/398M [01:55<01:57, 1.72MB/s]\n"," 49%|####9     | 196M/398M [01:55<01:51, 1.81MB/s]\n"," 50%|####9     | 197M/398M [01:56<01:59, 1.67MB/s]\n"," 50%|####9     | 198M/398M [01:56<01:25, 2.33MB/s]\n"," 50%|####9     | 199M/398M [01:56<01:36, 2.06MB/s]\n"," 50%|#####     | 199M/398M [01:56<01:28, 2.25MB/s]\n"," 50%|#####     | 200M/398M [01:57<01:20, 2.47MB/s]\n"," 50%|#####     | 200M/398M [01:57<01:38, 2.00MB/s]\n"," 51%|#####     | 201M/398M [01:57<01:34, 2.08MB/s]\n"," 51%|#####     | 202M/398M [01:58<01:26, 2.27MB/s]\n"," 51%|#####     | 202M/398M [01:58<02:04, 1.57MB/s]\n"," 51%|#####1    | 203M/398M [01:58<01:29, 2.18MB/s]\n"," 51%|#####1    | 204M/398M [01:59<01:49, 1.77MB/s]\n"," 51%|#####1    | 204M/398M [01:59<02:00, 1.61MB/s]\n"," 52%|#####1    | 205M/398M [02:00<02:28, 1.30MB/s]\n"," 52%|#####1    | 206M/398M [02:00<01:49, 1.75MB/s]\n"," 52%|#####1    | 207M/398M [02:01<01:46, 1.79MB/s]\n"," 52%|#####2    | 207M/398M [02:01<02:04, 1.53MB/s]\n"," 52%|#####2    | 208M/398M [02:01<01:53, 1.68MB/s]\n"," 52%|#####2    | 208M/398M [02:02<01:54, 1.66MB/s]\n"," 52%|#####2    | 209M/398M [02:02<01:52, 1.69MB/s]\n"," 53%|#####2    | 209M/398M [02:02<01:42, 1.85MB/s]\n"," 53%|#####2    | 210M/398M [02:02<01:44, 1.80MB/s]\n"," 53%|#####2    | 210M/398M [02:03<01:42, 1.82MB/s]\n"," 53%|#####2    | 211M/398M [02:03<01:34, 1.97MB/s]\n"," 53%|#####3    | 211M/398M [02:03<01:59, 1.56MB/s]\n"," 53%|#####3    | 212M/398M [02:04<01:56, 1.60MB/s]\n"," 53%|#####3    | 212M/398M [02:04<01:37, 1.91MB/s]\n"," 53%|#####3    | 213M/398M [02:04<01:46, 1.74MB/s]\n"," 54%|#####3    | 213M/398M [02:04<01:40, 1.84MB/s]\n"," 54%|#####3    | 214M/398M [02:05<01:32, 1.98MB/s]\n"," 54%|#####3    | 214M/398M [02:05<01:42, 1.79MB/s]\n"," 54%|#####4    | 215M/398M [02:05<01:26, 2.10MB/s]\n"," 54%|#####4    | 215M/398M [02:06<02:01, 1.50MB/s]\n"," 54%|#####4    | 216M/398M [02:06<01:48, 1.68MB/s]\n"," 54%|#####4    | 217M/398M [02:07<02:17, 1.32MB/s]\n"," 55%|#####4    | 217M/398M [02:07<01:57, 1.54MB/s]\n"," 55%|#####4    | 218M/398M [02:07<01:42, 1.75MB/s]\n"," 55%|#####4    | 218M/398M [02:07<01:44, 1.73MB/s]\n"," 55%|#####4    | 219M/398M [02:08<01:43, 1.73MB/s]\n"," 55%|#####5    | 219M/398M [02:08<01:37, 1.83MB/s]\n"," 55%|#####5    | 220M/398M [02:08<01:35, 1.86MB/s]\n"," 55%|#####5    | 220M/398M [02:08<01:28, 2.00MB/s]\n"," 55%|#####5    | 221M/398M [02:09<01:21, 2.19MB/s]\n"," 56%|#####5    | 221M/398M [02:09<01:11, 2.48MB/s]\n"," 56%|#####5    | 222M/398M [02:09<01:26, 2.04MB/s]\n"," 56%|#####5    | 222M/398M [02:09<01:33, 1.89MB/s]\n"," 56%|#####5    | 223M/398M [02:10<01:45, 1.66MB/s]\n"," 56%|#####6    | 223M/398M [02:10<01:26, 2.01MB/s]\n"," 56%|#####6    | 224M/398M [02:10<01:19, 2.18MB/s]\n"," 56%|#####6    | 224M/398M [02:10<01:15, 2.30MB/s]\n"," 57%|#####6    | 225M/398M [02:10<01:08, 2.52MB/s]\n"," 57%|#####6    | 225M/398M [02:11<01:43, 1.67MB/s]\n"," 57%|#####6    | 226M/398M [02:11<01:30, 1.90MB/s]\n"," 57%|#####6    | 226M/398M [02:12<01:57, 1.46MB/s]\n"," 57%|#####7    | 227M/398M [02:12<02:03, 1.38MB/s]\n"," 57%|#####7    | 228M/398M [02:12<01:41, 1.68MB/s]\n"," 57%|#####7    | 228M/398M [02:13<01:31, 1.86MB/s]\n"," 57%|#####7    | 229M/398M [02:13<01:43, 1.64MB/s]\n"," 58%|#####7    | 229M/398M [02:13<01:24, 1.99MB/s]\n"," 58%|#####7    | 230M/398M [02:14<01:38, 1.71MB/s]\n"," 58%|#####7    | 230M/398M [02:14<01:26, 1.94MB/s]\n"," 58%|#####7    | 231M/398M [02:14<01:38, 1.70MB/s]\n"," 58%|#####8    | 231M/398M [02:14<01:23, 1.99MB/s]\n"," 58%|#####8    | 232M/398M [02:15<01:45, 1.58MB/s]\n"," 58%|#####8    | 233M/398M [02:15<01:30, 1.82MB/s]\n"," 59%|#####8    | 233M/398M [02:15<01:24, 1.95MB/s]\n"," 59%|#####8    | 234M/398M [02:16<01:39, 1.65MB/s]\n"," 59%|#####8    | 234M/398M [02:16<01:35, 1.72MB/s]\n"," 59%|#####9    | 235M/398M [02:16<01:38, 1.66MB/s]\n"," 59%|#####9    | 235M/398M [02:17<01:19, 2.05MB/s]\n"," 59%|#####9    | 236M/398M [02:17<01:41, 1.60MB/s]\n"," 59%|#####9    | 236M/398M [02:17<01:26, 1.86MB/s]\n"," 60%|#####9    | 238M/398M [02:18<01:09, 2.32MB/s]\n"," 60%|#####9    | 238M/398M [02:18<01:15, 2.12MB/s]\n"," 60%|######    | 239M/398M [02:18<01:15, 2.09MB/s]\n"," 60%|######    | 240M/398M [02:19<01:20, 1.98MB/s]\n"," 60%|######    | 240M/398M [02:19<01:08, 2.31MB/s]\n"," 60%|######    | 241M/398M [02:19<01:21, 1.93MB/s]\n"," 61%|######    | 241M/398M [02:20<01:51, 1.41MB/s]\n"," 61%|######    | 242M/398M [02:20<01:42, 1.52MB/s]\n"," 61%|######    | 243M/398M [02:21<01:25, 1.82MB/s]\n"," 61%|######1   | 243M/398M [02:21<01:24, 1.82MB/s]\n"," 61%|######1   | 244M/398M [02:21<01:18, 1.96MB/s]\n"," 61%|######1   | 244M/398M [02:22<01:44, 1.47MB/s]\n"," 62%|######1   | 245M/398M [02:22<01:24, 1.80MB/s]\n"," 62%|######1   | 245M/398M [02:22<01:18, 1.93MB/s]\n"," 62%|######1   | 246M/398M [02:22<01:06, 2.28MB/s]\n"," 62%|######1   | 246M/398M [02:23<01:24, 1.80MB/s]\n"," 62%|######2   | 247M/398M [02:23<01:10, 2.14MB/s]\n"," 62%|######2   | 247M/398M [02:23<01:08, 2.20MB/s]\n"," 62%|######2   | 248M/398M [02:23<01:12, 2.06MB/s]\n"," 62%|######2   | 249M/398M [02:24<01:16, 1.95MB/s]\n"," 63%|######2   | 249M/398M [02:24<01:03, 2.34MB/s]\n"," 63%|######2   | 250M/398M [02:24<01:00, 2.46MB/s]\n"," 63%|######2   | 250M/398M [02:24<01:18, 1.89MB/s]\n"," 63%|######3   | 251M/398M [02:25<00:57, 2.56MB/s]\n"," 63%|######3   | 252M/398M [02:25<01:02, 2.36MB/s]\n"," 63%|######3   | 252M/398M [02:25<01:22, 1.76MB/s]\n"," 64%|######3   | 253M/398M [02:25<01:10, 2.06MB/s]\n"," 64%|######3   | 253M/398M [02:26<01:28, 1.64MB/s]\n"," 64%|######3   | 254M/398M [02:26<01:18, 1.83MB/s]\n"," 64%|######3   | 254M/398M [02:26<01:20, 1.79MB/s]\n"," 64%|######4   | 255M/398M [02:27<01:05, 2.19MB/s]\n"," 64%|######4   | 255M/398M [02:27<01:03, 2.23MB/s]\n"," 64%|######4   | 256M/398M [02:27<01:19, 1.78MB/s]\n"," 65%|######4   | 257M/398M [02:27<00:59, 2.38MB/s]\n"," 65%|######4   | 257M/398M [02:28<00:57, 2.43MB/s]\n"," 65%|######4   | 258M/398M [02:28<00:55, 2.54MB/s]\n"," 65%|######4   | 258M/398M [02:28<01:03, 2.20MB/s]\n"," 65%|######5   | 259M/398M [02:28<01:04, 2.14MB/s]\n"," 65%|######5   | 260M/398M [02:29<01:00, 2.28MB/s]\n"," 65%|######5   | 260M/398M [02:29<00:55, 2.50MB/s]\n"," 65%|######5   | 261M/398M [02:29<00:54, 2.52MB/s]\n"," 66%|######5   | 261M/398M [02:29<00:58, 2.33MB/s]\n"," 66%|######5   | 262M/398M [02:30<01:00, 2.26MB/s]\n"," 66%|######5   | 262M/398M [02:30<01:24, 1.61MB/s]\n"," 66%|######6   | 263M/398M [02:30<01:20, 1.68MB/s]\n"," 66%|######6   | 263M/398M [02:31<01:28, 1.52MB/s]\n"," 66%|######6   | 264M/398M [02:31<01:28, 1.51MB/s]\n"," 66%|######6   | 264M/398M [02:31<01:28, 1.51MB/s]\n"," 67%|######6   | 265M/398M [02:32<01:31, 1.46MB/s]\n"," 67%|######6   | 265M/398M [02:32<01:21, 1.63MB/s]\n"," 67%|######6   | 266M/398M [02:32<01:12, 1.83MB/s]\n"," 67%|######6   | 266M/398M [02:33<01:24, 1.55MB/s]\n"," 67%|######7   | 267M/398M [02:33<01:12, 1.80MB/s]\n"," 67%|######7   | 267M/398M [02:33<01:05, 1.98MB/s]\n"," 67%|######7   | 268M/398M [02:33<00:56, 2.29MB/s]\n"," 67%|######7   | 268M/398M [02:34<01:05, 1.97MB/s]\n"," 68%|######7   | 269M/398M [02:34<00:52, 2.46MB/s]\n"," 68%|######7   | 270M/398M [02:34<00:48, 2.64MB/s]\n"," 68%|######7   | 271M/398M [02:34<00:59, 2.14MB/s]\n"," 68%|######8   | 271M/398M [02:35<00:51, 2.48MB/s]\n"," 68%|######8   | 272M/398M [02:35<00:58, 2.17MB/s]\n"," 68%|######8   | 272M/398M [02:35<00:52, 2.40MB/s]\n"," 69%|######8   | 273M/398M [02:36<01:13, 1.71MB/s]\n"," 69%|######8   | 273M/398M [02:36<01:12, 1.72MB/s]\n"," 69%|######8   | 274M/398M [02:36<01:27, 1.42MB/s]\n"," 69%|######8   | 274M/398M [02:37<01:17, 1.60MB/s]\n"," 69%|######9   | 275M/398M [02:37<01:07, 1.82MB/s]\n"," 69%|######9   | 275M/398M [02:37<01:02, 1.97MB/s]\n"," 69%|######9   | 276M/398M [02:37<01:01, 2.00MB/s]\n"," 69%|######9   | 276M/398M [02:38<01:20, 1.50MB/s]\n"," 70%|######9   | 277M/398M [02:38<01:03, 1.89MB/s]\n"," 70%|######9   | 277M/398M [02:38<00:53, 2.24MB/s]\n"," 70%|######9   | 278M/398M [02:38<01:02, 1.92MB/s]\n"," 70%|#######   | 279M/398M [02:39<00:44, 2.69MB/s]\n"," 70%|#######   | 279M/398M [02:39<00:45, 2.61MB/s]\n"," 70%|#######   | 280M/398M [02:39<00:50, 2.35MB/s]\n"," 70%|#######   | 280M/398M [02:39<00:49, 2.38MB/s]\n"," 71%|#######   | 281M/398M [02:40<00:43, 2.70MB/s]\n"," 71%|#######   | 282M/398M [02:40<00:52, 2.21MB/s]\n"," 71%|#######1  | 283M/398M [02:41<01:07, 1.70MB/s]\n"," 71%|#######1  | 284M/398M [02:41<00:57, 1.97MB/s]\n"," 71%|#######1  | 284M/398M [02:41<00:50, 2.23MB/s]\n"," 72%|#######1  | 285M/398M [02:42<01:03, 1.78MB/s]\n"," 72%|#######1  | 286M/398M [02:42<00:50, 2.21MB/s]\n"," 72%|#######1  | 286M/398M [02:42<01:02, 1.78MB/s]\n"," 72%|#######2  | 287M/398M [02:43<00:59, 1.86MB/s]\n"," 72%|#######2  | 287M/398M [02:43<00:59, 1.86MB/s]\n"," 72%|#######2  | 288M/398M [02:43<01:02, 1.76MB/s]\n"," 73%|#######2  | 289M/398M [02:44<00:48, 2.26MB/s]\n"," 73%|#######2  | 289M/398M [02:44<00:51, 2.12MB/s]\n"," 73%|#######2  | 290M/398M [02:44<00:50, 2.16MB/s]\n"," 73%|#######2  | 290M/398M [02:44<00:47, 2.28MB/s]\n"," 73%|#######3  | 291M/398M [02:45<00:50, 2.14MB/s]\n"," 73%|#######3  | 292M/398M [02:45<01:06, 1.60MB/s]\n"," 73%|#######3  | 292M/398M [02:45<00:54, 1.96MB/s]\n"," 74%|#######3  | 293M/398M [02:45<00:48, 2.15MB/s]\n"," 74%|#######3  | 293M/398M [02:46<00:46, 2.24MB/s]\n"," 74%|#######3  | 294M/398M [02:46<00:46, 2.24MB/s]\n"," 74%|#######3  | 294M/398M [02:46<00:54, 1.91MB/s]\n"," 74%|#######4  | 295M/398M [02:46<00:49, 2.07MB/s]\n"," 74%|#######4  | 295M/398M [02:47<00:47, 2.15MB/s]\n"," 74%|#######4  | 296M/398M [02:47<00:56, 1.82MB/s]\n"," 74%|#######4  | 296M/398M [02:47<00:47, 2.15MB/s]\n"," 75%|#######4  | 297M/398M [02:47<00:39, 2.56MB/s]\n"," 75%|#######4  | 297M/398M [02:48<00:39, 2.55MB/s]\n"," 75%|#######4  | 298M/398M [02:48<00:42, 2.36MB/s]\n"," 75%|#######4  | 298M/398M [02:48<01:07, 1.48MB/s]\n"," 75%|#######5  | 299M/398M [02:49<00:47, 2.07MB/s]\n"," 75%|#######5  | 300M/398M [02:49<00:51, 1.90MB/s]\n"," 75%|#######5  | 300M/398M [02:50<01:00, 1.62MB/s]\n"," 76%|#######5  | 301M/398M [02:50<00:39, 2.46MB/s]\n"," 76%|#######5  | 302M/398M [02:50<00:43, 2.21MB/s]\n"," 76%|#######6  | 303M/398M [02:50<00:40, 2.33MB/s]\n"," 76%|#######6  | 303M/398M [02:50<00:41, 2.30MB/s]\n"," 76%|#######6  | 304M/398M [02:51<00:38, 2.45MB/s]\n"," 76%|#######6  | 304M/398M [02:51<00:53, 1.74MB/s]\n"," 77%|#######6  | 305M/398M [02:51<00:38, 2.39MB/s]\n"," 77%|#######6  | 306M/398M [02:52<00:37, 2.44MB/s]\n"," 77%|#######6  | 306M/398M [02:52<00:45, 2.02MB/s]\n"," 77%|#######7  | 307M/398M [02:52<00:32, 2.81MB/s]\n"," 77%|#######7  | 308M/398M [02:52<00:29, 3.07MB/s]\n"," 77%|#######7  | 308M/398M [02:53<00:39, 2.27MB/s]\n"," 78%|#######7  | 309M/398M [02:53<00:37, 2.35MB/s]\n"," 78%|#######7  | 309M/398M [02:53<00:42, 2.07MB/s]\n"," 78%|#######7  | 310M/398M [02:53<00:39, 2.22MB/s]\n"," 78%|#######7  | 310M/398M [02:54<00:54, 1.62MB/s]\n"," 78%|#######8  | 311M/398M [02:54<00:47, 1.83MB/s]\n"," 78%|#######8  | 311M/398M [02:55<00:52, 1.64MB/s]\n"," 78%|#######8  | 312M/398M [02:55<01:01, 1.40MB/s]\n"," 79%|#######8  | 312M/398M [02:55<00:48, 1.76MB/s]\n"," 79%|#######8  | 313M/398M [02:56<00:59, 1.43MB/s]\n"," 79%|#######8  | 314M/398M [02:56<00:42, 1.97MB/s]\n"," 79%|#######9  | 315M/398M [02:57<00:53, 1.56MB/s]\n"," 79%|#######9  | 316M/398M [02:57<00:43, 1.90MB/s]\n"," 79%|#######9  | 316M/398M [02:57<00:36, 2.22MB/s]\n"," 80%|#######9  | 317M/398M [02:57<00:35, 2.30MB/s]\n"," 80%|#######9  | 317M/398M [02:58<00:41, 1.94MB/s]\n"," 80%|#######9  | 318M/398M [02:58<00:34, 2.32MB/s]\n"," 80%|#######9  | 318M/398M [02:58<00:33, 2.38MB/s]\n"," 80%|########  | 319M/398M [02:58<00:41, 1.92MB/s]\n"," 80%|########  | 319M/398M [02:58<00:34, 2.31MB/s]\n"," 80%|########  | 320M/398M [02:59<00:32, 2.37MB/s]\n"," 80%|########  | 320M/398M [02:59<00:35, 2.18MB/s]\n"," 81%|########  | 321M/398M [02:59<00:44, 1.73MB/s]\n"," 81%|########  | 322M/398M [03:00<00:32, 2.33MB/s]\n"," 81%|########1 | 322M/398M [03:00<00:36, 2.05MB/s]\n"," 81%|########1 | 323M/398M [03:00<00:39, 1.88MB/s]\n"," 81%|########1 | 323M/398M [03:01<00:37, 1.97MB/s]\n"," 81%|########1 | 324M/398M [03:01<00:48, 1.52MB/s]\n"," 82%|########1 | 325M/398M [03:01<00:41, 1.77MB/s]\n"," 82%|########1 | 325M/398M [03:02<00:42, 1.73MB/s]\n"," 82%|########1 | 326M/398M [03:02<00:52, 1.38MB/s]\n"," 82%|########1 | 326M/398M [03:03<00:56, 1.28MB/s]\n"," 82%|########2 | 327M/398M [03:03<00:54, 1.31MB/s]\n"," 82%|########2 | 327M/398M [03:03<00:55, 1.28MB/s]\n"," 82%|########2 | 328M/398M [03:04<00:48, 1.46MB/s]\n"," 82%|########2 | 328M/398M [03:04<00:40, 1.72MB/s]\n"," 83%|########2 | 329M/398M [03:04<00:36, 1.92MB/s]\n"," 83%|########2 | 329M/398M [03:05<00:44, 1.55MB/s]\n"," 83%|########2 | 330M/398M [03:05<00:35, 1.91MB/s]\n"," 83%|########2 | 330M/398M [03:05<00:31, 2.13MB/s]\n"," 83%|########3 | 331M/398M [03:05<00:38, 1.74MB/s]\n"," 83%|########3 | 331M/398M [03:05<00:33, 1.97MB/s]\n"," 83%|########3 | 332M/398M [03:06<00:27, 2.37MB/s]\n"," 84%|########3 | 332M/398M [03:06<00:34, 1.88MB/s]\n"," 84%|########3 | 333M/398M [03:06<00:32, 2.03MB/s]\n"," 84%|########3 | 333M/398M [03:07<00:37, 1.72MB/s]\n"," 84%|########4 | 334M/398M [03:07<00:31, 2.03MB/s]\n"," 84%|########4 | 336M/398M [03:07<00:25, 2.41MB/s]\n"," 84%|########4 | 336M/398M [03:08<00:23, 2.61MB/s]\n"," 85%|########4 | 337M/398M [03:08<00:33, 1.82MB/s]\n"," 85%|########4 | 337M/398M [03:08<00:29, 2.08MB/s]\n"," 85%|########4 | 338M/398M [03:09<00:35, 1.68MB/s]\n"," 85%|########4 | 338M/398M [03:09<00:39, 1.50MB/s]\n"," 85%|########5 | 339M/398M [03:09<00:34, 1.74MB/s]\n"," 85%|########5 | 339M/398M [03:10<00:37, 1.56MB/s]\n"," 85%|########5 | 340M/398M [03:10<00:39, 1.47MB/s]\n"," 86%|########5 | 341M/398M [03:10<00:26, 2.17MB/s]\n"," 86%|########5 | 341M/398M [03:11<00:25, 2.19MB/s]\n"," 86%|########5 | 342M/398M [03:11<00:26, 2.12MB/s]\n"," 86%|########6 | 342M/398M [03:11<00:25, 2.15MB/s]\n"," 86%|########6 | 343M/398M [03:11<00:24, 2.29MB/s]\n"," 86%|########6 | 343M/398M [03:12<00:25, 2.12MB/s]\n"," 86%|########6 | 344M/398M [03:12<00:26, 2.03MB/s]\n"," 87%|########6 | 344M/398M [03:12<00:22, 2.39MB/s]\n"," 87%|########6 | 345M/398M [03:12<00:22, 2.36MB/s]\n"," 87%|########6 | 346M/398M [03:13<00:30, 1.73MB/s]\n"," 87%|########6 | 346M/398M [03:13<00:29, 1.78MB/s]\n"," 87%|########7 | 347M/398M [03:13<00:25, 2.02MB/s]\n"," 87%|########7 | 348M/398M [03:14<00:24, 2.09MB/s]\n"," 87%|########7 | 348M/398M [03:14<00:32, 1.53MB/s]\n"," 88%|########7 | 349M/398M [03:14<00:26, 1.88MB/s]\n"," 88%|########7 | 349M/398M [03:15<00:33, 1.46MB/s]\n"," 88%|########7 | 350M/398M [03:15<00:27, 1.76MB/s]\n"," 88%|########8 | 350M/398M [03:15<00:25, 1.91MB/s]\n"," 88%|########8 | 351M/398M [03:16<00:30, 1.53MB/s]\n"," 88%|########8 | 351M/398M [03:16<00:24, 1.90MB/s]\n"," 88%|########8 | 352M/398M [03:16<00:20, 2.30MB/s]\n"," 89%|########8 | 352M/398M [03:16<00:24, 1.90MB/s]\n"," 89%|########8 | 353M/398M [03:17<00:22, 2.01MB/s]\n"," 89%|########8 | 353M/398M [03:17<00:20, 2.17MB/s]\n"," 89%|########8 | 354M/398M [03:17<00:26, 1.65MB/s]\n"," 89%|########9 | 354M/398M [03:17<00:21, 2.07MB/s]\n"," 89%|########9 | 355M/398M [03:18<00:17, 2.46MB/s]\n"," 89%|########9 | 355M/398M [03:18<00:22, 1.86MB/s]\n"," 89%|########9 | 356M/398M [03:18<00:22, 1.84MB/s]\n"," 90%|########9 | 357M/398M [03:19<00:21, 1.92MB/s]\n"," 90%|########9 | 357M/398M [03:19<00:20, 1.97MB/s]\n"," 90%|########9 | 358M/398M [03:19<00:26, 1.51MB/s]\n"," 90%|########9 | 358M/398M [03:20<00:27, 1.45MB/s]\n"," 90%|######### | 359M/398M [03:20<00:28, 1.39MB/s]\n"," 90%|######### | 359M/398M [03:20<00:27, 1.42MB/s]\n"," 90%|######### | 360M/398M [03:21<00:32, 1.18MB/s]\n"," 91%|######### | 360M/398M [03:22<00:32, 1.17MB/s]\n"," 91%|######### | 361M/398M [03:22<00:32, 1.16MB/s]\n"," 91%|######### | 361M/398M [03:22<00:25, 1.46MB/s]\n"," 91%|######### | 362M/398M [03:22<00:22, 1.60MB/s]\n"," 91%|#########1| 362M/398M [03:23<00:23, 1.54MB/s]\n"," 91%|#########1| 363M/398M [03:23<00:22, 1.55MB/s]\n"," 91%|#########1| 363M/398M [03:23<00:21, 1.60MB/s]\n"," 91%|#########1| 364M/398M [03:24<00:20, 1.67MB/s]\n"," 92%|#########1| 364M/398M [03:24<00:22, 1.50MB/s]\n"," 92%|#########1| 365M/398M [03:25<00:22, 1.44MB/s]\n"," 92%|#########1| 365M/398M [03:25<00:18, 1.75MB/s]\n"," 92%|#########1| 366M/398M [03:25<00:15, 2.01MB/s]\n"," 92%|#########2| 366M/398M [03:25<00:16, 1.97MB/s]\n"," 92%|#########2| 367M/398M [03:25<00:16, 1.85MB/s]\n"," 92%|#########2| 368M/398M [03:26<00:11, 2.55MB/s]\n"," 93%|#########2| 369M/398M [03:26<00:12, 2.32MB/s]\n"," 93%|#########2| 369M/398M [03:26<00:13, 2.15MB/s]\n"," 93%|#########2| 370M/398M [03:27<00:15, 1.79MB/s]\n"," 93%|#########3| 370M/398M [03:27<00:15, 1.80MB/s]\n"," 93%|#########3| 371M/398M [03:28<00:18, 1.46MB/s]\n"," 93%|#########3| 372M/398M [03:28<00:13, 1.95MB/s]\n"," 94%|#########3| 372M/398M [03:28<00:12, 2.07MB/s]\n"," 94%|#########3| 373M/398M [03:28<00:12, 1.96MB/s]\n"," 94%|#########3| 373M/398M [03:29<00:14, 1.69MB/s]\n"," 94%|#########3| 374M/398M [03:29<00:14, 1.67MB/s]\n"," 94%|#########4| 374M/398M [03:29<00:12, 1.87MB/s]\n"," 94%|#########4| 375M/398M [03:30<00:12, 1.86MB/s]\n"," 94%|#########4| 375M/398M [03:30<00:11, 1.94MB/s]\n"," 94%|#########4| 376M/398M [03:30<00:11, 1.91MB/s]\n"," 95%|#########4| 376M/398M [03:30<00:10, 2.08MB/s]\n"," 95%|#########4| 377M/398M [03:31<00:09, 2.17MB/s]\n"," 95%|#########4| 377M/398M [03:31<00:09, 2.20MB/s]\n"," 95%|#########4| 378M/398M [03:31<00:08, 2.34MB/s]\n"," 95%|#########5| 379M/398M [03:31<00:09, 2.12MB/s]\n"," 95%|#########5| 379M/398M [03:32<00:13, 1.42MB/s]\n"," 96%|#########5| 380M/398M [03:32<00:08, 2.13MB/s]\n"," 96%|#########5| 381M/398M [03:33<00:11, 1.49MB/s]\n"," 96%|#########5| 381M/398M [03:33<00:11, 1.51MB/s]\n"," 96%|#########6| 382M/398M [03:34<00:08, 1.86MB/s]\n"," 96%|#########6| 383M/398M [03:34<00:10, 1.47MB/s]\n"," 96%|#########6| 383M/398M [03:35<00:11, 1.32MB/s]\n"," 96%|#########6| 384M/398M [03:35<00:10, 1.29MB/s]\n"," 97%|#########6| 384M/398M [03:36<00:11, 1.22MB/s]\n"," 97%|#########6| 385M/398M [03:36<00:10, 1.30MB/s]\n"," 97%|#########6| 385M/398M [03:36<00:08, 1.48MB/s]\n"," 97%|#########6| 386M/398M [03:36<00:07, 1.54MB/s]\n"," 97%|#########7| 386M/398M [03:37<00:06, 1.75MB/s]\n"," 97%|#########7| 387M/398M [03:37<00:05, 1.91MB/s]\n"," 97%|#########7| 387M/398M [03:37<00:06, 1.74MB/s]\n"," 97%|#########7| 388M/398M [03:37<00:05, 1.93MB/s]\n"," 98%|#########7| 388M/398M [03:38<00:04, 1.96MB/s]\n"," 98%|#########7| 389M/398M [03:38<00:04, 1.79MB/s]\n"," 98%|#########7| 390M/398M [03:39<00:06, 1.30MB/s]\n"," 98%|#########8| 390M/398M [03:39<00:04, 1.59MB/s]\n"," 98%|#########8| 391M/398M [03:39<00:04, 1.73MB/s]\n"," 98%|#########8| 391M/398M [03:39<00:04, 1.60MB/s]\n"," 98%|#########8| 392M/398M [03:40<00:03, 1.66MB/s]\n"," 99%|#########8| 392M/398M [03:40<00:03, 1.61MB/s]\n"," 99%|#########8| 393M/398M [03:40<00:03, 1.69MB/s]\n"," 99%|#########8| 393M/398M [03:41<00:02, 1.84MB/s]\n"," 99%|#########8| 394M/398M [03:41<00:02, 1.43MB/s]\n"," 99%|#########9| 394M/398M [03:41<00:02, 1.60MB/s]\n"," 99%|#########9| 395M/398M [03:42<00:01, 1.72MB/s]\n"," 99%|#########9| 395M/398M [03:42<00:01, 1.60MB/s]\n","100%|#########9| 396M/398M [03:42<00:00, 2.22MB/s]\n","100%|#########9| 397M/398M [03:42<00:00, 2.27MB/s]\n","100%|#########9| 397M/398M [03:43<00:00, 1.92MB/s]\n","100%|#########9| 398M/398M [03:43<00:00, 1.91MB/s]\n","100%|##########| 398M/398M [03:43<00:00, 1.78MB/s]\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\anaconda3\\envs\\summarization_v2\\lib\\site-packages\\gdown\\cli.py:127: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=14s4Efv9GoOcR1X-cyD-9a0xEKto2K95e\n","To: D:\\FypResearch\\Text Summarizer\\GANs\\version 1\\glove.6B.100d.txt\n","\n","  0%|          | 0.00/347M [00:00<?, ?B/s]\n","  0%|          | 524k/347M [00:00<08:55, 647kB/s]\n","  0%|          | 1.05M/347M [00:01<05:35, 1.03MB/s]\n","  0%|          | 1.57M/347M [00:01<04:33, 1.26MB/s]\n","  1%|          | 2.10M/347M [00:01<03:43, 1.54MB/s]\n","  1%|          | 2.62M/347M [00:02<04:17, 1.34MB/s]\n","  1%|          | 3.15M/347M [00:02<04:06, 1.40MB/s]\n","  1%|1         | 3.67M/347M [00:02<04:27, 1.28MB/s]\n","  1%|1         | 4.19M/347M [00:03<04:03, 1.41MB/s]\n","  1%|1         | 4.72M/347M [00:03<04:12, 1.36MB/s]\n","  2%|1         | 5.24M/347M [00:03<03:50, 1.49MB/s]\n","  2%|1         | 5.77M/347M [00:04<03:50, 1.48MB/s]\n","  2%|1         | 6.29M/347M [00:04<03:19, 1.71MB/s]\n","  2%|1         | 6.82M/347M [00:04<03:04, 1.84MB/s]\n","  2%|2         | 7.34M/347M [00:05<03:23, 1.67MB/s]\n","  2%|2         | 8.39M/347M [00:05<02:53, 1.95MB/s]\n","  3%|2         | 8.91M/347M [00:05<03:14, 1.74MB/s]\n","  3%|2         | 9.44M/347M [00:06<02:57, 1.90MB/s]\n","  3%|2         | 9.96M/347M [00:06<02:50, 1.98MB/s]\n","  3%|3         | 10.5M/347M [00:06<03:09, 1.77MB/s]\n","  3%|3         | 11.0M/347M [00:06<02:40, 2.10MB/s]\n","  3%|3         | 11.5M/347M [00:07<02:35, 2.16MB/s]\n","  3%|3         | 12.1M/347M [00:07<02:56, 1.90MB/s]\n","  4%|3         | 12.6M/347M [00:07<02:43, 2.05MB/s]\n","  4%|3         | 13.1M/347M [00:07<02:42, 2.06MB/s]\n","  4%|3         | 13.6M/347M [00:08<03:25, 1.63MB/s]\n","  4%|4         | 14.2M/347M [00:08<03:12, 1.73MB/s]\n","  4%|4         | 14.7M/347M [00:08<03:00, 1.84MB/s]\n","  4%|4         | 15.2M/347M [00:09<03:05, 1.79MB/s]\n","  5%|4         | 15.7M/347M [00:09<03:47, 1.46MB/s]\n","  5%|4         | 16.3M/347M [00:09<03:20, 1.65MB/s]\n","  5%|4         | 16.8M/347M [00:10<03:52, 1.42MB/s]\n","  5%|4         | 17.3M/347M [00:10<03:59, 1.38MB/s]\n","  5%|5         | 17.8M/347M [00:11<04:04, 1.35MB/s]\n","  5%|5         | 18.4M/347M [00:11<03:32, 1.54MB/s]\n","  5%|5         | 18.9M/347M [00:11<03:27, 1.59MB/s]\n","  6%|5         | 19.4M/347M [00:12<04:06, 1.33MB/s]\n","  6%|5         | 19.9M/347M [00:12<03:49, 1.42MB/s]\n","  6%|5         | 20.4M/347M [00:13<04:11, 1.30MB/s]\n","  6%|6         | 21.0M/347M [00:13<03:20, 1.63MB/s]\n","  6%|6         | 21.5M/347M [00:13<02:58, 1.82MB/s]\n","  6%|6         | 22.0M/347M [00:13<03:18, 1.64MB/s]\n","  6%|6         | 22.5M/347M [00:14<02:52, 1.88MB/s]\n","  7%|6         | 23.1M/347M [00:14<03:57, 1.37MB/s]\n","  7%|6         | 23.6M/347M [00:14<03:43, 1.45MB/s]\n","  7%|6         | 24.1M/347M [00:15<03:29, 1.54MB/s]\n","  7%|7         | 24.6M/347M [00:15<03:48, 1.41MB/s]\n","  7%|7         | 25.2M/347M [00:16<03:52, 1.38MB/s]\n","  7%|7         | 25.7M/347M [00:16<03:55, 1.36MB/s]\n","  8%|7         | 26.2M/347M [00:16<03:59, 1.34MB/s]\n","  8%|7         | 26.7M/347M [00:17<03:09, 1.69MB/s]\n","  8%|7         | 27.3M/347M [00:17<02:51, 1.87MB/s]\n","  8%|8         | 27.8M/347M [00:17<03:41, 1.44MB/s]\n","  8%|8         | 28.8M/347M [00:18<02:34, 2.06MB/s]\n","  8%|8         | 29.4M/347M [00:18<02:29, 2.12MB/s]\n","  9%|8         | 29.9M/347M [00:18<02:53, 1.82MB/s]\n","  9%|8         | 30.9M/347M [00:19<02:41, 1.96MB/s]\n","  9%|9         | 32.0M/347M [00:19<02:06, 2.50MB/s]\n","  9%|9         | 32.5M/347M [00:19<02:32, 2.07MB/s]\n"," 10%|9         | 33.0M/347M [00:20<02:47, 1.88MB/s]\n"," 10%|9         | 33.6M/347M [00:20<02:29, 2.09MB/s]\n"," 10%|9         | 34.1M/347M [00:20<02:25, 2.15MB/s]\n"," 10%|9         | 34.6M/347M [00:20<02:27, 2.12MB/s]\n"," 10%|#         | 35.1M/347M [00:21<02:40, 1.94MB/s]\n"," 10%|#         | 36.2M/347M [00:21<02:11, 2.36MB/s]\n"," 11%|#         | 36.7M/347M [00:21<02:04, 2.50MB/s]\n"," 11%|#         | 37.2M/347M [00:22<02:40, 1.93MB/s]\n"," 11%|#         | 37.7M/347M [00:22<02:13, 2.32MB/s]\n"," 11%|#1        | 38.3M/347M [00:22<02:23, 2.16MB/s]\n"," 11%|#1        | 38.8M/347M [00:22<02:51, 1.80MB/s]\n"," 11%|#1        | 39.3M/347M [00:23<02:28, 2.07MB/s]\n"," 11%|#1        | 39.8M/347M [00:23<03:20, 1.53MB/s]\n"," 12%|#1        | 40.4M/347M [00:24<03:29, 1.46MB/s]\n"," 12%|#1        | 40.9M/347M [00:24<03:02, 1.68MB/s]\n"," 12%|#1        | 41.4M/347M [00:24<03:46, 1.35MB/s]\n"," 12%|#2        | 41.9M/347M [00:24<03:05, 1.65MB/s]\n"," 12%|#2        | 42.5M/347M [00:25<03:11, 1.59MB/s]\n"," 12%|#2        | 43.0M/347M [00:25<03:33, 1.42MB/s]\n"," 13%|#2        | 43.5M/347M [00:25<03:06, 1.63MB/s]\n"," 13%|#2        | 44.0M/347M [00:26<02:50, 1.78MB/s]\n"," 13%|#2        | 44.6M/347M [00:26<02:51, 1.76MB/s]\n"," 13%|#2        | 45.1M/347M [00:26<02:51, 1.76MB/s]\n"," 13%|#3        | 45.6M/347M [00:27<03:09, 1.59MB/s]\n"," 13%|#3        | 46.1M/347M [00:27<03:02, 1.65MB/s]\n"," 13%|#3        | 46.7M/347M [00:27<02:48, 1.79MB/s]\n"," 14%|#3        | 47.2M/347M [00:28<02:46, 1.81MB/s]\n"," 14%|#3        | 47.7M/347M [00:28<02:32, 1.96MB/s]\n"," 14%|#3        | 48.2M/347M [00:28<02:06, 2.36MB/s]\n"," 14%|#4        | 48.8M/347M [00:28<02:06, 2.35MB/s]\n"," 14%|#4        | 49.3M/347M [00:28<02:34, 1.93MB/s]\n"," 14%|#4        | 49.8M/347M [00:29<03:30, 1.41MB/s]\n"," 14%|#4        | 50.3M/347M [00:29<03:00, 1.64MB/s]\n"," 15%|#4        | 50.9M/347M [00:30<03:06, 1.59MB/s]\n"," 15%|#4        | 51.4M/347M [00:30<03:05, 1.59MB/s]\n"," 15%|#4        | 51.9M/347M [00:30<03:03, 1.61MB/s]\n"," 15%|#5        | 52.4M/347M [00:31<03:35, 1.37MB/s]\n"," 15%|#5        | 53.0M/347M [00:31<02:58, 1.64MB/s]\n"," 15%|#5        | 53.5M/347M [00:31<02:56, 1.66MB/s]\n"," 16%|#5        | 54.0M/347M [00:32<02:53, 1.69MB/s]\n"," 16%|#5        | 54.5M/347M [00:32<02:35, 1.88MB/s]\n"," 16%|#5        | 55.1M/347M [00:32<02:22, 2.04MB/s]\n"," 16%|#6        | 55.6M/347M [00:32<02:38, 1.84MB/s]\n"," 16%|#6        | 56.1M/347M [00:33<02:33, 1.89MB/s]\n"," 16%|#6        | 57.1M/347M [00:33<01:53, 2.55MB/s]\n"," 17%|#6        | 57.7M/347M [00:33<02:09, 2.24MB/s]\n"," 17%|#6        | 58.2M/347M [00:34<02:47, 1.72MB/s]\n"," 17%|#6        | 58.7M/347M [00:34<02:39, 1.80MB/s]\n"," 17%|#7        | 59.2M/347M [00:34<02:45, 1.74MB/s]\n"," 17%|#7        | 59.8M/347M [00:35<03:18, 1.45MB/s]\n"," 17%|#7        | 60.3M/347M [00:35<02:52, 1.66MB/s]\n"," 18%|#7        | 60.8M/347M [00:35<02:54, 1.64MB/s]\n"," 18%|#7        | 61.3M/347M [00:36<02:47, 1.70MB/s]\n"," 18%|#7        | 61.9M/347M [00:36<02:49, 1.68MB/s]\n"," 18%|#7        | 62.4M/347M [00:36<02:19, 2.04MB/s]\n"," 18%|#8        | 62.9M/347M [00:36<02:54, 1.63MB/s]\n"," 18%|#8        | 64.0M/347M [00:37<02:00, 2.36MB/s]\n"," 19%|#8        | 64.5M/347M [00:37<01:56, 2.42MB/s]\n"," 19%|#8        | 65.0M/347M [00:37<02:12, 2.12MB/s]\n"," 19%|#8        | 65.5M/347M [00:37<02:06, 2.22MB/s]\n"," 19%|#9        | 66.6M/347M [00:38<01:58, 2.37MB/s]\n"," 19%|#9        | 67.1M/347M [00:38<01:54, 2.45MB/s]\n"," 19%|#9        | 67.6M/347M [00:38<02:13, 2.09MB/s]\n"," 20%|#9        | 68.2M/347M [00:39<02:30, 1.85MB/s]\n"," 20%|#9        | 68.7M/347M [00:39<03:06, 1.49MB/s]\n"," 20%|#9        | 69.2M/347M [00:40<02:55, 1.58MB/s]\n"," 20%|##        | 69.7M/347M [00:40<02:39, 1.74MB/s]\n"," 20%|##        | 70.3M/347M [00:40<02:24, 1.91MB/s]\n"," 20%|##        | 70.8M/347M [00:40<02:42, 1.70MB/s]\n"," 21%|##        | 71.3M/347M [00:41<02:24, 1.91MB/s]\n"," 21%|##        | 71.8M/347M [00:41<02:01, 2.26MB/s]\n"," 21%|##        | 72.4M/347M [00:41<02:26, 1.87MB/s]\n"," 21%|##        | 72.9M/347M [00:41<01:59, 2.29MB/s]\n"," 21%|##1       | 73.4M/347M [00:41<02:04, 2.21MB/s]\n"," 21%|##1       | 73.9M/347M [00:42<02:04, 2.19MB/s]\n"," 21%|##1       | 74.4M/347M [00:42<02:01, 2.24MB/s]\n"," 22%|##1       | 75.0M/347M [00:42<01:56, 2.34MB/s]\n"," 22%|##1       | 75.5M/347M [00:42<01:48, 2.51MB/s]\n"," 22%|##1       | 76.0M/347M [00:43<01:57, 2.30MB/s]\n"," 22%|##2       | 76.5M/347M [00:43<02:08, 2.10MB/s]\n"," 22%|##2       | 77.6M/347M [00:43<02:13, 2.02MB/s]\n"," 23%|##2       | 78.6M/347M [00:44<02:08, 2.09MB/s]\n"," 23%|##2       | 79.2M/347M [00:44<02:00, 2.23MB/s]\n"," 23%|##2       | 79.7M/347M [00:45<02:22, 1.87MB/s]\n"," 23%|##3       | 80.2M/347M [00:45<02:53, 1.54MB/s]\n"," 23%|##3       | 80.7M/347M [00:45<02:39, 1.67MB/s]\n"," 24%|##3       | 81.8M/347M [00:46<02:34, 1.72MB/s]\n"," 24%|##3       | 82.3M/347M [00:46<02:10, 2.03MB/s]\n"," 24%|##4       | 83.4M/347M [00:47<02:30, 1.75MB/s]\n"," 24%|##4       | 84.4M/347M [00:47<01:46, 2.47MB/s]\n"," 24%|##4       | 84.9M/347M [00:47<01:54, 2.30MB/s]\n"," 25%|##4       | 85.5M/347M [00:48<02:28, 1.76MB/s]\n"," 25%|##4       | 86.0M/347M [00:48<02:06, 2.07MB/s]\n"," 25%|##4       | 86.5M/347M [00:48<02:10, 2.00MB/s]\n"," 25%|##5       | 87.0M/347M [00:48<02:12, 1.96MB/s]\n"," 25%|##5       | 87.6M/347M [00:49<02:27, 1.76MB/s]\n"," 25%|##5       | 88.1M/347M [00:49<02:25, 1.79MB/s]\n"," 26%|##5       | 88.6M/347M [00:50<03:19, 1.30MB/s]\n"," 26%|##5       | 89.1M/347M [00:50<02:42, 1.59MB/s]\n"," 26%|##5       | 89.7M/347M [00:50<02:51, 1.50MB/s]\n"," 26%|##5       | 90.2M/347M [00:51<02:54, 1.47MB/s]\n"," 26%|##6       | 90.7M/347M [00:51<02:32, 1.69MB/s]\n"," 26%|##6       | 91.2M/347M [00:51<03:02, 1.40MB/s]\n"," 26%|##6       | 91.8M/347M [00:52<03:07, 1.36MB/s]\n"," 27%|##6       | 92.3M/347M [00:52<02:26, 1.74MB/s]\n"," 27%|##6       | 92.8M/347M [00:52<02:18, 1.84MB/s]\n"," 27%|##6       | 93.3M/347M [00:52<02:30, 1.69MB/s]\n"," 27%|##7       | 93.8M/347M [00:53<02:25, 1.74MB/s]\n"," 27%|##7       | 94.4M/347M [00:53<02:46, 1.52MB/s]\n"," 27%|##7       | 94.9M/347M [00:53<02:26, 1.72MB/s]\n"," 27%|##7       | 95.4M/347M [00:54<02:09, 1.95MB/s]\n"," 28%|##7       | 95.9M/347M [00:54<03:25, 1.22MB/s]\n"," 28%|##7       | 97.0M/347M [00:55<02:29, 1.67MB/s]\n"," 28%|##8       | 97.5M/347M [00:55<02:26, 1.70MB/s]\n"," 28%|##8       | 98.0M/347M [00:55<02:25, 1.71MB/s]\n"," 28%|##8       | 98.6M/347M [00:55<02:03, 2.01MB/s]\n"," 29%|##8       | 99.1M/347M [00:56<02:06, 1.97MB/s]\n"," 29%|##8       | 99.6M/347M [00:56<02:28, 1.67MB/s]\n"," 29%|##8       | 100M/347M [00:56<02:06, 1.95MB/s] \n"," 29%|##8       | 101M/347M [00:57<02:00, 2.05MB/s]\n"," 29%|##9       | 101M/347M [00:57<02:25, 1.70MB/s]\n"," 29%|##9       | 102M/347M [00:57<02:12, 1.86MB/s]\n"," 29%|##9       | 102M/347M [00:58<02:25, 1.69MB/s]\n"," 30%|##9       | 103M/347M [00:58<03:06, 1.31MB/s]\n"," 30%|##9       | 103M/347M [00:58<02:38, 1.54MB/s]\n"," 30%|##9       | 104M/347M [00:59<02:47, 1.45MB/s]\n"," 30%|###       | 104M/347M [00:59<02:31, 1.60MB/s]\n"," 30%|###       | 105M/347M [00:59<02:10, 1.86MB/s]\n"," 30%|###       | 105M/347M [01:00<02:50, 1.42MB/s]\n"," 31%|###       | 106M/347M [01:00<02:17, 1.76MB/s]\n"," 31%|###       | 106M/347M [01:00<01:55, 2.08MB/s]\n"," 31%|###       | 107M/347M [01:00<01:46, 2.25MB/s]\n"," 31%|###       | 107M/347M [01:01<03:09, 1.26MB/s]\n"," 31%|###1      | 109M/347M [01:01<02:11, 1.81MB/s]\n"," 31%|###1      | 109M/347M [01:02<02:29, 1.59MB/s]\n"," 32%|###1      | 110M/347M [01:02<02:13, 1.78MB/s]\n"," 32%|###1      | 110M/347M [01:02<02:09, 1.83MB/s]\n"," 32%|###1      | 111M/347M [01:02<01:59, 1.97MB/s]\n"," 32%|###2      | 111M/347M [01:03<02:10, 1.81MB/s]\n"," 32%|###2      | 112M/347M [01:03<02:06, 1.87MB/s]\n"," 32%|###2      | 112M/347M [01:03<02:00, 1.95MB/s]\n"," 32%|###2      | 113M/347M [01:04<02:13, 1.75MB/s]\n"," 33%|###2      | 113M/347M [01:04<02:03, 1.89MB/s]\n"," 33%|###2      | 114M/347M [01:04<02:36, 1.49MB/s]\n"," 33%|###2      | 114M/347M [01:05<02:13, 1.74MB/s]\n"," 33%|###3      | 115M/347M [01:05<02:40, 1.45MB/s]\n"," 33%|###3      | 115M/347M [01:05<02:24, 1.60MB/s]\n"," 33%|###3      | 116M/347M [01:06<02:06, 1.83MB/s]\n"," 34%|###3      | 116M/347M [01:06<02:27, 1.56MB/s]\n"," 34%|###3      | 117M/347M [01:06<02:16, 1.69MB/s]\n"," 34%|###3      | 117M/347M [01:07<02:36, 1.47MB/s]\n"," 34%|###4      | 118M/347M [01:07<02:00, 1.90MB/s]\n"," 34%|###4      | 119M/347M [01:07<01:58, 1.93MB/s]\n"," 34%|###4      | 120M/347M [01:08<02:08, 1.77MB/s]\n"," 35%|###4      | 120M/347M [01:08<01:46, 2.13MB/s]\n"," 35%|###4      | 121M/347M [01:08<01:34, 2.39MB/s]\n"," 35%|###4      | 121M/347M [01:08<01:44, 2.16MB/s]\n"," 35%|###5      | 122M/347M [01:09<02:11, 1.71MB/s]\n"," 35%|###5      | 122M/347M [01:09<01:54, 1.96MB/s]\n"," 35%|###5      | 123M/347M [01:09<01:51, 2.02MB/s]\n"," 35%|###5      | 123M/347M [01:09<01:57, 1.91MB/s]\n"," 36%|###5      | 124M/347M [01:10<01:54, 1.94MB/s]\n"," 36%|###5      | 124M/347M [01:10<02:29, 1.49MB/s]\n"," 36%|###5      | 125M/347M [01:11<02:23, 1.55MB/s]\n"," 36%|###6      | 125M/347M [01:11<02:49, 1.31MB/s]\n"," 36%|###6      | 126M/347M [01:12<02:45, 1.34MB/s]\n"," 36%|###6      | 126M/347M [01:12<02:36, 1.41MB/s]\n"," 37%|###6      | 127M/347M [01:12<02:26, 1.50MB/s]\n"," 37%|###6      | 127M/347M [01:12<02:25, 1.51MB/s]\n"," 37%|###6      | 128M/347M [01:13<02:24, 1.52MB/s]\n"," 37%|###7      | 128M/347M [01:13<02:26, 1.49MB/s]\n"," 37%|###7      | 129M/347M [01:14<02:22, 1.53MB/s]\n"," 37%|###7      | 129M/347M [01:14<02:39, 1.36MB/s]\n"," 37%|###7      | 130M/347M [01:14<02:19, 1.56MB/s]\n"," 38%|###7      | 131M/347M [01:14<02:06, 1.72MB/s]\n"," 38%|###7      | 131M/347M [01:15<02:15, 1.60MB/s]\n"," 38%|###7      | 132M/347M [01:15<02:01, 1.78MB/s]\n"," 38%|###8      | 132M/347M [01:15<01:51, 1.93MB/s]\n"," 38%|###8      | 133M/347M [01:16<01:54, 1.88MB/s]\n"," 38%|###8      | 133M/347M [01:16<01:54, 1.87MB/s]\n"," 39%|###8      | 134M/347M [01:16<02:01, 1.76MB/s]\n"," 39%|###8      | 134M/347M [01:17<02:37, 1.35MB/s]\n"," 39%|###8      | 135M/347M [01:17<02:13, 1.60MB/s]\n"," 39%|###8      | 135M/347M [01:17<02:00, 1.75MB/s]\n"," 39%|###9      | 136M/347M [01:18<02:26, 1.44MB/s]\n"," 39%|###9      | 136M/347M [01:18<02:06, 1.66MB/s]\n"," 39%|###9      | 137M/347M [01:18<02:03, 1.70MB/s]\n"," 40%|###9      | 137M/347M [01:19<02:27, 1.42MB/s]\n"," 40%|###9      | 138M/347M [01:19<02:08, 1.63MB/s]\n"," 40%|###9      | 138M/347M [01:19<02:08, 1.63MB/s]\n"," 40%|####      | 139M/347M [01:20<02:02, 1.70MB/s]\n"," 40%|####      | 139M/347M [01:20<01:42, 2.02MB/s]\n"," 40%|####      | 140M/347M [01:20<01:37, 2.14MB/s]\n"," 40%|####      | 141M/347M [01:20<01:44, 1.98MB/s]\n"," 41%|####      | 141M/347M [01:20<01:44, 1.97MB/s]\n"," 41%|####      | 142M/347M [01:21<01:29, 2.29MB/s]\n"," 41%|####      | 142M/347M [01:21<01:25, 2.39MB/s]\n"," 41%|####1     | 143M/347M [01:21<01:44, 1.95MB/s]\n"," 41%|####1     | 143M/347M [01:21<01:29, 2.27MB/s]\n"," 41%|####1     | 144M/347M [01:22<01:37, 2.08MB/s]\n"," 42%|####1     | 144M/347M [01:22<01:34, 2.15MB/s]\n"," 42%|####1     | 145M/347M [01:22<01:37, 2.09MB/s]\n"," 42%|####1     | 145M/347M [01:22<01:20, 2.51MB/s]\n"," 42%|####1     | 146M/347M [01:22<01:23, 2.42MB/s]\n"," 42%|####2     | 146M/347M [01:23<02:24, 1.39MB/s]\n"," 42%|####2     | 147M/347M [01:23<01:59, 1.68MB/s]\n"," 42%|####2     | 147M/347M [01:24<02:52, 1.16MB/s]\n"," 43%|####2     | 148M/347M [01:25<02:47, 1.19MB/s]\n"," 43%|####2     | 148M/347M [01:25<02:32, 1.31MB/s]\n"," 43%|####2     | 149M/347M [01:25<02:20, 1.41MB/s]\n"," 43%|####3     | 149M/347M [01:25<02:05, 1.58MB/s]\n"," 43%|####3     | 150M/347M [01:26<02:11, 1.50MB/s]\n"," 43%|####3     | 150M/347M [01:26<02:05, 1.57MB/s]\n"," 43%|####3     | 151M/347M [01:26<01:53, 1.72MB/s]\n"," 44%|####3     | 152M/347M [01:27<01:51, 1.76MB/s]\n"," 44%|####3     | 152M/347M [01:27<01:52, 1.73MB/s]\n"," 44%|####3     | 153M/347M [01:27<01:45, 1.84MB/s]\n"," 44%|####4     | 153M/347M [01:27<01:38, 1.96MB/s]\n"," 44%|####4     | 154M/347M [01:28<01:36, 2.01MB/s]\n"," 44%|####4     | 154M/347M [01:28<01:46, 1.80MB/s]\n"," 45%|####4     | 155M/347M [01:28<01:44, 1.85MB/s]\n"," 45%|####4     | 155M/347M [01:29<01:37, 1.96MB/s]\n"," 45%|####4     | 156M/347M [01:29<02:14, 1.42MB/s]\n"," 45%|####5     | 156M/347M [01:29<02:08, 1.49MB/s]\n"," 45%|####5     | 157M/347M [01:30<02:11, 1.45MB/s]\n"," 45%|####5     | 157M/347M [01:30<01:58, 1.60MB/s]\n"," 45%|####5     | 158M/347M [01:31<02:08, 1.47MB/s]\n"," 46%|####5     | 158M/347M [01:31<01:46, 1.78MB/s]\n"," 46%|####5     | 159M/347M [01:31<01:36, 1.95MB/s]\n"," 46%|####5     | 159M/347M [01:31<01:31, 2.05MB/s]\n"," 46%|####6     | 160M/347M [01:32<01:57, 1.59MB/s]\n"," 46%|####6     | 160M/347M [01:32<01:43, 1.81MB/s]\n"," 46%|####6     | 161M/347M [01:32<01:38, 1.89MB/s]\n"," 47%|####6     | 161M/347M [01:32<01:36, 1.92MB/s]\n"," 47%|####6     | 162M/347M [01:32<01:22, 2.25MB/s]\n"," 47%|####6     | 163M/347M [01:33<01:22, 2.23MB/s]\n"," 47%|####6     | 163M/347M [01:33<01:23, 2.20MB/s]\n"," 47%|####7     | 164M/347M [01:33<01:55, 1.60MB/s]\n"," 47%|####7     | 164M/347M [01:34<01:49, 1.68MB/s]\n"," 47%|####7     | 165M/347M [01:34<02:12, 1.38MB/s]\n"," 48%|####7     | 165M/347M [01:34<01:51, 1.64MB/s]\n"," 48%|####7     | 166M/347M [01:35<02:03, 1.47MB/s]\n"," 48%|####7     | 166M/347M [01:35<01:58, 1.52MB/s]\n"," 48%|####8     | 167M/347M [01:36<01:54, 1.57MB/s]\n"," 48%|####8     | 167M/347M [01:36<01:37, 1.84MB/s]\n"," 48%|####8     | 168M/347M [01:36<01:44, 1.71MB/s]\n"," 48%|####8     | 168M/347M [01:36<01:31, 1.96MB/s]\n"," 49%|####8     | 169M/347M [01:37<01:34, 1.89MB/s]\n"," 49%|####8     | 169M/347M [01:37<01:35, 1.86MB/s]\n"," 49%|####8     | 170M/347M [01:37<01:28, 1.99MB/s]\n"," 49%|####9     | 170M/347M [01:37<01:23, 2.12MB/s]\n"," 49%|####9     | 171M/347M [01:37<01:12, 2.42MB/s]\n"," 49%|####9     | 171M/347M [01:38<01:16, 2.29MB/s]\n"," 50%|####9     | 172M/347M [01:38<01:24, 2.06MB/s]\n"," 50%|####9     | 173M/347M [01:38<01:18, 2.21MB/s]\n"," 50%|####9     | 174M/347M [01:39<01:13, 2.37MB/s]\n"," 50%|#####     | 174M/347M [01:39<01:09, 2.50MB/s]\n"," 50%|#####     | 175M/347M [01:39<01:03, 2.70MB/s]\n"," 50%|#####     | 175M/347M [01:39<01:15, 2.29MB/s]\n"," 51%|#####     | 176M/347M [01:40<01:38, 1.75MB/s]\n"," 51%|#####     | 176M/347M [01:40<01:27, 1.96MB/s]\n"," 51%|#####     | 177M/347M [01:40<01:33, 1.82MB/s]\n"," 51%|#####1    | 177M/347M [01:40<01:26, 1.96MB/s]\n"," 51%|#####1    | 178M/347M [01:41<01:38, 1.72MB/s]\n"," 51%|#####1    | 178M/347M [01:41<01:31, 1.84MB/s]\n"," 52%|#####1    | 179M/347M [01:41<01:31, 1.83MB/s]\n"," 52%|#####1    | 179M/347M [01:42<01:51, 1.51MB/s]\n"," 52%|#####1    | 180M/347M [01:42<01:30, 1.85MB/s]\n"," 52%|#####1    | 180M/347M [01:42<01:28, 1.89MB/s]\n"," 52%|#####2    | 181M/347M [01:43<01:33, 1.77MB/s]\n"," 52%|#####2    | 181M/347M [01:43<01:25, 1.94MB/s]\n"," 52%|#####2    | 182M/347M [01:43<01:47, 1.53MB/s]\n"," 53%|#####2    | 182M/347M [01:43<01:25, 1.94MB/s]\n"," 53%|#####2    | 183M/347M [01:44<01:18, 2.10MB/s]\n"," 53%|#####2    | 184M/347M [01:44<01:16, 2.14MB/s]\n"," 53%|#####3    | 184M/347M [01:44<01:21, 2.01MB/s]\n"," 53%|#####3    | 185M/347M [01:44<01:14, 2.18MB/s]\n"," 53%|#####3    | 185M/347M [01:45<01:50, 1.47MB/s]\n"," 53%|#####3    | 186M/347M [01:45<01:32, 1.74MB/s]\n"," 54%|#####3    | 186M/347M [01:45<01:19, 2.03MB/s]\n"," 54%|#####3    | 187M/347M [01:46<01:23, 1.92MB/s]\n"," 54%|#####3    | 187M/347M [01:46<01:42, 1.56MB/s]\n"," 54%|#####4    | 188M/347M [01:46<01:43, 1.55MB/s]\n"," 54%|#####4    | 188M/347M [01:47<01:35, 1.67MB/s]\n"," 54%|#####4    | 189M/347M [01:47<01:28, 1.79MB/s]\n"," 55%|#####4    | 189M/347M [01:47<01:44, 1.51MB/s]\n"," 55%|#####4    | 190M/347M [01:48<01:54, 1.38MB/s]\n"," 55%|#####4    | 191M/347M [01:48<01:26, 1.81MB/s]\n"," 55%|#####5    | 191M/347M [01:48<01:21, 1.91MB/s]\n"," 55%|#####5    | 192M/347M [01:49<01:29, 1.73MB/s]\n"," 55%|#####5    | 192M/347M [01:49<01:29, 1.72MB/s]\n"," 56%|#####5    | 193M/347M [01:49<01:17, 2.00MB/s]\n"," 56%|#####5    | 193M/347M [01:50<01:20, 1.90MB/s]\n"," 56%|#####5    | 194M/347M [01:50<01:13, 2.09MB/s]\n"," 56%|#####6    | 195M/347M [01:50<01:11, 2.14MB/s]\n"," 56%|#####6    | 195M/347M [01:50<01:01, 2.47MB/s]\n"," 56%|#####6    | 196M/347M [01:51<01:20, 1.89MB/s]\n"," 56%|#####6    | 196M/347M [01:51<01:08, 2.19MB/s]\n"," 57%|#####6    | 197M/347M [01:51<01:03, 2.37MB/s]\n"," 57%|#####6    | 197M/347M [01:51<00:59, 2.52MB/s]\n"," 57%|#####6    | 198M/347M [01:51<01:08, 2.17MB/s]\n"," 57%|#####7    | 198M/347M [01:52<00:56, 2.63MB/s]\n"," 57%|#####7    | 199M/347M [01:52<00:52, 2.84MB/s]\n"," 57%|#####7    | 199M/347M [01:52<01:06, 2.21MB/s]\n"," 58%|#####7    | 200M/347M [01:52<01:23, 1.75MB/s]\n"," 58%|#####7    | 200M/347M [01:53<01:15, 1.93MB/s]\n"," 58%|#####7    | 201M/347M [01:53<01:18, 1.85MB/s]\n"," 58%|#####7    | 201M/347M [01:53<01:20, 1.82MB/s]\n"," 58%|#####8    | 202M/347M [01:54<01:20, 1.81MB/s]\n"," 58%|#####8    | 202M/347M [01:54<01:21, 1.77MB/s]\n"," 58%|#####8    | 203M/347M [01:54<01:23, 1.73MB/s]\n"," 59%|#####8    | 203M/347M [01:55<01:39, 1.44MB/s]\n"," 59%|#####8    | 204M/347M [01:55<01:28, 1.62MB/s]\n"," 59%|#####8    | 204M/347M [01:55<01:28, 1.61MB/s]\n"," 59%|#####9    | 205M/347M [01:55<01:14, 1.91MB/s]\n"," 59%|#####9    | 206M/347M [01:56<01:10, 2.00MB/s]\n"," 59%|#####9    | 206M/347M [01:56<01:05, 2.16MB/s]\n"," 60%|#####9    | 207M/347M [01:56<01:00, 2.31MB/s]\n"," 60%|#####9    | 207M/347M [01:56<00:57, 2.45MB/s]\n"," 60%|#####9    | 208M/347M [01:57<00:59, 2.33MB/s]\n"," 60%|#####9    | 208M/347M [01:57<01:02, 2.21MB/s]\n"," 60%|######    | 209M/347M [01:57<01:01, 2.27MB/s]\n"," 60%|######    | 209M/347M [01:57<00:58, 2.34MB/s]\n"," 60%|######    | 210M/347M [01:58<01:12, 1.89MB/s]\n"," 61%|######    | 211M/347M [01:58<00:51, 2.65MB/s]\n"," 61%|######    | 211M/347M [01:58<00:49, 2.76MB/s]\n"," 61%|######1   | 212M/347M [01:58<00:47, 2.87MB/s]\n"," 61%|######1   | 212M/347M [01:58<00:53, 2.50MB/s]\n"," 61%|######1   | 213M/347M [01:59<00:56, 2.38MB/s]\n"," 61%|######1   | 213M/347M [01:59<00:55, 2.42MB/s]\n"," 62%|######1   | 214M/347M [01:59<00:53, 2.50MB/s]\n"," 62%|######1   | 214M/347M [02:00<01:30, 1.46MB/s]\n"," 62%|######1   | 215M/347M [02:00<01:17, 1.71MB/s]\n"," 62%|######2   | 215M/347M [02:00<01:16, 1.72MB/s]\n"," 62%|######2   | 216M/347M [02:01<01:12, 1.82MB/s]\n"," 62%|######2   | 217M/347M [02:01<01:27, 1.49MB/s]\n"," 63%|######2   | 217M/347M [02:01<01:35, 1.36MB/s]\n"," 63%|######2   | 218M/347M [02:02<01:21, 1.60MB/s]\n"," 63%|######2   | 218M/347M [02:02<01:45, 1.22MB/s]\n"," 63%|######2   | 219M/347M [02:02<01:22, 1.55MB/s]\n"," 63%|######3   | 219M/347M [02:03<01:26, 1.48MB/s]\n"," 63%|######3   | 220M/347M [02:03<01:23, 1.53MB/s]\n"," 63%|######3   | 220M/347M [02:03<01:18, 1.61MB/s]\n"," 64%|######3   | 221M/347M [02:04<01:14, 1.70MB/s]\n"," 64%|######3   | 221M/347M [02:04<01:32, 1.36MB/s]\n"," 64%|######3   | 222M/347M [02:04<01:16, 1.63MB/s]\n"," 64%|######4   | 222M/347M [02:05<01:25, 1.45MB/s]\n"," 64%|######4   | 223M/347M [02:05<01:29, 1.39MB/s]\n"," 64%|######4   | 223M/347M [02:06<01:23, 1.49MB/s]\n"," 64%|######4   | 224M/347M [02:06<01:18, 1.56MB/s]\n"," 65%|######4   | 224M/347M [02:06<01:20, 1.53MB/s]\n"," 65%|######4   | 225M/347M [02:07<01:15, 1.61MB/s]\n"," 65%|######4   | 225M/347M [02:07<01:13, 1.65MB/s]\n"," 65%|######5   | 226M/347M [02:07<01:13, 1.64MB/s]\n"," 65%|######5   | 226M/347M [02:07<01:10, 1.70MB/s]\n"," 65%|######5   | 227M/347M [02:08<01:10, 1.71MB/s]\n"," 66%|######5   | 228M/347M [02:08<01:25, 1.40MB/s]\n"," 66%|######5   | 228M/347M [02:09<01:22, 1.44MB/s]\n"," 66%|######5   | 229M/347M [02:09<01:25, 1.38MB/s]\n"," 66%|######6   | 229M/347M [02:09<01:17, 1.53MB/s]\n"," 66%|######6   | 230M/347M [02:10<01:15, 1.56MB/s]\n"," 66%|######6   | 230M/347M [02:10<01:05, 1.78MB/s]\n"," 66%|######6   | 231M/347M [02:10<00:58, 2.00MB/s]\n"," 67%|######6   | 231M/347M [02:10<01:06, 1.74MB/s]\n"," 67%|######6   | 232M/347M [02:11<01:22, 1.40MB/s]\n"," 67%|######6   | 232M/347M [02:11<01:05, 1.76MB/s]\n"," 67%|######7   | 233M/347M [02:12<01:19, 1.45MB/s]\n"," 67%|######7   | 233M/347M [02:12<01:10, 1.61MB/s]\n"," 68%|######7   | 234M/347M [02:12<00:50, 2.23MB/s]\n"," 68%|######7   | 235M/347M [02:12<00:45, 2.44MB/s]\n"," 68%|######7   | 235M/347M [02:13<00:57, 1.94MB/s]\n"," 68%|######7   | 236M/347M [02:13<00:51, 2.17MB/s]\n"," 68%|######8   | 236M/347M [02:13<00:55, 2.00MB/s]\n"," 68%|######8   | 237M/347M [02:14<01:02, 1.78MB/s]\n"," 68%|######8   | 238M/347M [02:14<00:57, 1.91MB/s]\n"," 69%|######8   | 238M/347M [02:14<00:59, 1.82MB/s]\n"," 69%|######8   | 239M/347M [02:14<01:04, 1.69MB/s]\n"," 69%|######8   | 239M/347M [02:15<00:54, 1.97MB/s]\n"," 69%|######9   | 240M/347M [02:15<00:58, 1.83MB/s]\n"," 69%|######9   | 240M/347M [02:16<01:33, 1.14MB/s]\n"," 69%|######9   | 241M/347M [02:16<01:03, 1.67MB/s]\n"," 70%|######9   | 242M/347M [02:17<01:16, 1.37MB/s]\n"," 70%|######9   | 242M/347M [02:17<01:04, 1.63MB/s]\n"," 70%|######9   | 243M/347M [02:17<00:54, 1.92MB/s]\n"," 70%|#######   | 243M/347M [02:18<01:17, 1.34MB/s]\n"," 70%|#######   | 244M/347M [02:18<00:51, 1.99MB/s]\n"," 71%|#######   | 245M/347M [02:18<01:02, 1.62MB/s]\n"," 71%|#######   | 245M/347M [02:19<00:53, 1.89MB/s]\n"," 71%|#######   | 246M/347M [02:19<00:59, 1.69MB/s]\n"," 71%|#######   | 246M/347M [02:19<00:59, 1.70MB/s]\n"," 71%|#######1  | 247M/347M [02:19<00:54, 1.84MB/s]\n"," 71%|#######1  | 247M/347M [02:20<00:54, 1.83MB/s]\n"," 71%|#######1  | 248M/347M [02:20<00:58, 1.68MB/s]\n"," 72%|#######1  | 249M/347M [02:21<01:21, 1.20MB/s]\n"," 72%|#######1  | 249M/347M [02:21<01:24, 1.15MB/s]\n"," 72%|#######1  | 250M/347M [02:22<01:11, 1.36MB/s]\n"," 72%|#######2  | 250M/347M [02:22<01:23, 1.17MB/s]\n"," 72%|#######2  | 251M/347M [02:22<01:14, 1.29MB/s]\n"," 72%|#######2  | 251M/347M [02:23<00:59, 1.63MB/s]\n"," 72%|#######2  | 252M/347M [02:23<00:56, 1.68MB/s]\n"," 73%|#######2  | 252M/347M [02:23<00:56, 1.68MB/s]\n"," 73%|#######2  | 253M/347M [02:23<00:46, 2.04MB/s]\n"," 73%|#######2  | 253M/347M [02:24<00:44, 2.13MB/s]\n"," 73%|#######3  | 254M/347M [02:24<00:51, 1.80MB/s]\n"," 73%|#######3  | 254M/347M [02:24<00:41, 2.22MB/s]\n"," 73%|#######3  | 255M/347M [02:25<00:54, 1.68MB/s]\n"," 74%|#######3  | 255M/347M [02:25<01:15, 1.21MB/s]\n"," 74%|#######3  | 256M/347M [02:25<00:59, 1.54MB/s]\n"," 74%|#######3  | 256M/347M [02:26<00:56, 1.59MB/s]\n"," 74%|#######4  | 257M/347M [02:26<00:56, 1.59MB/s]\n"," 74%|#######4  | 257M/347M [02:27<01:04, 1.39MB/s]\n"," 74%|#######4  | 258M/347M [02:27<01:05, 1.36MB/s]\n"," 74%|#######4  | 258M/347M [02:27<01:02, 1.42MB/s]\n"," 75%|#######4  | 259M/347M [02:28<00:58, 1.49MB/s]\n"," 75%|#######4  | 260M/347M [02:28<00:55, 1.57MB/s]\n"," 75%|#######4  | 260M/347M [02:28<00:50, 1.73MB/s]\n"," 75%|#######5  | 261M/347M [02:28<00:49, 1.75MB/s]\n"," 75%|#######5  | 261M/347M [02:29<00:59, 1.46MB/s]\n"," 75%|#######5  | 262M/347M [02:29<00:51, 1.65MB/s]\n"," 76%|#######5  | 262M/347M [02:30<01:07, 1.26MB/s]\n"," 76%|#######5  | 263M/347M [02:30<01:00, 1.39MB/s]\n"," 76%|#######5  | 263M/347M [02:30<00:57, 1.47MB/s]\n"," 76%|#######5  | 264M/347M [02:31<00:48, 1.72MB/s]\n"," 76%|#######6  | 264M/347M [02:31<00:51, 1.62MB/s]\n"," 76%|#######6  | 265M/347M [02:31<01:02, 1.32MB/s]\n"," 76%|#######6  | 265M/347M [02:32<00:57, 1.41MB/s]\n"," 77%|#######6  | 266M/347M [02:32<00:53, 1.52MB/s]\n"," 77%|#######6  | 266M/347M [02:33<01:05, 1.23MB/s]\n"," 77%|#######6  | 267M/347M [02:33<00:51, 1.57MB/s]\n"," 77%|#######7  | 267M/347M [02:33<00:57, 1.38MB/s]\n"," 77%|#######7  | 268M/347M [02:34<00:51, 1.54MB/s]\n"," 77%|#######7  | 268M/347M [02:34<00:48, 1.61MB/s]\n"," 77%|#######7  | 269M/347M [02:34<00:51, 1.51MB/s]\n"," 78%|#######7  | 269M/347M [02:34<00:41, 1.86MB/s]\n"," 78%|#######7  | 270M/347M [02:35<00:38, 2.01MB/s]\n"," 78%|#######7  | 271M/347M [02:35<00:38, 1.97MB/s]\n"," 78%|#######8  | 271M/347M [02:35<00:36, 2.06MB/s]\n"," 78%|#######8  | 272M/347M [02:35<00:31, 2.42MB/s]\n"," 78%|#######8  | 272M/347M [02:35<00:31, 2.39MB/s]\n"," 79%|#######8  | 273M/347M [02:36<00:35, 2.09MB/s]\n"," 79%|#######8  | 273M/347M [02:36<00:48, 1.51MB/s]\n"," 79%|#######8  | 274M/347M [02:36<00:41, 1.76MB/s]\n"," 79%|#######8  | 274M/347M [02:37<00:46, 1.56MB/s]\n"," 79%|#######9  | 275M/347M [02:37<00:37, 1.95MB/s]\n"," 79%|#######9  | 275M/347M [02:37<00:37, 1.94MB/s]\n"," 79%|#######9  | 276M/347M [02:38<00:34, 2.04MB/s]\n"," 80%|#######9  | 276M/347M [02:38<00:31, 2.23MB/s]\n"," 80%|#######9  | 277M/347M [02:38<00:38, 1.82MB/s]\n"," 80%|########  | 278M/347M [02:39<00:34, 2.02MB/s]\n"," 80%|########  | 278M/347M [02:39<00:37, 1.82MB/s]\n"," 80%|########  | 279M/347M [02:39<00:32, 2.09MB/s]\n"," 81%|########  | 279M/347M [02:39<00:33, 2.03MB/s]\n"," 81%|########  | 280M/347M [02:40<00:45, 1.47MB/s]\n"," 81%|########  | 280M/347M [02:40<00:40, 1.66MB/s]\n"," 81%|########  | 281M/347M [02:40<00:39, 1.68MB/s]\n"," 81%|########1 | 282M/347M [02:41<00:39, 1.65MB/s]\n"," 81%|########1 | 282M/347M [02:41<00:50, 1.29MB/s]\n"," 81%|########1 | 283M/347M [02:42<00:46, 1.39MB/s]\n"," 82%|########1 | 283M/347M [02:42<00:42, 1.50MB/s]\n"," 82%|########1 | 284M/347M [02:42<00:37, 1.68MB/s]\n"," 82%|########1 | 284M/347M [02:43<00:36, 1.71MB/s]\n"," 82%|########2 | 285M/347M [02:43<00:36, 1.70MB/s]\n"," 82%|########2 | 285M/347M [02:43<00:35, 1.73MB/s]\n"," 82%|########2 | 286M/347M [02:43<00:33, 1.82MB/s]\n"," 82%|########2 | 286M/347M [02:44<00:32, 1.86MB/s]\n"," 83%|########2 | 287M/347M [02:44<00:28, 2.10MB/s]\n"," 83%|########2 | 287M/347M [02:44<00:25, 2.33MB/s]\n"," 83%|########2 | 288M/347M [02:44<00:28, 2.08MB/s]\n"," 83%|########3 | 288M/347M [02:45<00:28, 2.07MB/s]\n"," 83%|########3 | 289M/347M [02:45<00:26, 2.16MB/s]\n"," 83%|########3 | 289M/347M [02:45<00:26, 2.18MB/s]\n"," 84%|########3 | 290M/347M [02:45<00:30, 1.86MB/s]\n"," 84%|########3 | 291M/347M [02:46<00:21, 2.59MB/s]\n"," 84%|########3 | 292M/347M [02:46<00:19, 2.81MB/s]\n"," 84%|########4 | 292M/347M [02:46<00:21, 2.54MB/s]\n"," 84%|########4 | 293M/347M [02:47<00:29, 1.86MB/s]\n"," 84%|########4 | 293M/347M [02:47<00:36, 1.49MB/s]\n"," 85%|########4 | 294M/347M [02:47<00:25, 2.12MB/s]\n"," 85%|########4 | 295M/347M [02:48<00:30, 1.71MB/s]\n"," 85%|########5 | 296M/347M [02:48<00:20, 2.51MB/s]\n"," 85%|########5 | 296M/347M [02:48<00:21, 2.41MB/s]\n"," 85%|########5 | 297M/347M [02:49<00:24, 2.05MB/s]\n"," 86%|########5 | 297M/347M [02:49<00:22, 2.21MB/s]\n"," 86%|########5 | 298M/347M [02:49<00:19, 2.50MB/s]\n"," 86%|########5 | 298M/347M [02:49<00:23, 2.08MB/s]\n"," 86%|########6 | 299M/347M [02:50<00:31, 1.53MB/s]\n"," 86%|########6 | 299M/347M [02:50<00:30, 1.57MB/s]\n"," 86%|########6 | 300M/347M [02:50<00:25, 1.87MB/s]\n"," 87%|########6 | 300M/347M [02:51<00:28, 1.67MB/s]\n"," 87%|########6 | 301M/347M [02:51<00:28, 1.64MB/s]\n"," 87%|########6 | 301M/347M [02:51<00:30, 1.50MB/s]\n"," 87%|########6 | 302M/347M [02:52<00:26, 1.72MB/s]\n"," 87%|########7 | 303M/347M [02:52<00:25, 1.72MB/s]\n"," 87%|########7 | 303M/347M [02:52<00:24, 1.80MB/s]\n"," 87%|########7 | 304M/347M [02:53<00:30, 1.41MB/s]\n"," 88%|########7 | 304M/347M [02:53<00:23, 1.80MB/s]\n"," 88%|########7 | 305M/347M [02:53<00:23, 1.78MB/s]\n"," 88%|########7 | 305M/347M [02:53<00:23, 1.75MB/s]\n"," 88%|########8 | 306M/347M [02:54<00:22, 1.88MB/s]\n"," 88%|########8 | 306M/347M [02:54<00:25, 1.59MB/s]\n"," 88%|########8 | 307M/347M [02:55<00:33, 1.21MB/s]\n"," 89%|########8 | 307M/347M [02:55<00:25, 1.56MB/s]\n"," 89%|########8 | 308M/347M [02:55<00:29, 1.34MB/s]\n"," 89%|########8 | 308M/347M [02:56<00:25, 1.53MB/s]\n"," 89%|########8 | 309M/347M [02:56<00:25, 1.48MB/s]\n"," 89%|########9 | 309M/347M [02:56<00:26, 1.45MB/s]\n"," 89%|########9 | 310M/347M [02:57<00:22, 1.64MB/s]\n"," 89%|########9 | 310M/347M [02:57<00:28, 1.30MB/s]\n"," 90%|########9 | 311M/347M [02:57<00:22, 1.62MB/s]\n"," 90%|########9 | 311M/347M [02:58<00:23, 1.51MB/s]\n"," 90%|########9 | 312M/347M [02:58<00:24, 1.46MB/s]\n"," 90%|######### | 312M/347M [02:58<00:21, 1.60MB/s]\n"," 90%|######### | 313M/347M [02:59<00:23, 1.42MB/s]\n"," 90%|######### | 314M/347M [02:59<00:21, 1.60MB/s]\n"," 90%|######### | 314M/347M [02:59<00:19, 1.72MB/s]\n"," 91%|######### | 315M/347M [03:00<00:21, 1.51MB/s]\n"," 91%|######### | 315M/347M [03:00<00:22, 1.44MB/s]\n"," 91%|######### | 316M/347M [03:01<00:24, 1.26MB/s]\n"," 91%|#########1| 316M/347M [03:01<00:28, 1.10MB/s]\n"," 91%|#########1| 317M/347M [03:02<00:26, 1.17MB/s]\n"," 91%|#########1| 317M/347M [03:02<00:23, 1.26MB/s]\n"," 92%|#########1| 318M/347M [03:03<00:23, 1.26MB/s]\n"," 92%|#########1| 318M/347M [03:03<00:19, 1.52MB/s]\n"," 92%|#########1| 319M/347M [03:03<00:18, 1.57MB/s]\n"," 92%|#########1| 319M/347M [03:03<00:16, 1.73MB/s]\n"," 92%|#########2| 320M/347M [03:04<00:16, 1.65MB/s]\n"," 92%|#########2| 320M/347M [03:04<00:13, 1.99MB/s]\n"," 92%|#########2| 321M/347M [03:04<00:16, 1.63MB/s]\n"," 93%|#########2| 321M/347M [03:04<00:14, 1.72MB/s]\n"," 93%|#########2| 322M/347M [03:05<00:12, 1.97MB/s]\n"," 93%|#########3| 323M/347M [03:05<00:13, 1.78MB/s]\n"," 93%|#########3| 323M/347M [03:05<00:11, 2.02MB/s]\n"," 93%|#########3| 324M/347M [03:06<00:11, 2.09MB/s]\n"," 93%|#########3| 325M/347M [03:06<00:17, 1.31MB/s]\n"," 94%|#########3| 326M/347M [03:07<00:11, 1.84MB/s]\n"," 94%|#########3| 326M/347M [03:07<00:12, 1.67MB/s]\n"," 94%|#########4| 327M/347M [03:08<00:13, 1.56MB/s]\n"," 94%|#########4| 327M/347M [03:08<00:11, 1.74MB/s]\n"," 94%|#########4| 328M/347M [03:08<00:12, 1.60MB/s]\n"," 95%|#########4| 328M/347M [03:09<00:12, 1.49MB/s]\n"," 95%|#########4| 329M/347M [03:09<00:11, 1.65MB/s]\n"," 95%|#########4| 329M/347M [03:09<00:14, 1.22MB/s]\n"," 95%|#########5| 330M/347M [03:10<00:13, 1.33MB/s]\n"," 95%|#########5| 330M/347M [03:10<00:12, 1.31MB/s]\n"," 95%|#########5| 331M/347M [03:11<00:14, 1.11MB/s]\n"," 95%|#########5| 331M/347M [03:11<00:10, 1.44MB/s]\n"," 96%|#########5| 332M/347M [03:11<00:09, 1.54MB/s]\n"," 96%|#########5| 332M/347M [03:12<00:10, 1.36MB/s]\n"," 96%|#########5| 333M/347M [03:12<00:10, 1.40MB/s]\n"," 96%|#########6| 333M/347M [03:13<00:11, 1.19MB/s]\n"," 96%|#########6| 334M/347M [03:13<00:10, 1.31MB/s]\n"," 96%|#########6| 334M/347M [03:13<00:09, 1.40MB/s]\n"," 97%|#########6| 335M/347M [03:14<00:10, 1.18MB/s]\n"," 97%|#########6| 336M/347M [03:14<00:08, 1.30MB/s]\n"," 97%|#########6| 336M/347M [03:15<00:08, 1.29MB/s]\n"," 97%|#########6| 337M/347M [03:15<00:07, 1.40MB/s]\n"," 97%|#########7| 337M/347M [03:15<00:06, 1.43MB/s]\n"," 97%|#########7| 338M/347M [03:16<00:06, 1.55MB/s]\n"," 97%|#########7| 338M/347M [03:16<00:05, 1.73MB/s]\n"," 98%|#########7| 339M/347M [03:16<00:05, 1.66MB/s]\n"," 98%|#########7| 339M/347M [03:16<00:04, 1.76MB/s]\n"," 98%|#########7| 340M/347M [03:17<00:04, 1.70MB/s]\n"," 98%|#########8| 340M/347M [03:17<00:04, 1.44MB/s]\n"," 98%|#########8| 341M/347M [03:18<00:04, 1.49MB/s]\n"," 98%|#########8| 341M/347M [03:18<00:04, 1.37MB/s]\n"," 98%|#########8| 342M/347M [03:18<00:04, 1.27MB/s]\n"," 99%|#########8| 342M/347M [03:19<00:03, 1.39MB/s]\n"," 99%|#########8| 343M/347M [03:19<00:03, 1.36MB/s]\n"," 99%|#########8| 343M/347M [03:19<00:02, 1.52MB/s]\n"," 99%|#########9| 344M/347M [03:20<00:01, 1.79MB/s]\n"," 99%|#########9| 344M/347M [03:20<00:01, 1.94MB/s]\n"," 99%|#########9| 345M/347M [03:20<00:01, 1.93MB/s]\n","100%|#########9| 346M/347M [03:20<00:00, 2.06MB/s]\n","100%|#########9| 346M/347M [03:21<00:00, 2.15MB/s]\n","100%|#########9| 347M/347M [03:21<00:00, 1.99MB/s]\n","100%|#########9| 347M/347M [03:21<00:00, 1.96MB/s]\n","100%|##########| 347M/347M [03:21<00:00, 1.72MB/s]\n"]}],"source":["!gdown --id 1v9CBx_z-TwrCByZVhjzb7nxPTgEfRjIY\n","!gdown --id 14s4Efv9GoOcR1X-cyD-9a0xEKto2K95e"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sg0Y9lKVGXVY","outputId":"73b3d0a6-96af-4bfb-8669-d828a04f3cf4"},"outputs":[{"name":"stdout","output_type":"stream","text":[" Volume in drive D is New Volume\n"," Volume Serial Number is B471-4626\n","\n"," Directory of D:\\FypResearch\\Text Summarizer\\GANs\\version 1\n","\n","05/03/2022  12:15 AM    <DIR>          .\n","05/03/2022  12:15 AM    <DIR>          ..\n","05/03/2022  12:09 AM    <DIR>          .ipynb_checkpoints\n","05/03/2022  12:15 AM       347,116,733 glove.6B.100d.txt\n","05/03/2022  12:15 AM           134,020 Transformer_and_GAN_based_Summarizer.ipynb\n","05/03/2022  12:12 AM       397,955,275 wikiHowCleanedData.csv\n","               3 File(s)    745,206,028 bytes\n","               3 Dir(s)  271,091,544,064 bytes free\n"]}],"source":["ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tJ9GIbB3O7Ns"},"outputs":[],"source":["wikiHowCleanedDF = pd.read_csv(\"wikiHowCleanedData.csv\")"]},{"cell_type":"markdown","metadata":{"id":"NhCmxtmiw-A1"},"source":["# Data Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p0zEmtLTxE1_"},"outputs":[],"source":["# changing the Datatype of datapoints in Dataset to String \n","wikiHowCleanedDF.cleaned_text=wikiHowCleanedDF.cleaned_text.astype(str)\n","wikiHowCleanedDF.cleaned_summary=wikiHowCleanedDF.cleaned_summary.astype(str)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LM7gjJPOxJ2h"},"outputs":[],"source":["# creating new column with amount of word contain in text source and summary\n","wikiHowCleanedDF['cleaned_text_word_count'] = wikiHowCleanedDF[['cleaned_text']].apply(lambda x: len(x[0].split(' ')), axis=1)\n","wikiHowCleanedDF['cleaned_summary_word_count'] = wikiHowCleanedDF[['cleaned_summary']].apply(lambda x: len(x[0].split(' ')), axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5aQAuh1JxPr0","outputId":"8755f998-5bb2-47f6-8033-f443eaf1d524"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>cleaned_text</th>\n","      <th>cleaned_summary</th>\n","      <th>cleaned_text_word_count</th>\n","      <th>cleaned_summary_word_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>photographer keep necessary lens cords batteri...</td>\n","      <td>&lt;go&gt; keep related supplies in the same area ma...</td>\n","      <td>332</td>\n","      <td>85</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>see image drawing develops step step however i...</td>\n","      <td>&lt;go&gt; create sketch in the neopoprealist manner...</td>\n","      <td>342</td>\n","      <td>129</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>possible become vfx artist without college deg...</td>\n","      <td>&lt;go&gt; get bachelor degree enroll in studio base...</td>\n","      <td>250</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>best art investors research pieces art buy som...</td>\n","      <td>&lt;go&gt; start with some experience or interest in...</td>\n","      <td>468</td>\n","      <td>125</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>start planning project work likely gathering s...</td>\n","      <td>&lt;go&gt; keep your reference materials sketches ar...</td>\n","      <td>233</td>\n","      <td>63</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0                                       cleaned_text  \\\n","0           0  photographer keep necessary lens cords batteri...   \n","1           1  see image drawing develops step step however i...   \n","2           2  possible become vfx artist without college deg...   \n","3           3  best art investors research pieces art buy som...   \n","4           4  start planning project work likely gathering s...   \n","\n","                                     cleaned_summary  cleaned_text_word_count  \\\n","0  <go> keep related supplies in the same area ma...                      332   \n","1  <go> create sketch in the neopoprealist manner...                      342   \n","2  <go> get bachelor degree enroll in studio base...                      250   \n","3  <go> start with some experience or interest in...                      468   \n","4  <go> keep your reference materials sketches ar...                      233   \n","\n","   cleaned_summary_word_count  \n","0                          85  \n","1                         129  \n","2                          37  \n","3                         125  \n","4                          63  "]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["wikiHowCleanedDF.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H5HFd7-fxMQ5"},"outputs":[],"source":["# Droping the rows that containing more words in summary than the Document \n","wikiHowCleanedDF.drop(wikiHowCleanedDF[wikiHowCleanedDF['cleaned_text_word_count'] < wikiHowCleanedDF['cleaned_summary_word_count']].index, inplace = True)"]},{"cell_type":"markdown","metadata":{"id":"ndUaHprIxTXt"},"source":["# Train/Test split preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6T0B-AkZxfU1"},"outputs":[],"source":["#spliting the data in to train and test sets \n","document,document_test,summary,summary_test= train_test_split(\n","    wikiHowCleanedDF['cleaned_text'],\n","    wikiHowCleanedDF['cleaned_summary'],\n","    test_size=0.004,random_state=0,\n","    shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z52XQRK_xsTi","outputId":"67f16554-90a1-4194-9eeb-9dfccf76d8d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Traning Document Shape : (168155,)\n","Traning summary Shape : (168155,)\n","\n","Testing Document Shape : (676,)\n","Testing summary Shape : (676,)\n"]}],"source":["print(\"Traning Document Shape : \"+str(document.shape))\n","print(\"Traning summary Shape : \"+str(summary.shape))\n","\n","print()\n","\n","print(\"Testing Document Shape : \"+str(document_test.shape))\n","print(\"Testing summary Shape : \"+str(summary_test.shape))"]},{"cell_type":"markdown","metadata":{"id":"Gs7nhAI4yXs8"},"source":["# Dataset Pipeline "]},{"cell_type":"markdown","metadata":{"id":"v1kaVWWNzbD5"},"source":["## Tokenization "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SzDRmG0Vymk0"},"outputs":[],"source":["filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n","oov_token = '<unk>'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ubjoyGndyrH8"},"outputs":[],"source":["document_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=oov_token)\n","summary_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)\n","\n","document_tokenizer.fit_on_texts(document)\n","summary_tokenizer.fit_on_texts(summary)\n","\n","inputs = document_tokenizer.texts_to_sequences(document)\n","targets = summary_tokenizer.texts_to_sequences(summary)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m9ltTQsGyyGM","outputId":"7a122b71-6203-43df-bafc-72e0715ee3f3"},"outputs":[{"data":{"text/plain":["(149619, 62456)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["encoder_vocab_size = len(document_tokenizer.word_index) + 1\n","decoder_vocab_size = len(summary_tokenizer.word_index) + 1\n","\n","# vocab_size\n","encoder_vocab_size, decoder_vocab_size"]},{"cell_type":"markdown","metadata":{"id":"OckZxkZRzdd6"},"source":["## maxlen insights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f4OPE4eQzlzU"},"outputs":[],"source":["document_lengths = pd.Series([len(x.split(' ')) for x in document])\n","summary_lengths = pd.Series([len(x.split(' ')) for x in summary])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RyFrgbXEzsnA","outputId":"e4a13e95-6f16-4ebf-95ba-28d2fe2859bf"},"outputs":[{"data":{"text/plain":["count    168155.000000\n","mean        269.082305\n","std         247.776334\n","min           5.000000\n","25%         117.000000\n","50%         189.000000\n","75%         319.000000\n","max        6505.000000\n","dtype: float64"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["document_lengths.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MiPHmGM4zuJs","outputId":"7be785ff-0918-4007-caff-377a79d42637"},"outputs":[{"data":{"text/plain":["count    168155.000000\n","mean         51.753275\n","std          43.066821\n","min           4.000000\n","25%          25.000000\n","50%          39.000000\n","75%          66.000000\n","max        3782.000000\n","dtype: float64"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["summary_lengths.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_n8yi0OAz2Tt"},"outputs":[],"source":["encoder_maxlen = 400\n","decoder_maxlen = 100"]},{"cell_type":"markdown","metadata":{"id":"Hwi6J4_Jz7it"},"source":["## Padding/Truncating sequences"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bmnzQH9mz-81"},"outputs":[],"source":["inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=encoder_maxlen, padding='post', truncating='post')\n","targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=decoder_maxlen, padding='post', truncating='post')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QTZsAQS50A4G","outputId":"42be3369-5907-4f2d-b638-dc153880c75b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input Data Shape : (168155, 400)\n","Output Data Shape : (168155, 100)\n"]}],"source":["print(\"Input Data Shape : \"+str(inputs.shape))\n","print(\"Output Data Shape : \"+str(targets.shape))"]},{"cell_type":"markdown","metadata":{"id":"3qleZo790alE"},"source":["## dataset pipeline Creation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f45FmCNy0gWI"},"outputs":[],"source":["# casting datatype to int32 \n","inputs = tf.cast(inputs, dtype=tf.int32)\n","targets = tf.cast(targets, dtype=tf.int32)\n","\n","BUFFER_SIZE = 20000\n","BATCH_SIZE = 64"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FbK1mpqY0mOM"},"outputs":[],"source":["# tensorflow Dataset API provide effecient way to do data manipulations when traning the model \n","train_dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"]},{"cell_type":"markdown","metadata":{"id":"HaeAqWpVO78X"},"source":["# The Generator"]},{"cell_type":"markdown","metadata":{"id":"KOSqCxJtPFsP"},"source":["## Positional Encoding Layer \n"]},{"cell_type":"markdown","metadata":{"id":"cab6AH2hH5VJ"},"source":["for adding notion of position among words as unlike RNN this is non-directional"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4JMKRmTHO9H_"},"outputs":[],"source":["def get_angles(position, i, d_model):\n","    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n","    return position * angle_rates"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K99J1FavPB2Z"},"outputs":[],"source":["def positional_encoding(position, d_model):\n","    angle_rads = get_angles(\n","        np.arange(position)[:, np.newaxis],\n","        np.arange(d_model)[np.newaxis, :],\n","        d_model\n","    )\n","\n","    # apply sin to even indices in the array; 2i\n","    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","\n","    # apply cos to odd indices in the array; 2i+1\n","    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","\n","    pos_encoding = angle_rads[np.newaxis, ...]\n","\n","    return tf.cast(pos_encoding, dtype=tf.float32)"]},{"cell_type":"markdown","metadata":{"id":"gG-RpvO_HwNw"},"source":["## Masking Layers"]},{"cell_type":"markdown","metadata":{"id":"KBNlhkJfPPHg"},"source":["- Padding mask for masking \"pad\" sequences.\n","- Lookahead mask for masking future words from contributing in prediction of current words in self attention."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gnY5pegZPYtb"},"outputs":[],"source":["def create_padding_mask(seq):\n","    # add extra dimensions to add the padding\n","    # to the attention logits.\n","    seq = tf.cast(tf.math.equal(seq, 1), tf.float32)\n","    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7JeMdLpXPdBg"},"outputs":[],"source":["def create_look_ahead_mask(size):\n","    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n","    return mask # (seq_len, seq_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1uLuyGvOPe5I"},"outputs":[],"source":["def create_masks(inp, tar):\n","    \n","    # Encoder padding mask\n","    enc_padding_mask = create_padding_mask(inp)\n","    \n","    # Used in the 2nd attention block in the decoder.\n","    # This padding mask is used to mask the encoder outputs.\n","    dec_padding_mask = create_padding_mask(inp)\n","\n","    # Used in the 1st attention block in the decoder.\n","    # It is used to pad and mask future tokens in the input received by the decoder.\n","    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n","    dec_target_padding_mask = create_padding_mask(tar)\n","    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n","  \n","    return enc_padding_mask, combined_mask, dec_padding_mask"]},{"cell_type":"markdown","metadata":{"id":"db_KhInXHis4"},"source":["## Attention Layers"]},{"cell_type":"markdown","metadata":{"id":"QOP7xPYgHzks"},"source":["### Scaled Dot Product"]},{"cell_type":"markdown","metadata":{"id":"t_hJjK7DPhf8"},"source":["- Calculate the attention weights.\n","\n","- q, k, v must have matching leading dimensions.\n","\n","- k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n","\n","- The mask has different shapes depending on its type(padding or look ahead) but it must be broadcastable for addition.\n","\n","Args:\n","\n","- q: query shape == (..., seq_len_q, depth) \n","- k: key shape == (..., seq_len_k, depth) \n","- v: value shape == (..., seq_len_v, depth_v) \n","\n","mask: Float tensor with shape broadcastable \n","      to (..., seq_len_q, seq_len_k). Defaults to None.\n","\n","Returns:\n","output, attention_weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yB91CtfMPiws"},"outputs":[],"source":["def scaled_dot_product_attention(q, k, v, mask):\n","    \n","    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n","\n","    # scale matmul_qk\n","    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","\n","    # add the mask to the scaled tensor.\n","    if mask is not None:\n","        scaled_attention_logits += (mask * -1e9)  \n","\n","    # softmax is normalized on the last axis (seq_len_k) so that the scoresadd up to 1.\n","    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1) # (..., seq_len_q, seq_len_k)\n","\n","    output = tf.matmul(attention_weights, v)# (..., seq_len_q, depth_v)\n","    \n","    return output, attention_weights"]},{"cell_type":"markdown","metadata":{"id":"QmKta7gZPl5k"},"source":["### Multi-Headed Attention"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_wnSk1wXPpR7"},"outputs":[],"source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        assert d_model % self.num_heads == 0\n","\n","        self.depth = d_model // self.num_heads\n","\n","        self.wq = tf.keras.layers.Dense(d_model) \n","        self.wk = tf.keras.layers.Dense(d_model) \n","        self.wv = tf.keras.layers.Dense(d_model) \n","\n","        self.dense = tf.keras.layers.Dense(d_model)\n","        \n","    def split_heads(self, x, batch_size):\n","        \n","        \"\"\"Split the last dimension into (num_heads, depth).\n","        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\"\"\"\n","        \n","        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(x, perm=[0, 2, 1, 3])\n","    \n","    def call(self, v, k, q, mask):\n","        batch_size = tf.shape(q)[0]\n","\n","        q = self.wq(q) # (batch_size, seq_len, d_model)\n","        k = self.wk(k) # (batch_size, seq_len, d_model)\n","        v = self.wv(v) # (batch_size, seq_len, d_model)\n","\n","        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n","        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n","        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n","\n","        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n","        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n","        scaled_attention, attention_weights = scaled_dot_product_attention(\n","            q, k, v, mask) # (batch_size, seq_len_q, num_heads, depth)\n","\n","        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","\n","        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model)) # (batch_size, seq_len_q, d_model)\n","        output = self.dense(concat_attention) # (batch_size, seq_len_q, d_model)\n","            \n","        return output, attention_weights"]},{"cell_type":"markdown","metadata":{"id":"ZVjC0-8SIUel"},"source":["## Final distribution"]},{"cell_type":"markdown","metadata":{"id":"uNBEk0lXIYpk"},"source":["Calculate the final distribution, for the pointer-generator model\n","\n","Args:\n","\n","- vocab_dists: The vocabulary distributions. List length max_dec_steps of (batch_size, vsize) arrays. The words are in the order they appear in the vocabulary file.\n","\n","- attn_dists: The attention distributions. List length max_dec_steps of (batch_size, attn_len) arrays\n","\n","Returns:\n","\n","- final_dists: The final distributions. List length max_dec_steps of (batch_size, extended_vsize) arrays."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LBMzGC-6IV3V"},"outputs":[],"source":["def _calc_final_dist( _enc_batch_extend_vocab, vocab_dists, attn_dists, p_gens, batch_oov_len, vocab_size, batch_size):\n","\n","    # Multiply vocab dists by p_gen and attention dists by (1-p_gen)\n","    vocab_dists = [p_gen * dist for (p_gen,dist) in zip(p_gens, vocab_dists)]\n","    attn_dists = [(1-p_gen) * dist for (p_gen,dist) in zip(p_gens, attn_dists)]\n","\n","    # Concatenate some zeros to each vocabulary dist, to hold the probabilities for in-article OOV words\n","    extended_vsize = vocab_size + batch_oov_len # the maximum (over the batch) size of the extended vocabulary\n","    extra_zeros = tf.zeros((batch_size, batch_oov_len ))\n","    vocab_dists_extended = [tf.concat(axis=1, values=[dist, extra_zeros]) for dist in vocab_dists] # list length max_dec_steps of shape (batch_size, extended_vsize)\n","\n","    # Project the values in the attention distributions onto the appropriate entries in the final distributions\n","    \n","    # This means that if a_i = 0.1 and the ith encoder word is w, and w has index 500 in the vocabulary, then we add 0.1 onto the 500th entry of the final distribution\n","    # This is done for each decoder timestep.\n","    # This is fiddly; we use tf.scatter_nd to do the projection\n","    \n","    batch_nums = tf.range(0, limit=batch_size) # shape (batch_size)\n","    batch_nums = tf.expand_dims(batch_nums, 1) # shape (batch_size, 1)\n","    attn_len = tf.shape(_enc_batch_extend_vocab)[1] # number of states we attend over\n","    batch_nums = tf.tile(batch_nums, [1, attn_len]) # shape (batch_size, attn_len)\n","    indices = tf.stack( (batch_nums, _enc_batch_extend_vocab), axis=2) # shape (batch_size, enc_t, 2)\n","    shape = [batch_size, extended_vsize]\n","    attn_dists_projected = [tf.scatter_nd(indices, copy_dist, shape) for copy_dist in attn_dists] # list length max_dec_steps (batch_size, extended_vsize)\n","\n","    # Add the vocab distributions and the copy distributions together to get the final distributions\n","    \n","    # final_dists is a list length max_dec_steps; each entry is a tensor shape (batch_size, extended_vsize) giving the final distribution for that decoder timestep\n","    # Note that for decoder timesteps and examples corresponding to a [PAD] token, this is junk - ignore.\n","    final_dists = [vocab_dist + copy_dist for (vocab_dist,copy_dist) in zip(vocab_dists_extended, attn_dists_projected)]\n","\n","    return final_dists"]},{"cell_type":"markdown","metadata":{"id":"xrgAPieOPrUr"},"source":["## Feed Forward Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AYNbEKDVPui3"},"outputs":[],"source":["def point_wise_feed_forward_network(d_model, dff):\n","    return tf.keras.Sequential([\n","        tf.keras.layers.Dense(dff, activation='relu'),# (batch_size, seq_len, dff)\n","        tf.keras.layers.Dense(d_model)# (batch_size, seq_len, d_model)\n","    ])"]},{"cell_type":"markdown","metadata":{"id":"UXGF8mfRIw9Z"},"source":["## Embedding Layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_lDFSOiHIyiE"},"outputs":[],"source":["class Embedding(tf.keras.layers.Layer):\n","\n","    def __init__(self, vocab_size, d_model):\n","        super(Embedding, self).__init__()\n","        self.vocab_size = vocab_size\n","        self.d_model = d_model\n","\n","        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model)\n","        self.pos_encoding = positional_encoding(vocab_size, d_model)\n","\n","    def call(self, x):\n","        \n","        embed_x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n","        embed_x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        embed_x += self.pos_encoding[:, :tf.shape(x)[1], :]\n","        \n","        return embed_x"]},{"cell_type":"markdown","metadata":{"id":"qqlQHWLPPwlD"},"source":["## Transformer Model"]},{"cell_type":"markdown","metadata":{"id":"xbYM3EJLP_1U"},"source":["### Fundamental Unit of Transformer encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xlbIPpo1P4kv"},"outputs":[],"source":["class EncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(EncoderLayer, self).__init__()\n","\n","        self.mha = MultiHeadAttention(d_model, num_heads)\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","    \n","    def call(self, x, training, mask):\n","        attn_output, _ = self.mha(x, x, x, mask) # (batch_size, input_seq_len, d_model)\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(x + attn_output) # (batch_size, input_seq_len, d_model)\n","\n","        ffn_output = self.ffn(out1)# (batch_size, input_seq_len, d_model)\n","        ffn_output = self.dropout2(ffn_output, training=training)\n","        out2 = self.layernorm2(out1 + ffn_output)# (batch_size, input_seq_len, d_model)\n","\n","        return out2"]},{"cell_type":"markdown","metadata":{"id":"GQ0GmK3aQKxz"},"source":["### Fundamental Unit of Transformer decoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gMBHNdGzQNoB"},"outputs":[],"source":["class DecoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_heads, dff, rate=0.1):\n","        super(DecoderLayer, self).__init__()\n","\n","        self.mha1 = MultiHeadAttention(d_model, num_heads)\n","        self.mha2 = MultiHeadAttention(d_model, num_heads)\n","\n","        self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","        self.dropout2 = tf.keras.layers.Dropout(rate)\n","        self.dropout3 = tf.keras.layers.Dropout(rate)\n","    \n","    \n","    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n","        \n","        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask) # (batch_size, target_seq_len, d_model)\n","        attn1 = self.dropout1(attn1, training=training)\n","        out1 = self.layernorm1(attn1 + x)\n","\n","        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask) # (batch_size, target_seq_len, d_model)\n","        attn2 = self.dropout2(attn2, training=training)\n","        out2 = self.layernorm2(attn2 + out1)# (batch_size, target_seq_len, d_model)\n","\n","        ffn_output = self.ffn(out2)# (batch_size, target_seq_len, d_model)\n","        ffn_output = self.dropout3(ffn_output, training=training)\n","        out3 = self.layernorm3(ffn_output + out2)# (batch_size, target_seq_len, d_model)\n","\n","        return out3, attn_weights_block1, attn_weights_block2"]},{"cell_type":"markdown","metadata":{"id":"ETZrjq-sQP2z"},"source":["### Encoder consisting of multiple EncoderLayer(s)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hPRcqgyyQRc3"},"outputs":[],"source":["class Encoder(tf.keras.layers.Layer):\n","    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, rate=0.1):\n","        super(Encoder, self).__init__()\n","\n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","\n","        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","        self.dropout = tf.keras.layers.Dropout(rate)\n","        \n","    def call(self, x, training, mask):\n","        x = self.dropout(x, training=training)\n","    \n","        for i in range(self.num_layers):\n","            x = self.enc_layers[i](x, training, mask)\n","    \n","        return x # (batch_size, input_seq_len, d_model)"]},{"cell_type":"markdown","metadata":{"id":"tQ8DT0C4QTnv"},"source":["### Decoder consisting of multiple DecoderLayer(s)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3YECNdN4QV-X"},"outputs":[],"source":["class Decoder(tf.keras.layers.Layer):\n","    \n","    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, rate=0.1):\n","        super(Decoder, self).__init__()\n","        \n","        self.d_model = d_model\n","        self.num_layers = num_layers\n","        self.num_heads = num_heads\n","        self.depth = d_model // self.num_heads\n","        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n","        \n","        self.dropout = tf.keras.layers.Dropout(rate)\n","        \n","        self.Wh = tf.keras.layers.Dense(1)\n","        self.Ws = tf.keras.layers.Dense(1)\n","        self.Wx = tf.keras.layers.Dense(1)\n","        self.V = tf.keras.layers.Dense(1)\n","\n","\n","    def call(self, embed_x, enc_output, training, look_ahead_mask, padding_mask):\n","\n","        attention_weights = {}\n","        out = self.dropout(embed_x, training=training)\n","\n","        for i in range(self.num_layers):\n","            \n","            out, block1, block2 = self.dec_layers[i](out, enc_output, training,look_ahead_mask, padding_mask)\n","\n","            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n","            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n","\n","        # out.shape == (batch_size, target_seq_len, d_model)\n","\n","        #context vectors\n","        enc_out_shape = tf.shape(enc_output)\n","        context = tf.reshape(enc_output,(enc_out_shape[0], enc_out_shape[1], self.num_heads, self.depth) ) # shape : (batch_size, input_seq_len, num_heads, depth)\n","        context = tf.transpose(context, [0,2,1,3]) # (batch_size, num_heads, input_seq_len, depth)\n","        context = tf.expand_dims(context, axis=2)  # (batch_size, num_heads, 1, input_seq_len, depth)\n","\n","        attn = tf.expand_dims(block2, axis=-1)  # (batch_size, num_heads, target_seq_len, input_seq_len, 1)\n","\n","        context = context * attn # (batch_size, num_heads, target_seq_len, input_seq_len, depth)\n","        context = tf.reduce_sum(context, axis=3) # (batch_size, num_heads, target_seq_len, depth)\n","        context = tf.transpose(context, [0,2,1,3]) # (batch_size, target_seq_len, num_heads, depth)\n","        context = tf.reshape(context, (tf.shape(context)[0], tf.shape(context)[1], self.d_model)) # (batch_size, target_seq_len, d_model)\n","\n","        # P_gens computing\n","        a = self.Wx(embed_x)\n","        b = self.Ws(out)\n","        c = self.Wh(context)\n","        p_gens = tf.sigmoid(self.V(a + b + c))\n","\n","        return out, attention_weights,  p_gens"]},{"cell_type":"markdown","metadata":{"id":"u6mEQ-wYQavc"},"source":["### Transformer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vrY86QqfQZwX"},"outputs":[],"source":["class Transformer(tf.keras.Model):\n","    def __init__(self, num_layers, d_model, num_heads, dff, vocab_size,batch_size, rate=0.1):\n","        super(Transformer, self).__init__()\n","\n","        self.num_layers =num_layers\n","        self.vocab_size = vocab_size\n","        self.batch_size = batch_size\n","        self.model_depth = d_model\n","        self.num_heads = num_heads\n","\n","        self.embedding = Embedding(vocab_size, d_model)\n","        self.encoder = Encoder(num_layers, d_model, num_heads, dff, vocab_size, rate)\n","        self.decoder = Decoder(num_layers, d_model, num_heads, dff, vocab_size, rate)\n","        self.final_layer = tf.keras.layers.Dense(vocab_size)\n","\n","\n","    def call(self, inp, extended_inp,max_oov_len, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n","\n","        embed_x = self.embedding(inp)\n","        embed_dec = self.embedding(tar)\n","\n","        enc_output = self.encoder(embed_x, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n","\n","        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n","        dec_output, attention_weights, p_gens = self.decoder(embed_dec, enc_output, training, look_ahead_mask, dec_padding_mask)\n","\n","        output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n","        output = tf.nn.softmax(output) # (batch_size, tar_seq_len, vocab_size)\n","        #output = tf.concat([output, tf.zeros((tf.shape(output)[0], tf.shape(output)[1], max_oov_len))], axis=-1) # (batch_size, targ_seq_len, vocab_size+max_oov_len)\n","\n","        attn_dists = attention_weights['decoder_layer{}_block2'.format(self.num_layers)] # (batch_size,num_heads, targ_seq_len, inp_seq_len)\n","        attn_dists = tf.reduce_sum(attn_dists, axis=1)/self.num_heads # (batch_size, targ_seq_len, inp_seq_len)\n","\n","        final_dists =  _calc_final_dist( extended_inp, tf.unstack(output, axis=1) , tf.unstack(attn_dists, axis=1), tf.unstack(p_gens, axis=1), max_oov_len, self.vocab_size, self.batch_size)\n","        final_output =tf.stack(final_dists, axis=1)\n","\n","        return final_output, dec_output, attention_weights"]},{"cell_type":"markdown","metadata":{"id":"gELmOIzvRGBT"},"source":["### Initiating Transformer Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_EkfSfPO4t9"},"outputs":[],"source":["num_layers = 4\n","d_model = 128\n","dff = 512\n","num_heads = 8\n","encoder_vocab_size = 149619\n","decoder_vocab_size = 62456"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ctYFAhmO6tX"},"outputs":[],"source":["transformer = Transformer( num_layers=num_layers, d_model=d_model, num_heads=num_heads, dff=dff, \n","                          input_vocab_size = encoder_vocab_size, target_vocab_size = decoder_vocab_size, \n","                          pe_input=encoder_vocab_size,pe_target=decoder_vocab_size)"]},{"cell_type":"markdown","metadata":{"id":"eBSJ2qN7Rmkv"},"source":["# The Discriminator"]},{"cell_type":"markdown","metadata":{"id":"nh2OPhippZAE"},"source":["## Word Embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DQM6nB4Mpjgx","outputId":"0fc98568-65a4-4319-be0b-935658322fef"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 400000 word vectors\n"]}],"source":["embeddings_index = dict()\n","f = open('glove.6B.100d.txt', encoding='utf8')\n","for line in f:\n","    values = line.split()\n","    embeddings_index[values[0]]= np.asarray(values[1:],dtype='float32')\n","f.close()\n","print(f'Found {len(embeddings_index)} word vectors')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D5t39r3eoVDZ"},"outputs":[],"source":["embedding_dim = decoder_maxlen\n","embedding_matrix= np.zeros((decoder_vocab_size,embedding_dim))\n","for word, index in summary_tokenizer.word_index.items():\n","  embedding_vector = embeddings_index.get(word)\n","  if embedding_vector is not None:\n","    embedding_matrix[index]= embedding_vector"]},{"cell_type":"markdown","metadata":{"id":"YW31T4uwpdDF"},"source":["## Discriminator Model"]},{"cell_type":"markdown","metadata":{"id":"-zLcDZwRw9Br"},"source":["\"\"\"\n","    A CNN for text classification.\n","    Uses an embedding layer, followed by a convolutional, max-pooling and softmax layer.\n","    \"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ZARX8iwRrS0"},"outputs":[],"source":["def make_discriminator_model():\n","  model = tf.keras.Sequential()\n","  model.add(layers.Embedding(decoder_vocab_size,\n","                    embedding_dim,\n","                    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n","                    trainable=False))\n","  model.add(layers.Dropout(0.2))\n","  model.add(layers.Conv1D(filters=250,kernel_size=5,padding='valid',activation='elu'))\n","  model.add(layers.MaxPooling1D())\n","  model.add(layers.Conv1D(filters=250,kernel_size=3,padding='valid',activation='elu'))\n","  model.add(layers.GlobalMaxPooling1D())\n","  model.add(layers.Dense(units=250, activation='elu'))\n","  model.add(layers.Dropout(0.2))\n","  model.add(layers.Dense(1, activation='sigmoid'))\n","\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KUYswIEHq2FR","outputId":"7364c9e7-5487-4e61-e436-b57d69cb14fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_2 (Embedding)     (None, None, 100)         6245600   \n","                                                                 \n"," dropout_22 (Dropout)        (None, None, 100)         0         \n","                                                                 \n"," conv1d (Conv1D)             (None, None, 250)         125250    \n","                                                                 \n"," max_pooling1d (MaxPooling1D  (None, None, 250)        0         \n"," )                                                               \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, None, 250)         187750    \n","                                                                 \n"," global_max_pooling1d (Globa  (None, 250)              0         \n"," lMaxPooling1D)                                                  \n","                                                                 \n"," dense_65 (Dense)            (None, 250)               62750     \n","                                                                 \n"," dropout_23 (Dropout)        (None, 250)               0         \n","                                                                 \n"," dense_66 (Dense)            (None, 1)                 251       \n","                                                                 \n","=================================================================\n","Total params: 6,621,601\n","Trainable params: 376,001\n","Non-trainable params: 6,245,600\n","_________________________________________________________________\n"]}],"source":["discriminator = make_discriminator_model()\n","discriminator.summary()"]},{"cell_type":"markdown","metadata":{"id":"DPoVsJ7-QgeU"},"source":["# Loss and Otimizers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"weXWR_6DfLpz"},"outputs":[],"source":["generatorLoss = tf.keras.metrics.Mean(name='generatorLoss')\n","discriminatorLoss = tf.keras.metrics.Mean(name='discriminatorLoss')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l8P818ybLXJ1"},"outputs":[],"source":["# This method returns a helper function to compute cross entropy loss\n","binary_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","sparse_cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"]},{"cell_type":"markdown","metadata":{"id":"Oe9xQdZqLpLH"},"source":["## Discriminator loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A1DqCmwwLqnM"},"outputs":[],"source":["def discriminator_loss(real_output, fake_output):\n","\n","    real_loss = binary_cross_entropy(tf.ones_like(real_output), real_output)\n","    fake_loss = binary_cross_entropy(tf.zeros_like(fake_output), fake_output)\n","    total_loss = real_loss + fake_loss\n","    \n","    return total_loss"]},{"cell_type":"markdown","metadata":{"id":"Yey4Flx8L2uP"},"source":["## Generator loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lrtjHFTFMOq9"},"outputs":[],"source":["def generator_loss(real, pred):\n","  \n","    mask = tf.math.logical_not(tf.math.equal(real, 0))\n","    loss_ = sparse_cross_entropy(real, pred)\n","\n","    mask = tf.cast(mask, dtype=loss_.dtype)\n","    loss_ *= mask\n","\n","    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"]},{"cell_type":"markdown","metadata":{"id":"S5wYOa4_MeMM"},"source":["## Optimizers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"emLFxxkgMlTM"},"outputs":[],"source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    def __init__(self, d_model, warmup_steps=4000):\n","        super(CustomSchedule, self).__init__()\n","\n","        self.d_model = d_model\n","        self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","        self.warmup_steps = warmup_steps\n","    \n","    def __call__(self, step):\n","        arg1 = tf.math.rsqrt(step)\n","        arg2 = step * (self.warmup_steps ** -1.5)\n","\n","        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8rWyDtolMp6I"},"outputs":[],"source":["learning_rate = CustomSchedule(d_model)\n","generator_optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"]},{"cell_type":"markdown","metadata":{"id":"f7IJVB_RNAlc"},"source":["# Save checkpoints"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5LkiYyLkNBvk"},"outputs":[],"source":["checkpoint_dir = 'checkpoints'\n","\n","ckpt = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n","                                 discriminator_optimizer=discriminator_optimizer,\n","                                 generator=transformer,\n","                                 discriminator=discriminator)\n","\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_dir, max_to_keep=5)\n","\n","if ckpt_manager.latest_checkpoint:\n","    ckpt.restore(ckpt_manager.latest_checkpoint)\n","    print ('Latest checkpoint restored!!')"]},{"cell_type":"markdown","metadata":{"id":"iroDOd43P_UQ"},"source":["# Training"]},{"cell_type":"markdown","metadata":{"id":"TXV3-exjNpjO"},"source":["## Define the training loop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"McbqF7Q7NvmA"},"outputs":[],"source":["# Notice the use of `tf.function`\n","# This annotation causes the function to be \"compiled\".\n","@tf.function\n","def train_step(inp, tar):\n","\n","    tar_inp = tar[:, :-1]\n","    tar_real = tar[:, 1:]\n","    \n","    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n","\n","    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n","      \n","      predictions, _ = transformer(\n","            inp, tar_inp, \n","            True, \n","            enc_padding_mask, \n","            combined_mask, \n","            dec_padding_mask\n","        )\n","      \n","      predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n","     \n","\n","      real_output = discriminator(tar_real, training=True)\n","      fake_output = discriminator(predicted_id, training=True)\n","\n","      gen_loss = generator_loss(tar_real, predictions)\n","      disc_loss = discriminator_loss(real_output, fake_output)\n","\n","    gradients_of_generator = gen_tape.gradient(gen_loss, transformer.trainable_variables)\n","    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n","\n","    generator_optimizer.apply_gradients(zip(gradients_of_generator, transformer.trainable_variables))\n","    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n","\n","    generatorLoss(gen_loss)\n","    discriminatorLoss(disc_loss)"]},{"cell_type":"markdown","metadata":{"id":"lMi4A917Py_o"},"source":["## Training the Model "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LfiCmK0AQEOw"},"outputs":[],"source":["EPOCHS = 100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K1KTN8C5GXVl"},"outputs":[],"source":["column_names = ['Epoch','Time', 'Generator_Loss','Discriminator_Loss']\n","training_Report = pd.DataFrame(columns = column_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bKrK77bfQJYE"},"outputs":[],"source":["def train(dataset, epochs,report):\n","\n","  for epoch in range(epochs):\n","      start = time.time()\n","\n","      for (batch, (inp, tar)) in enumerate(dataset):\n","          train_step(inp, tar)\n","      \n","          # 151947 samples\n","          # we display 3 batch results -- 0th, middle and last one (approx)\n","          # 151947 / 128 (batch size) ~ 1,187; 1,187 / 2 = 593\n","          \n","          if batch % 593 == 0:\n","              print ('Epoch {} Batch {} generator Loss {:.4f} discriminator Loss {:.4f}'.format(epoch + 1, batch, generatorLoss.result(),discriminatorLoss.result()))\n","\n","      if (epoch + 1) % 5 == 0:\n","          ckpt_save_path = ckpt_manager.save()\n","          print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n","      \n","      print ('Epoch {} generator Loss {:.4f} discriminator Loss {:.4f}'.format(epoch + 1, generatorLoss.result(),discriminatorLoss.result()))\n","\n","      update_row = {\n","            'Epoch':epoch + 1 ,\n","            'Time': time.time() - start,\n","            'Generator_Loss':generatorLoss.result() ,\n","            'Discriminator_Loss':discriminatorLoss.result() ,}\n","      \n","      row_to_add = pd.Series(update_row,name= str(epoch))\n","      report = report.append(row_to_add)\n","\n","      print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n","\n","  return report  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8O7hx5DiQe9b","outputId":"d5b3ccd0-9ef2-4269-f0f4-0c10ee65cc19"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\anaconda3\\envs\\summarization_v2\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n","  return dispatch_target(*args, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1 Batch 0 generator Loss 11.0375 discriminator Loss 1.4698\n","Epoch 1 Batch 593 generator Loss 8.8808 discriminator Loss 0.1764\n","Epoch 1 Batch 1186 generator Loss 7.7323 discriminator Loss 0.0917\n","Epoch 1 Batch 1779 generator Loss 7.1403 discriminator Loss 0.0641\n","Epoch 1 Batch 2372 generator Loss 6.7674 discriminator Loss 0.0536\n","Epoch 1 generator Loss 6.6430 discriminator Loss 0.0510\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Time taken for 1 epoch: 881.8595037460327 secs\n","\n","Epoch 2 Batch 0 generator Loss 6.6426 discriminator Loss 0.0510\n","Epoch 2 Batch 593 generator Loss 6.4034 discriminator Loss 0.0474\n","Epoch 2 Batch 1186 generator Loss 6.2145 discriminator Loss 0.0450\n","Epoch 2 Batch 1779 generator Loss 6.0616 discriminator Loss 0.0435\n","Epoch 2 Batch 2372 generator Loss 5.9329 discriminator Loss 0.0412\n","Epoch 2 generator Loss 5.8842 discriminator Loss 0.0404\n","Time taken for 1 epoch: 861.4498174190521 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3 Batch 0 generator Loss 5.8841 discriminator Loss 0.0404\n","Epoch 3 Batch 593 generator Loss 5.7791 discriminator Loss 0.0383\n","Epoch 3 Batch 1186 generator Loss 5.6875 discriminator Loss 0.0361\n","Epoch 3 Batch 1779 generator Loss 5.6068 discriminator Loss 0.0343\n","Epoch 3 Batch 2372 generator Loss 5.5355 discriminator Loss 0.0327\n","Epoch 3 generator Loss 5.5072 discriminator Loss 0.0321\n","Time taken for 1 epoch: 862.4787149429321 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4 Batch 0 generator Loss 5.5071 discriminator Loss 0.0321\n","Epoch 4 Batch 593 generator Loss 5.4457 discriminator Loss 0.0308\n","Epoch 4 Batch 1186 generator Loss 5.3902 discriminator Loss 0.0295\n","Epoch 4 Batch 1779 generator Loss 5.3393 discriminator Loss 0.0284\n","Epoch 4 Batch 2372 generator Loss 5.2935 discriminator Loss 0.0274\n","Epoch 4 generator Loss 5.2753 discriminator Loss 0.0270\n","Time taken for 1 epoch: 861.422116279602 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5 Batch 0 generator Loss 5.2752 discriminator Loss 0.0269\n","Epoch 5 Batch 593 generator Loss 5.2348 discriminator Loss 0.0260\n","Epoch 5 Batch 1186 generator Loss 5.1969 discriminator Loss 0.0251\n","Epoch 5 Batch 1779 generator Loss 5.1620 discriminator Loss 0.0243\n","Epoch 5 Batch 2372 generator Loss 5.1297 discriminator Loss 0.0236\n","Saving checkpoint for epoch 5 at checkpoints\\ckpt-1\n","Epoch 5 generator Loss 5.1168 discriminator Loss 0.0234\n","Time taken for 1 epoch: 862.3744521141052 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6 Batch 0 generator Loss 5.1167 discriminator Loss 0.0234\n","Epoch 6 Batch 593 generator Loss 5.0877 discriminator Loss 0.0227\n","Epoch 6 Batch 1186 generator Loss 5.0600 discriminator Loss 0.0221\n","Epoch 6 Batch 1779 generator Loss 5.0344 discriminator Loss 0.0216\n","Epoch 6 Batch 2372 generator Loss 5.0101 discriminator Loss 0.0211\n","Epoch 6 generator Loss 5.0003 discriminator Loss 0.0208\n","Time taken for 1 epoch: 861.6913955211639 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7 Batch 0 generator Loss 5.0002 discriminator Loss 0.0208\n","Epoch 7 Batch 593 generator Loss 4.9782 discriminator Loss 0.0203\n","Epoch 7 Batch 1186 generator Loss 4.9567 discriminator Loss 0.0198\n","Epoch 7 Batch 1779 generator Loss 4.9367 discriminator Loss 0.0194\n","Epoch 7 Batch 2372 generator Loss 4.9177 discriminator Loss 0.0190\n","Epoch 7 generator Loss 4.9098 discriminator Loss 0.0188\n","Time taken for 1 epoch: 860.4616327285767 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8 Batch 0 generator Loss 4.9098 discriminator Loss 0.0188\n","Epoch 8 Batch 593 generator Loss 4.8921 discriminator Loss 0.0184\n","Epoch 8 Batch 1186 generator Loss 4.8750 discriminator Loss 0.0181\n","Epoch 8 Batch 1779 generator Loss 4.8588 discriminator Loss 0.0177\n","Epoch 8 Batch 2372 generator Loss 4.8433 discriminator Loss 0.0173\n","Epoch 8 generator Loss 4.8369 discriminator Loss 0.0171\n","Time taken for 1 epoch: 864.1706085205078 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9 Batch 0 generator Loss 4.8369 discriminator Loss 0.0171\n","Epoch 9 Batch 593 generator Loss 4.8223 discriminator Loss 0.0168\n","Epoch 9 Batch 1186 generator Loss 4.8080 discriminator Loss 0.0165\n","Epoch 9 Batch 1779 generator Loss 4.7947 discriminator Loss 0.0162\n","Epoch 9 Batch 2372 generator Loss 4.7816 discriminator Loss 0.0160\n","Epoch 9 generator Loss 4.7762 discriminator Loss 0.0158\n","Time taken for 1 epoch: 861.936883687973 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10 Batch 0 generator Loss 4.7762 discriminator Loss 0.0158\n","Epoch 10 Batch 593 generator Loss 4.7640 discriminator Loss 0.0156\n","Epoch 10 Batch 1186 generator Loss 4.7518 discriminator Loss 0.0153\n","Epoch 10 Batch 1779 generator Loss 4.7404 discriminator Loss 0.0150\n","Epoch 10 Batch 2372 generator Loss 4.7293 discriminator Loss 0.0148\n","Saving checkpoint for epoch 10 at checkpoints\\ckpt-2\n","Epoch 10 generator Loss 4.7246 discriminator Loss 0.0147\n","Time taken for 1 epoch: 866.0887262821198 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11 Batch 0 generator Loss 4.7246 discriminator Loss 0.0147\n","Epoch 11 Batch 593 generator Loss 4.7141 discriminator Loss 0.0145\n","Epoch 11 Batch 1186 generator Loss 4.7037 discriminator Loss 0.0142\n","Epoch 11 Batch 1779 generator Loss 4.6937 discriminator Loss 0.0141\n","Epoch 11 Batch 2372 generator Loss 4.6841 discriminator Loss 0.0139\n","Epoch 11 generator Loss 4.6800 discriminator Loss 0.0138\n","Time taken for 1 epoch: 862.5558731555939 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12 Batch 0 generator Loss 4.6800 discriminator Loss 0.0138\n","Epoch 12 Batch 593 generator Loss 4.6709 discriminator Loss 0.0136\n","Epoch 12 Batch 1186 generator Loss 4.6617 discriminator Loss 0.0134\n","Epoch 12 Batch 1779 generator Loss 4.6530 discriminator Loss 0.0132\n","Epoch 12 Batch 2372 generator Loss 4.6444 discriminator Loss 0.0131\n","Epoch 12 generator Loss 4.6409 discriminator Loss 0.0130\n","Time taken for 1 epoch: 864.7690064907074 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13 Batch 0 generator Loss 4.6408 discriminator Loss 0.0130\n","Epoch 13 Batch 593 generator Loss 4.6328 discriminator Loss 0.0129\n","Epoch 13 Batch 1186 generator Loss 4.6246 discriminator Loss 0.0128\n","Epoch 13 Batch 1779 generator Loss 4.6168 discriminator Loss 0.0126\n","Epoch 13 Batch 2372 generator Loss 4.6094 discriminator Loss 0.0124\n","Epoch 13 generator Loss 4.6062 discriminator Loss 0.0124\n","Time taken for 1 epoch: 864.1338374614716 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14 Batch 0 generator Loss 4.6062 discriminator Loss 0.0124\n","Epoch 14 Batch 593 generator Loss 4.5990 discriminator Loss 0.0122\n","Epoch 14 Batch 1186 generator Loss 4.5917 discriminator Loss 0.0121\n","Epoch 14 Batch 1779 generator Loss 4.5848 discriminator Loss 0.0120\n","Epoch 14 Batch 2372 generator Loss 4.5780 discriminator Loss 0.0119\n","Epoch 14 generator Loss 4.5752 discriminator Loss 0.0118\n","Time taken for 1 epoch: 864.5025897026062 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15 Batch 0 generator Loss 4.5751 discriminator Loss 0.0118\n","Epoch 15 Batch 593 generator Loss 4.5687 discriminator Loss 0.0117\n","Epoch 15 Batch 1186 generator Loss 4.5621 discriminator Loss 0.0116\n","Epoch 15 Batch 1779 generator Loss 4.5559 discriminator Loss 0.0114\n","Epoch 15 Batch 2372 generator Loss 4.5498 discriminator Loss 0.0113\n","Saving checkpoint for epoch 15 at checkpoints\\ckpt-3\n","Epoch 15 generator Loss 4.5472 discriminator Loss 0.0113\n","Time taken for 1 epoch: 865.0772223472595 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16 Batch 0 generator Loss 4.5472 discriminator Loss 0.0113\n","Epoch 16 Batch 593 generator Loss 4.5414 discriminator Loss 0.0112\n","Epoch 16 Batch 1186 generator Loss 4.5354 discriminator Loss 0.0111\n","Epoch 16 Batch 1779 generator Loss 4.5297 discriminator Loss 0.0110\n","Epoch 16 Batch 2372 generator Loss 4.5241 discriminator Loss 0.0109\n","Epoch 16 generator Loss 4.5218 discriminator Loss 0.0109\n","Time taken for 1 epoch: 864.0626423358917 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17 Batch 0 generator Loss 4.5218 discriminator Loss 0.0109\n","Epoch 17 Batch 593 generator Loss 4.5165 discriminator Loss 0.0108\n","Epoch 17 Batch 1186 generator Loss 4.5111 discriminator Loss 0.0107\n","Epoch 17 Batch 1779 generator Loss 4.5058 discriminator Loss 0.0106\n","Epoch 17 Batch 2372 generator Loss 4.5007 discriminator Loss 0.0105\n","Epoch 17 generator Loss 4.4986 discriminator Loss 0.0105\n","Time taken for 1 epoch: 865.3102581501007 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18 Batch 0 generator Loss 4.4986 discriminator Loss 0.0105\n","Epoch 18 Batch 593 generator Loss 4.4937 discriminator Loss 0.0104\n","Epoch 18 Batch 1186 generator Loss 4.4886 discriminator Loss 0.0103\n","Epoch 18 Batch 1779 generator Loss 4.4839 discriminator Loss 0.0102\n","Epoch 18 Batch 2372 generator Loss 4.4793 discriminator Loss 0.0102\n","Epoch 18 generator Loss 4.4772 discriminator Loss 0.0101\n","Time taken for 1 epoch: 863.2844676971436 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19 Batch 0 generator Loss 4.4772 discriminator Loss 0.0101\n","Epoch 19 Batch 593 generator Loss 4.4727 discriminator Loss 0.0101\n","Epoch 19 Batch 1186 generator Loss 4.4681 discriminator Loss 0.0100\n","Epoch 19 Batch 1779 generator Loss 4.4636 discriminator Loss 0.0099\n","Epoch 19 Batch 2372 generator Loss 4.4593 discriminator Loss 0.0099\n","Epoch 19 generator Loss 4.4575 discriminator Loss 0.0099\n","Time taken for 1 epoch: 865.4451644420624 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20 Batch 0 generator Loss 4.4575 discriminator Loss 0.0099\n","Epoch 20 Batch 593 generator Loss 4.4534 discriminator Loss 0.0098\n","Epoch 20 Batch 1186 generator Loss 4.4491 discriminator Loss 0.0097\n","Epoch 20 Batch 1779 generator Loss 4.4449 discriminator Loss 0.0097\n","Epoch 20 Batch 2372 generator Loss 4.4409 discriminator Loss 0.0096\n","Saving checkpoint for epoch 20 at checkpoints\\ckpt-4\n","Epoch 20 generator Loss 4.4391 discriminator Loss 0.0096\n","Time taken for 1 epoch: 864.004894733429 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 21 Batch 0 generator Loss 4.4391 discriminator Loss 0.0096\n","Epoch 21 Batch 593 generator Loss 4.4352 discriminator Loss 0.0095\n","Epoch 21 Batch 1186 generator Loss 4.4312 discriminator Loss 0.0095\n","Epoch 21 Batch 1779 generator Loss 4.4274 discriminator Loss 0.0094\n","Epoch 21 Batch 2372 generator Loss 4.4236 discriminator Loss 0.0093\n","Epoch 21 generator Loss 4.4220 discriminator Loss 0.0093\n","Time taken for 1 epoch: 865.5428383350372 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 22 Batch 0 generator Loss 4.4220 discriminator Loss 0.0093\n","Epoch 22 Batch 593 generator Loss 4.4185 discriminator Loss 0.0093\n","Epoch 22 Batch 1186 generator Loss 4.4147 discriminator Loss 0.0092\n","Epoch 22 Batch 1779 generator Loss 4.4111 discriminator Loss 0.0092\n","Epoch 22 Batch 2372 generator Loss 4.4076 discriminator Loss 0.0091\n","Epoch 22 generator Loss 4.4061 discriminator Loss 0.0091\n","Time taken for 1 epoch: 863.6833806037903 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 23 Batch 0 generator Loss 4.4061 discriminator Loss 0.0091\n","Epoch 23 Batch 593 generator Loss 4.4027 discriminator Loss 0.0091\n","Epoch 23 Batch 1186 generator Loss 4.3992 discriminator Loss 0.0090\n","Epoch 23 Batch 1779 generator Loss 4.3958 discriminator Loss 0.0090\n","Epoch 23 Batch 2372 generator Loss 4.3925 discriminator Loss 0.0089\n","Epoch 23 generator Loss 4.3911 discriminator Loss 0.0089\n","Time taken for 1 epoch: 865.3454988002777 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 24 Batch 0 generator Loss 4.3911 discriminator Loss 0.0089\n","Epoch 24 Batch 593 generator Loss 4.3879 discriminator Loss 0.0089\n","Epoch 24 Batch 1186 generator Loss 4.3846 discriminator Loss 0.0088\n","Epoch 24 Batch 1779 generator Loss 4.3814 discriminator Loss 0.0088\n","Epoch 24 Batch 2372 generator Loss 4.3783 discriminator Loss 0.0088\n","Epoch 24 generator Loss 4.3770 discriminator Loss 0.0087\n","Time taken for 1 epoch: 864.3085753917694 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 25 Batch 0 generator Loss 4.3770 discriminator Loss 0.0087\n","Epoch 25 Batch 593 generator Loss 4.3740 discriminator Loss 0.0087\n","Epoch 25 Batch 1186 generator Loss 4.3708 discriminator Loss 0.0087\n","Epoch 25 Batch 1779 generator Loss 4.3678 discriminator Loss 0.0086\n","Epoch 25 Batch 2372 generator Loss 4.3649 discriminator Loss 0.0086\n","Saving checkpoint for epoch 25 at checkpoints\\ckpt-5\n","Epoch 25 generator Loss 4.3636 discriminator Loss 0.0086\n","Time taken for 1 epoch: 865.8316504955292 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 26 Batch 0 generator Loss 4.3636 discriminator Loss 0.0086\n","Epoch 26 Batch 593 generator Loss 4.3608 discriminator Loss 0.0086\n","Epoch 26 Batch 1186 generator Loss 4.3579 discriminator Loss 0.0085\n","Epoch 26 Batch 1779 generator Loss 4.3550 discriminator Loss 0.0085\n","Epoch 26 Batch 2372 generator Loss 4.3522 discriminator Loss 0.0085\n","Epoch 26 generator Loss 4.3510 discriminator Loss 0.0084\n","Time taken for 1 epoch: 864.9860873222351 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 27 Batch 0 generator Loss 4.3510 discriminator Loss 0.0084\n","Epoch 27 Batch 593 generator Loss 4.3484 discriminator Loss 0.0084\n","Epoch 27 Batch 1186 generator Loss 4.3455 discriminator Loss 0.0084\n","Epoch 27 Batch 1779 generator Loss 4.3428 discriminator Loss 0.0084\n","Epoch 27 Batch 2372 generator Loss 4.3402 discriminator Loss 0.0083\n","Epoch 27 generator Loss 4.3390 discriminator Loss 0.0083\n","Time taken for 1 epoch: 863.9254903793335 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 28 Batch 0 generator Loss 4.3390 discriminator Loss 0.0083\n","Epoch 28 Batch 593 generator Loss 4.3365 discriminator Loss 0.0083\n","Epoch 28 Batch 1186 generator Loss 4.3338 discriminator Loss 0.0083\n","Epoch 28 Batch 1779 generator Loss 4.3313 discriminator Loss 0.0082\n","Epoch 28 Batch 2372 generator Loss 4.3288 discriminator Loss 0.0082\n","Epoch 28 generator Loss 4.3277 discriminator Loss 0.0082\n","Time taken for 1 epoch: 865.8929057121277 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 29 Batch 0 generator Loss 4.3277 discriminator Loss 0.0082\n","Epoch 29 Batch 593 generator Loss 4.3252 discriminator Loss 0.0082\n","Epoch 29 Batch 1186 generator Loss 4.3227 discriminator Loss 0.0081\n","Epoch 29 Batch 1779 generator Loss 4.3202 discriminator Loss 0.0081\n","Epoch 29 Batch 2372 generator Loss 4.3178 discriminator Loss 0.0081\n","Epoch 29 generator Loss 4.3168 discriminator Loss 0.0081\n","Time taken for 1 epoch: 863.3724870681763 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 30 Batch 0 generator Loss 4.3168 discriminator Loss 0.0081\n","Epoch 30 Batch 593 generator Loss 4.3145 discriminator Loss 0.0081\n","Epoch 30 Batch 1186 generator Loss 4.3121 discriminator Loss 0.0080\n","Epoch 30 Batch 1779 generator Loss 4.3098 discriminator Loss 0.0080\n","Epoch 30 Batch 2372 generator Loss 4.3075 discriminator Loss 0.0080\n","Saving checkpoint for epoch 30 at checkpoints\\ckpt-6\n","Epoch 30 generator Loss 4.3065 discriminator Loss 0.0080\n","Time taken for 1 epoch: 865.8273901939392 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 31 Batch 0 generator Loss 4.3065 discriminator Loss 0.0080\n","Epoch 31 Batch 593 generator Loss 4.3043 discriminator Loss 0.0080\n","Epoch 31 Batch 1186 generator Loss 4.3020 discriminator Loss 0.0079\n","Epoch 31 Batch 1779 generator Loss 4.2997 discriminator Loss 0.0079\n","Epoch 31 Batch 2372 generator Loss 4.2975 discriminator Loss 0.0079\n","Epoch 31 generator Loss 4.2966 discriminator Loss 0.0079\n","Time taken for 1 epoch: 861.0245265960693 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 32 Batch 0 generator Loss 4.2966 discriminator Loss 0.0079\n","Epoch 32 Batch 593 generator Loss 4.2945 discriminator Loss 0.0078\n","Epoch 32 Batch 1186 generator Loss 4.2923 discriminator Loss 0.0078\n","Epoch 32 Batch 1779 generator Loss 4.2901 discriminator Loss 0.0078\n","Epoch 32 Batch 2372 generator Loss 4.2880 discriminator Loss 0.0078\n","Epoch 32 generator Loss 4.2871 discriminator Loss 0.0077\n","Time taken for 1 epoch: 862.8338739871979 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 33 Batch 0 generator Loss 4.2871 discriminator Loss 0.0077\n","Epoch 33 Batch 593 generator Loss 4.2851 discriminator Loss 0.0077\n","Epoch 33 Batch 1186 generator Loss 4.2830 discriminator Loss 0.0077\n","Epoch 33 Batch 1779 generator Loss 4.2808 discriminator Loss 0.0077\n","Epoch 33 Batch 2372 generator Loss 4.2789 discriminator Loss 0.0077\n","Epoch 33 generator Loss 4.2780 discriminator Loss 0.0077\n","Time taken for 1 epoch: 860.8822965621948 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 34 Batch 0 generator Loss 4.2780 discriminator Loss 0.0077\n","Epoch 34 Batch 593 generator Loss 4.2761 discriminator Loss 0.0076\n","Epoch 34 Batch 1186 generator Loss 4.2740 discriminator Loss 0.0076\n","Epoch 34 Batch 1779 generator Loss 4.2720 discriminator Loss 0.0076\n","Epoch 34 Batch 2372 generator Loss 4.2701 discriminator Loss 0.0076\n","Epoch 34 generator Loss 4.2692 discriminator Loss 0.0076\n","Time taken for 1 epoch: 862.3890841007233 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 35 Batch 0 generator Loss 4.2692 discriminator Loss 0.0076\n","Epoch 35 Batch 593 generator Loss 4.2674 discriminator Loss 0.0076\n","Epoch 35 Batch 1186 generator Loss 4.2654 discriminator Loss 0.0075\n","Epoch 35 Batch 1779 generator Loss 4.2635 discriminator Loss 0.0075\n","Epoch 35 Batch 2372 generator Loss 4.2616 discriminator Loss 0.0075\n","Saving checkpoint for epoch 35 at checkpoints\\ckpt-7\n","Epoch 35 generator Loss 4.2608 discriminator Loss 0.0075\n","Time taken for 1 epoch: 862.4255771636963 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 36 Batch 0 generator Loss 4.2608 discriminator Loss 0.0075\n","Epoch 36 Batch 593 generator Loss 4.2590 discriminator Loss 0.0075\n","Epoch 36 Batch 1186 generator Loss 4.2571 discriminator Loss 0.0075\n","Epoch 36 Batch 1779 generator Loss 4.2553 discriminator Loss 0.0075\n","Epoch 36 Batch 2372 generator Loss 4.2535 discriminator Loss 0.0074\n","Epoch 36 generator Loss 4.2527 discriminator Loss 0.0074\n","Time taken for 1 epoch: 861.0662095546722 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 37 Batch 0 generator Loss 4.2527 discriminator Loss 0.0074\n","Epoch 37 Batch 593 generator Loss 4.2510 discriminator Loss 0.0074\n","Epoch 37 Batch 1186 generator Loss 4.2491 discriminator Loss 0.0074\n","Epoch 37 Batch 1779 generator Loss 4.2474 discriminator Loss 0.0074\n","Epoch 37 Batch 2372 generator Loss 4.2457 discriminator Loss 0.0074\n","Epoch 37 generator Loss 4.2449 discriminator Loss 0.0074\n","Time taken for 1 epoch: 862.1049041748047 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 38 Batch 0 generator Loss 4.2449 discriminator Loss 0.0073\n","Epoch 38 Batch 593 generator Loss 4.2432 discriminator Loss 0.0073\n","Epoch 38 Batch 1186 generator Loss 4.2415 discriminator Loss 0.0073\n","Epoch 38 Batch 1779 generator Loss 4.2397 discriminator Loss 0.0073\n","Epoch 38 Batch 2372 generator Loss 4.2381 discriminator Loss 0.0073\n","Epoch 38 generator Loss 4.2374 discriminator Loss 0.0073\n","Time taken for 1 epoch: 861.0199108123779 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 39 Batch 0 generator Loss 4.2374 discriminator Loss 0.0073\n","Epoch 39 Batch 593 generator Loss 4.2357 discriminator Loss 0.0073\n","Epoch 39 Batch 1186 generator Loss 4.2340 discriminator Loss 0.0072\n","Epoch 39 Batch 1779 generator Loss 4.2324 discriminator Loss 0.0072\n","Epoch 39 Batch 2372 generator Loss 4.2308 discriminator Loss 0.0072\n","Epoch 39 generator Loss 4.2301 discriminator Loss 0.0072\n","Time taken for 1 epoch: 862.9651029109955 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 40 Batch 0 generator Loss 4.2301 discriminator Loss 0.0072\n","Epoch 40 Batch 593 generator Loss 4.2285 discriminator Loss 0.0072\n","Epoch 40 Batch 1186 generator Loss 4.2268 discriminator Loss 0.0072\n","Epoch 40 Batch 1779 generator Loss 4.2252 discriminator Loss 0.0072\n","Epoch 40 Batch 2372 generator Loss 4.2237 discriminator Loss 0.0071\n","Saving checkpoint for epoch 40 at checkpoints\\ckpt-8\n","Epoch 40 generator Loss 4.2230 discriminator Loss 0.0071\n","Time taken for 1 epoch: 861.0527529716492 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 41 Batch 0 generator Loss 4.2230 discriminator Loss 0.0071\n","Epoch 41 Batch 593 generator Loss 4.2215 discriminator Loss 0.0071\n","Epoch 41 Batch 1186 generator Loss 4.2199 discriminator Loss 0.0071\n","Epoch 41 Batch 1779 generator Loss 4.2183 discriminator Loss 0.0071\n","Epoch 41 Batch 2372 generator Loss 4.2168 discriminator Loss 0.0071\n","Epoch 41 generator Loss 4.2162 discriminator Loss 0.0071\n","Time taken for 1 epoch: 862.6919074058533 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 42 Batch 0 generator Loss 4.2161 discriminator Loss 0.0071\n","Epoch 42 Batch 593 generator Loss 4.2147 discriminator Loss 0.0071\n","Epoch 42 Batch 1186 generator Loss 4.2131 discriminator Loss 0.0070\n","Epoch 42 Batch 1779 generator Loss 4.2116 discriminator Loss 0.0070\n","Epoch 42 Batch 2372 generator Loss 4.2101 discriminator Loss 0.0070\n","Epoch 42 generator Loss 4.2095 discriminator Loss 0.0070\n","Time taken for 1 epoch: 860.453774690628 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 43 Batch 0 generator Loss 4.2095 discriminator Loss 0.0070\n","Epoch 43 Batch 593 generator Loss 4.2081 discriminator Loss 0.0070\n","Epoch 43 Batch 1186 generator Loss 4.2066 discriminator Loss 0.0070\n","Epoch 43 Batch 1779 generator Loss 4.2051 discriminator Loss 0.0070\n","Epoch 43 Batch 2372 generator Loss 4.2037 discriminator Loss 0.0069\n","Epoch 43 generator Loss 4.2031 discriminator Loss 0.0069\n","Time taken for 1 epoch: 862.2348184585571 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 44 Batch 0 generator Loss 4.2031 discriminator Loss 0.0069\n","Epoch 44 Batch 593 generator Loss 4.2017 discriminator Loss 0.0069\n","Epoch 44 Batch 1186 generator Loss 4.2002 discriminator Loss 0.0069\n","Epoch 44 Batch 1779 generator Loss 4.1988 discriminator Loss 0.0069\n","Epoch 44 Batch 2372 generator Loss 4.1974 discriminator Loss 0.0069\n","Epoch 44 generator Loss 4.1968 discriminator Loss 0.0069\n","Time taken for 1 epoch: 860.1492719650269 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 45 Batch 0 generator Loss 4.1968 discriminator Loss 0.0069\n","Epoch 45 Batch 593 generator Loss 4.1955 discriminator Loss 0.0069\n","Epoch 45 Batch 1186 generator Loss 4.1941 discriminator Loss 0.0069\n","Epoch 45 Batch 1779 generator Loss 4.1927 discriminator Loss 0.0068\n","Epoch 45 Batch 2372 generator Loss 4.1913 discriminator Loss 0.0068\n","Saving checkpoint for epoch 45 at checkpoints\\ckpt-9\n","Epoch 45 generator Loss 4.1908 discriminator Loss 0.0068\n","Time taken for 1 epoch: 862.1184935569763 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 46 Batch 0 generator Loss 4.1908 discriminator Loss 0.0068\n","Epoch 46 Batch 593 generator Loss 4.1895 discriminator Loss 0.0068\n","Epoch 46 Batch 1186 generator Loss 4.1881 discriminator Loss 0.0068\n","Epoch 46 Batch 1779 generator Loss 4.1868 discriminator Loss 0.0068\n","Epoch 46 Batch 2372 generator Loss 4.1855 discriminator Loss 0.0068\n","Epoch 46 generator Loss 4.1849 discriminator Loss 0.0068\n","Time taken for 1 epoch: 861.43634724617 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 47 Batch 0 generator Loss 4.1849 discriminator Loss 0.0068\n","Epoch 47 Batch 593 generator Loss 4.1836 discriminator Loss 0.0068\n","Epoch 47 Batch 1186 generator Loss 4.1822 discriminator Loss 0.0067\n","Epoch 47 Batch 1779 generator Loss 4.1810 discriminator Loss 0.0067\n","Epoch 47 Batch 2372 generator Loss 4.1797 discriminator Loss 0.0067\n","Epoch 47 generator Loss 4.1791 discriminator Loss 0.0067\n","Time taken for 1 epoch: 860.9187786579132 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 48 Batch 0 generator Loss 4.1791 discriminator Loss 0.0067\n","Epoch 48 Batch 593 generator Loss 4.1779 discriminator Loss 0.0067\n","Epoch 48 Batch 1186 generator Loss 4.1766 discriminator Loss 0.0067\n","Epoch 48 Batch 1779 generator Loss 4.1753 discriminator Loss 0.0067\n","Epoch 48 Batch 2372 generator Loss 4.1741 discriminator Loss 0.0067\n","Epoch 48 generator Loss 4.1735 discriminator Loss 0.0067\n","Time taken for 1 epoch: 861.9139966964722 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 49 Batch 0 generator Loss 4.1735 discriminator Loss 0.0067\n","Epoch 49 Batch 593 generator Loss 4.1723 discriminator Loss 0.0067\n","Epoch 49 Batch 1186 generator Loss 4.1710 discriminator Loss 0.0066\n","Epoch 49 Batch 1779 generator Loss 4.1698 discriminator Loss 0.0066\n","Epoch 49 Batch 2372 generator Loss 4.1686 discriminator Loss 0.0066\n","Epoch 49 generator Loss 4.1681 discriminator Loss 0.0066\n","Time taken for 1 epoch: 859.9577751159668 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 50 Batch 0 generator Loss 4.1681 discriminator Loss 0.0066\n","Epoch 50 Batch 593 generator Loss 4.1669 discriminator Loss 0.0066\n","Epoch 50 Batch 1186 generator Loss 4.1657 discriminator Loss 0.0066\n","Epoch 50 Batch 1779 generator Loss 4.1645 discriminator Loss 0.0066\n","Epoch 50 Batch 2372 generator Loss 4.1633 discriminator Loss 0.0066\n","Saving checkpoint for epoch 50 at checkpoints\\ckpt-10\n","Epoch 50 generator Loss 4.1628 discriminator Loss 0.0066\n","Time taken for 1 epoch: 863.7830109596252 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 51 Batch 0 generator Loss 4.1628 discriminator Loss 0.0066\n","Epoch 51 Batch 593 generator Loss 4.1616 discriminator Loss 0.0066\n","Epoch 51 Batch 1186 generator Loss 4.1604 discriminator Loss 0.0065\n","Epoch 51 Batch 1779 generator Loss 4.1592 discriminator Loss 0.0065\n","Epoch 51 Batch 2372 generator Loss 4.1581 discriminator Loss 0.0065\n","Epoch 51 generator Loss 4.1576 discriminator Loss 0.0065\n","Time taken for 1 epoch: 859.988692522049 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 52 Batch 0 generator Loss 4.1576 discriminator Loss 0.0065\n","Epoch 52 Batch 593 generator Loss 4.1565 discriminator Loss 0.0065\n","Epoch 52 Batch 1186 generator Loss 4.1553 discriminator Loss 0.0065\n","Epoch 52 Batch 1779 generator Loss 4.1542 discriminator Loss 0.0065\n","Epoch 52 Batch 2372 generator Loss 4.1531 discriminator Loss 0.0065\n","Epoch 52 generator Loss 4.1526 discriminator Loss 0.0065\n","Time taken for 1 epoch: 862.7371778488159 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 53 Batch 0 generator Loss 4.1526 discriminator Loss 0.0065\n","Epoch 53 Batch 593 generator Loss 4.1515 discriminator Loss 0.0065\n","Epoch 53 Batch 1186 generator Loss 4.1503 discriminator Loss 0.0065\n","Epoch 53 Batch 1779 generator Loss 4.1492 discriminator Loss 0.0065\n","Epoch 53 Batch 2372 generator Loss 4.1481 discriminator Loss 0.0064\n","Epoch 53 generator Loss 4.1476 discriminator Loss 0.0064\n","Time taken for 1 epoch: 859.9525928497314 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 54 Batch 0 generator Loss 4.1476 discriminator Loss 0.0064\n","Epoch 54 Batch 593 generator Loss 4.1466 discriminator Loss 0.0064\n","Epoch 54 Batch 1186 generator Loss 4.1454 discriminator Loss 0.0064\n","Epoch 54 Batch 1779 generator Loss 4.1443 discriminator Loss 0.0064\n","Epoch 54 Batch 2372 generator Loss 4.1433 discriminator Loss 0.0064\n","Epoch 54 generator Loss 4.1428 discriminator Loss 0.0064\n","Time taken for 1 epoch: 862.7368054389954 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 55 Batch 0 generator Loss 4.1428 discriminator Loss 0.0064\n","Epoch 55 Batch 593 generator Loss 4.1418 discriminator Loss 0.0064\n","Epoch 55 Batch 1186 generator Loss 4.1407 discriminator Loss 0.0064\n","Epoch 55 Batch 1779 generator Loss 4.1396 discriminator Loss 0.0064\n","Epoch 55 Batch 2372 generator Loss 4.1385 discriminator Loss 0.0064\n","Saving checkpoint for epoch 55 at checkpoints\\ckpt-11\n","Epoch 55 generator Loss 4.1381 discriminator Loss 0.0064\n","Time taken for 1 epoch: 862.4183337688446 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 56 Batch 0 generator Loss 4.1381 discriminator Loss 0.0064\n","Epoch 56 Batch 593 generator Loss 4.1371 discriminator Loss 0.0064\n","Epoch 56 Batch 1186 generator Loss 4.1360 discriminator Loss 0.0063\n","Epoch 56 Batch 1779 generator Loss 4.1350 discriminator Loss 0.0063\n","Epoch 56 Batch 2372 generator Loss 4.1339 discriminator Loss 0.0063\n","Epoch 56 generator Loss 4.1335 discriminator Loss 0.0063\n","Time taken for 1 epoch: 861.7607185840607 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 57 Batch 0 generator Loss 4.1335 discriminator Loss 0.0063\n","Epoch 57 Batch 593 generator Loss 4.1325 discriminator Loss 0.0063\n","Epoch 57 Batch 1186 generator Loss 4.1314 discriminator Loss 0.0063\n","Epoch 57 Batch 1779 generator Loss 4.1304 discriminator Loss 0.0063\n","Epoch 57 Batch 2372 generator Loss 4.1294 discriminator Loss 0.0063\n","Epoch 57 generator Loss 4.1290 discriminator Loss 0.0063\n","Time taken for 1 epoch: 861.416300535202 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 58 Batch 0 generator Loss 4.1290 discriminator Loss 0.0063\n","Epoch 58 Batch 593 generator Loss 4.1280 discriminator Loss 0.0063\n","Epoch 58 Batch 1186 generator Loss 4.1270 discriminator Loss 0.0063\n","Epoch 58 Batch 1779 generator Loss 4.1260 discriminator Loss 0.0063\n","Epoch 58 Batch 2372 generator Loss 4.1250 discriminator Loss 0.0063\n","Epoch 58 generator Loss 4.1246 discriminator Loss 0.0063\n","Time taken for 1 epoch: 860.797881603241 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 59 Batch 0 generator Loss 4.1246 discriminator Loss 0.0063\n","Epoch 59 Batch 593 generator Loss 4.1236 discriminator Loss 0.0063\n","Epoch 59 Batch 1186 generator Loss 4.1226 discriminator Loss 0.0062\n","Epoch 59 Batch 1779 generator Loss 4.1216 discriminator Loss 0.0062\n","Epoch 59 Batch 2372 generator Loss 4.1207 discriminator Loss 0.0062\n","Epoch 59 generator Loss 4.1203 discriminator Loss 0.0062\n","Time taken for 1 epoch: 861.8826105594635 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 60 Batch 0 generator Loss 4.1203 discriminator Loss 0.0062\n","Epoch 60 Batch 593 generator Loss 4.1193 discriminator Loss 0.0062\n","Epoch 60 Batch 1186 generator Loss 4.1184 discriminator Loss 0.0062\n","Epoch 60 Batch 1779 generator Loss 4.1174 discriminator Loss 0.0062\n","Epoch 60 Batch 2372 generator Loss 4.1164 discriminator Loss 0.0062\n","Saving checkpoint for epoch 60 at checkpoints\\ckpt-12\n","Epoch 60 generator Loss 4.1160 discriminator Loss 0.0062\n","Time taken for 1 epoch: 861.4982566833496 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 61 Batch 0 generator Loss 4.1160 discriminator Loss 0.0062\n","Epoch 61 Batch 593 generator Loss 4.1151 discriminator Loss 0.0062\n","Epoch 61 Batch 1186 generator Loss 4.1141 discriminator Loss 0.0062\n","Epoch 61 Batch 1779 generator Loss 4.1132 discriminator Loss 0.0062\n","Epoch 61 Batch 2372 generator Loss 4.1123 discriminator Loss 0.0062\n","Epoch 61 generator Loss 4.1119 discriminator Loss 0.0062\n","Time taken for 1 epoch: 862.4935853481293 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 62 Batch 0 generator Loss 4.1119 discriminator Loss 0.0062\n","Epoch 62 Batch 593 generator Loss 4.1110 discriminator Loss 0.0062\n","Epoch 62 Batch 1186 generator Loss 4.1100 discriminator Loss 0.0061\n","Epoch 62 Batch 1779 generator Loss 4.1091 discriminator Loss 0.0061\n","Epoch 62 Batch 2372 generator Loss 4.1082 discriminator Loss 0.0061\n","Epoch 62 generator Loss 4.1078 discriminator Loss 0.0061\n","Time taken for 1 epoch: 862.1432750225067 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 63 Batch 0 generator Loss 4.1078 discriminator Loss 0.0061\n","Epoch 63 Batch 593 generator Loss 4.1070 discriminator Loss 0.0061\n","Epoch 63 Batch 1186 generator Loss 4.1060 discriminator Loss 0.0061\n","Epoch 63 Batch 1779 generator Loss 4.1051 discriminator Loss 0.0061\n","Epoch 63 Batch 2372 generator Loss 4.1042 discriminator Loss 0.0061\n","Epoch 63 generator Loss 4.1039 discriminator Loss 0.0061\n","Time taken for 1 epoch: 865.839693069458 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 64 Batch 0 generator Loss 4.1039 discriminator Loss 0.0061\n","Epoch 64 Batch 593 generator Loss 4.1030 discriminator Loss 0.0061\n","Epoch 64 Batch 1186 generator Loss 4.1021 discriminator Loss 0.0061\n","Epoch 64 Batch 1779 generator Loss 4.1012 discriminator Loss 0.0061\n","Epoch 64 Batch 2372 generator Loss 4.1004 discriminator Loss 0.0061\n","Epoch 64 generator Loss 4.1000 discriminator Loss 0.0061\n","Time taken for 1 epoch: 863.7852454185486 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 65 Batch 0 generator Loss 4.1000 discriminator Loss 0.0061\n","Epoch 65 Batch 593 generator Loss 4.0991 discriminator Loss 0.0061\n","Epoch 65 Batch 1186 generator Loss 4.0982 discriminator Loss 0.0061\n","Epoch 65 Batch 1779 generator Loss 4.0974 discriminator Loss 0.0060\n","Epoch 65 Batch 2372 generator Loss 4.0965 discriminator Loss 0.0060\n","Saving checkpoint for epoch 65 at checkpoints\\ckpt-13\n","Epoch 65 generator Loss 4.0961 discriminator Loss 0.0060\n","Time taken for 1 epoch: 866.4077820777893 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 66 Batch 0 generator Loss 4.0961 discriminator Loss 0.0060\n","Epoch 66 Batch 593 generator Loss 4.0953 discriminator Loss 0.0060\n","Epoch 66 Batch 1186 generator Loss 4.0944 discriminator Loss 0.0060\n","Epoch 66 Batch 1779 generator Loss 4.0936 discriminator Loss 0.0060\n","Epoch 66 Batch 2372 generator Loss 4.0927 discriminator Loss 0.0060\n","Epoch 66 generator Loss 4.0924 discriminator Loss 0.0060\n","Time taken for 1 epoch: 863.9212164878845 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 67 Batch 0 generator Loss 4.0924 discriminator Loss 0.0060\n","Epoch 67 Batch 593 generator Loss 4.0916 discriminator Loss 0.0060\n","Epoch 67 Batch 1186 generator Loss 4.0907 discriminator Loss 0.0060\n","Epoch 67 Batch 1779 generator Loss 4.0899 discriminator Loss 0.0060\n","Epoch 67 Batch 2372 generator Loss 4.0890 discriminator Loss 0.0060\n","Epoch 67 generator Loss 4.0887 discriminator Loss 0.0060\n","Time taken for 1 epoch: 865.4574062824249 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 68 Batch 0 generator Loss 4.0887 discriminator Loss 0.0060\n","Epoch 68 Batch 593 generator Loss 4.0879 discriminator Loss 0.0060\n","Epoch 68 Batch 1186 generator Loss 4.0871 discriminator Loss 0.0060\n","Epoch 68 Batch 1779 generator Loss 4.0862 discriminator Loss 0.0060\n","Epoch 68 Batch 2372 generator Loss 4.0854 discriminator Loss 0.0059\n","Epoch 68 generator Loss 4.0851 discriminator Loss 0.0059\n","Time taken for 1 epoch: 865.6705350875854 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 69 Batch 0 generator Loss 4.0851 discriminator Loss 0.0059\n","Epoch 69 Batch 593 generator Loss 4.0843 discriminator Loss 0.0059\n","Epoch 69 Batch 1186 generator Loss 4.0835 discriminator Loss 0.0059\n","Epoch 69 Batch 1779 generator Loss 4.0827 discriminator Loss 0.0059\n","Epoch 69 Batch 2372 generator Loss 4.0819 discriminator Loss 0.0059\n","Epoch 69 generator Loss 4.0815 discriminator Loss 0.0059\n","Time taken for 1 epoch: 864.5836551189423 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 70 Batch 0 generator Loss 4.0815 discriminator Loss 0.0059\n","Epoch 70 Batch 593 generator Loss 4.0808 discriminator Loss 0.0059\n","Epoch 70 Batch 1186 generator Loss 4.0799 discriminator Loss 0.0059\n","Epoch 70 Batch 1779 generator Loss 4.0791 discriminator Loss 0.0059\n","Epoch 70 Batch 2372 generator Loss 4.0784 discriminator Loss 0.0059\n","Saving checkpoint for epoch 70 at checkpoints\\ckpt-14\n","Epoch 70 generator Loss 4.0780 discriminator Loss 0.0059\n","Time taken for 1 epoch: 866.3529088497162 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 71 Batch 0 generator Loss 4.0780 discriminator Loss 0.0059\n","Epoch 71 Batch 593 generator Loss 4.0773 discriminator Loss 0.0059\n","Epoch 71 Batch 1186 generator Loss 4.0764 discriminator Loss 0.0059\n","Epoch 71 Batch 1779 generator Loss 4.0757 discriminator Loss 0.0059\n","Epoch 71 Batch 2372 generator Loss 4.0749 discriminator Loss 0.0059\n","Epoch 71 generator Loss 4.0746 discriminator Loss 0.0059\n","Time taken for 1 epoch: 861.7458319664001 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 72 Batch 0 generator Loss 4.0746 discriminator Loss 0.0059\n","Epoch 72 Batch 593 generator Loss 4.0738 discriminator Loss 0.0059\n","Epoch 72 Batch 1186 generator Loss 4.0730 discriminator Loss 0.0059\n","Epoch 72 Batch 1779 generator Loss 4.0723 discriminator Loss 0.0058\n","Epoch 72 Batch 2372 generator Loss 4.0715 discriminator Loss 0.0058\n","Epoch 72 generator Loss 4.0712 discriminator Loss 0.0058\n","Time taken for 1 epoch: 863.8696401119232 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 73 Batch 0 generator Loss 4.0712 discriminator Loss 0.0058\n","Epoch 73 Batch 593 generator Loss 4.0705 discriminator Loss 0.0058\n","Epoch 73 Batch 1186 generator Loss 4.0697 discriminator Loss 0.0058\n","Epoch 73 Batch 1779 generator Loss 4.0689 discriminator Loss 0.0058\n","Epoch 73 Batch 2372 generator Loss 4.0682 discriminator Loss 0.0058\n","Epoch 73 generator Loss 4.0679 discriminator Loss 0.0058\n","Time taken for 1 epoch: 861.0702228546143 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 74 Batch 0 generator Loss 4.0679 discriminator Loss 0.0058\n","Epoch 74 Batch 593 generator Loss 4.0672 discriminator Loss 0.0058\n","Epoch 74 Batch 1186 generator Loss 4.0664 discriminator Loss 0.0058\n","Epoch 74 Batch 1779 generator Loss 4.0657 discriminator Loss 0.0058\n","Epoch 74 Batch 2372 generator Loss 4.0649 discriminator Loss 0.0058\n","Epoch 74 generator Loss 4.0646 discriminator Loss 0.0058\n","Time taken for 1 epoch: 862.751284122467 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 75 Batch 0 generator Loss 4.0646 discriminator Loss 0.0058\n","Epoch 75 Batch 593 generator Loss 4.0639 discriminator Loss 0.0058\n","Epoch 75 Batch 1186 generator Loss 4.0631 discriminator Loss 0.0058\n","Epoch 75 Batch 1779 generator Loss 4.0624 discriminator Loss 0.0058\n","Epoch 75 Batch 2372 generator Loss 4.0617 discriminator Loss 0.0058\n","Saving checkpoint for epoch 75 at checkpoints\\ckpt-15\n","Epoch 75 generator Loss 4.0614 discriminator Loss 0.0058\n","Time taken for 1 epoch: 861.8909180164337 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 76 Batch 0 generator Loss 4.0614 discriminator Loss 0.0058\n","Epoch 76 Batch 593 generator Loss 4.0607 discriminator Loss 0.0058\n","Epoch 76 Batch 1186 generator Loss 4.0600 discriminator Loss 0.0057\n","Epoch 76 Batch 1779 generator Loss 4.0593 discriminator Loss 0.0057\n","Epoch 76 Batch 2372 generator Loss 4.0585 discriminator Loss 0.0057\n","Epoch 76 generator Loss 4.0583 discriminator Loss 0.0057\n","Time taken for 1 epoch: 861.0252890586853 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 77 Batch 0 generator Loss 4.0582 discriminator Loss 0.0057\n","Epoch 77 Batch 593 generator Loss 4.0576 discriminator Loss 0.0057\n","Epoch 77 Batch 1186 generator Loss 4.0568 discriminator Loss 0.0057\n","Epoch 77 Batch 1779 generator Loss 4.0561 discriminator Loss 0.0057\n","Epoch 77 Batch 2372 generator Loss 4.0554 discriminator Loss 0.0057\n","Epoch 77 generator Loss 4.0551 discriminator Loss 0.0057\n","Time taken for 1 epoch: 860.6767752170563 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 78 Batch 0 generator Loss 4.0551 discriminator Loss 0.0057\n","Epoch 78 Batch 593 generator Loss 4.0545 discriminator Loss 0.0057\n","Epoch 78 Batch 1186 generator Loss 4.0538 discriminator Loss 0.0057\n","Epoch 78 Batch 1779 generator Loss 4.0531 discriminator Loss 0.0057\n","Epoch 78 Batch 2372 generator Loss 4.0524 discriminator Loss 0.0057\n","Epoch 78 generator Loss 4.0521 discriminator Loss 0.0057\n","Time taken for 1 epoch: 861.6120593547821 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 79 Batch 0 generator Loss 4.0521 discriminator Loss 0.0057\n","Epoch 79 Batch 593 generator Loss 4.0514 discriminator Loss 0.0057\n","Epoch 79 Batch 1186 generator Loss 4.0507 discriminator Loss 0.0057\n","Epoch 79 Batch 1779 generator Loss 4.0500 discriminator Loss 0.0057\n","Epoch 79 Batch 2372 generator Loss 4.0493 discriminator Loss 0.0057\n","Epoch 79 generator Loss 4.0491 discriminator Loss 0.0057\n","Time taken for 1 epoch: 861.5389168262482 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 80 Batch 0 generator Loss 4.0491 discriminator Loss 0.0057\n","Epoch 80 Batch 593 generator Loss 4.0484 discriminator Loss 0.0057\n","Epoch 80 Batch 1186 generator Loss 4.0477 discriminator Loss 0.0057\n","Epoch 80 Batch 1779 generator Loss 4.0470 discriminator Loss 0.0057\n","Epoch 80 Batch 2372 generator Loss 4.0464 discriminator Loss 0.0057\n","Saving checkpoint for epoch 80 at checkpoints\\ckpt-16\n","Epoch 80 generator Loss 4.0461 discriminator Loss 0.0057\n","Time taken for 1 epoch: 863.4317009449005 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 81 Batch 0 generator Loss 4.0461 discriminator Loss 0.0057\n","Epoch 81 Batch 593 generator Loss 4.0455 discriminator Loss 0.0056\n","Epoch 81 Batch 1186 generator Loss 4.0448 discriminator Loss 0.0056\n","Epoch 81 Batch 1779 generator Loss 4.0441 discriminator Loss 0.0056\n","Epoch 81 Batch 2372 generator Loss 4.0434 discriminator Loss 0.0056\n","Epoch 81 generator Loss 4.0432 discriminator Loss 0.0056\n","Time taken for 1 epoch: 864.6724381446838 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 82 Batch 0 generator Loss 4.0432 discriminator Loss 0.0056\n","Epoch 82 Batch 593 generator Loss 4.0425 discriminator Loss 0.0056\n","Epoch 82 Batch 1186 generator Loss 4.0419 discriminator Loss 0.0056\n","Epoch 82 Batch 1779 generator Loss 4.0412 discriminator Loss 0.0056\n","Epoch 82 Batch 2372 generator Loss 4.0406 discriminator Loss 0.0056\n","Epoch 82 generator Loss 4.0403 discriminator Loss 0.0056\n","Time taken for 1 epoch: 862.6458485126495 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 83 Batch 0 generator Loss 4.0403 discriminator Loss 0.0056\n","Epoch 83 Batch 593 generator Loss 4.0397 discriminator Loss 0.0056\n","Epoch 83 Batch 1186 generator Loss 4.0390 discriminator Loss 0.0056\n","Epoch 83 Batch 1779 generator Loss 4.0384 discriminator Loss 0.0056\n","Epoch 83 Batch 2372 generator Loss 4.0377 discriminator Loss 0.0056\n","Epoch 83 generator Loss 4.0375 discriminator Loss 0.0056\n","Time taken for 1 epoch: 864.8533909320831 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 84 Batch 0 generator Loss 4.0375 discriminator Loss 0.0056\n","Epoch 84 Batch 593 generator Loss 4.0368 discriminator Loss 0.0056\n","Epoch 84 Batch 1186 generator Loss 4.0362 discriminator Loss 0.0056\n","Epoch 84 Batch 1779 generator Loss 4.0356 discriminator Loss 0.0056\n","Epoch 84 Batch 2372 generator Loss 4.0349 discriminator Loss 0.0056\n","Epoch 84 generator Loss 4.0347 discriminator Loss 0.0056\n","Time taken for 1 epoch: 862.7745835781097 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 85 Batch 0 generator Loss 4.0347 discriminator Loss 0.0056\n","Epoch 85 Batch 593 generator Loss 4.0340 discriminator Loss 0.0056\n","Epoch 85 Batch 1186 generator Loss 4.0334 discriminator Loss 0.0056\n","Epoch 85 Batch 1779 generator Loss 4.0328 discriminator Loss 0.0056\n","Epoch 85 Batch 2372 generator Loss 4.0322 discriminator Loss 0.0056\n","Saving checkpoint for epoch 85 at checkpoints\\ckpt-17\n","Epoch 85 generator Loss 4.0319 discriminator Loss 0.0056\n","Time taken for 1 epoch: 865.6964395046234 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 86 Batch 0 generator Loss 4.0319 discriminator Loss 0.0056\n","Epoch 86 Batch 593 generator Loss 4.0313 discriminator Loss 0.0055\n","Epoch 86 Batch 1186 generator Loss 4.0307 discriminator Loss 0.0055\n","Epoch 86 Batch 1779 generator Loss 4.0301 discriminator Loss 0.0055\n","Epoch 86 Batch 2372 generator Loss 4.0295 discriminator Loss 0.0055\n","Epoch 86 generator Loss 4.0292 discriminator Loss 0.0055\n","Time taken for 1 epoch: 863.5702111721039 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 87 Batch 0 generator Loss 4.0292 discriminator Loss 0.0055\n","Epoch 87 Batch 593 generator Loss 4.0286 discriminator Loss 0.0055\n","Epoch 87 Batch 1186 generator Loss 4.0280 discriminator Loss 0.0055\n","Epoch 87 Batch 1779 generator Loss 4.0274 discriminator Loss 0.0055\n","Epoch 87 Batch 2372 generator Loss 4.0268 discriminator Loss 0.0055\n","Epoch 87 generator Loss 4.0266 discriminator Loss 0.0055\n","Time taken for 1 epoch: 864.6681780815125 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 88 Batch 0 generator Loss 4.0266 discriminator Loss 0.0055\n","Epoch 88 Batch 593 generator Loss 4.0260 discriminator Loss 0.0055\n","Epoch 88 Batch 1186 generator Loss 4.0254 discriminator Loss 0.0055\n","Epoch 88 Batch 1779 generator Loss 4.0248 discriminator Loss 0.0055\n","Epoch 88 Batch 2372 generator Loss 4.0242 discriminator Loss 0.0055\n","Epoch 88 generator Loss 4.0239 discriminator Loss 0.0055\n","Time taken for 1 epoch: 865.5227568149567 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 89 Batch 0 generator Loss 4.0239 discriminator Loss 0.0055\n","Epoch 89 Batch 593 generator Loss 4.0234 discriminator Loss 0.0055\n","Epoch 89 Batch 1186 generator Loss 4.0228 discriminator Loss 0.0055\n","Epoch 89 Batch 1779 generator Loss 4.0222 discriminator Loss 0.0055\n","Epoch 89 Batch 2372 generator Loss 4.0216 discriminator Loss 0.0055\n","Epoch 89 generator Loss 4.0214 discriminator Loss 0.0055\n","Time taken for 1 epoch: 863.9987018108368 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 90 Batch 0 generator Loss 4.0214 discriminator Loss 0.0055\n","Epoch 90 Batch 593 generator Loss 4.0208 discriminator Loss 0.0055\n","Epoch 90 Batch 1186 generator Loss 4.0202 discriminator Loss 0.0055\n","Epoch 90 Batch 1779 generator Loss 4.0196 discriminator Loss 0.0055\n","Epoch 90 Batch 2372 generator Loss 4.0191 discriminator Loss 0.0055\n","Saving checkpoint for epoch 90 at checkpoints\\ckpt-18\n","Epoch 90 generator Loss 4.0188 discriminator Loss 0.0055\n","Time taken for 1 epoch: 866.6691813468933 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 91 Batch 0 generator Loss 4.0188 discriminator Loss 0.0055\n","Epoch 91 Batch 593 generator Loss 4.0183 discriminator Loss 0.0055\n","Epoch 91 Batch 1186 generator Loss 4.0177 discriminator Loss 0.0055\n","Epoch 91 Batch 1779 generator Loss 4.0171 discriminator Loss 0.0055\n","Epoch 91 Batch 2372 generator Loss 4.0166 discriminator Loss 0.0055\n","Epoch 91 generator Loss 4.0163 discriminator Loss 0.0055\n","Time taken for 1 epoch: 863.0027322769165 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 92 Batch 0 generator Loss 4.0163 discriminator Loss 0.0055\n","Epoch 92 Batch 593 generator Loss 4.0158 discriminator Loss 0.0054\n","Epoch 92 Batch 1186 generator Loss 4.0152 discriminator Loss 0.0054\n","Epoch 92 Batch 1779 generator Loss 4.0147 discriminator Loss 0.0054\n","Epoch 92 Batch 2372 generator Loss 4.0141 discriminator Loss 0.0054\n","Epoch 92 generator Loss 4.0139 discriminator Loss 0.0054\n","Time taken for 1 epoch: 866.1518640518188 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 93 Batch 0 generator Loss 4.0139 discriminator Loss 0.0054\n","Epoch 93 Batch 593 generator Loss 4.0134 discriminator Loss 0.0054\n","Epoch 93 Batch 1186 generator Loss 4.0128 discriminator Loss 0.0054\n","Epoch 93 Batch 1779 generator Loss 4.0123 discriminator Loss 0.0054\n","Epoch 93 Batch 2372 generator Loss 4.0117 discriminator Loss 0.0054\n","Epoch 93 generator Loss 4.0115 discriminator Loss 0.0054\n","Time taken for 1 epoch: 863.9571509361267 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 94 Batch 0 generator Loss 4.0115 discriminator Loss 0.0054\n","Epoch 94 Batch 593 generator Loss 4.0110 discriminator Loss 0.0054\n","Epoch 94 Batch 1186 generator Loss 4.0104 discriminator Loss 0.0054\n","Epoch 94 Batch 1779 generator Loss 4.0099 discriminator Loss 0.0054\n","Epoch 94 Batch 2372 generator Loss 4.0094 discriminator Loss 0.0054\n","Epoch 94 generator Loss 4.0091 discriminator Loss 0.0054\n","Time taken for 1 epoch: 866.1903586387634 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 95 Batch 0 generator Loss 4.0091 discriminator Loss 0.0054\n","Epoch 95 Batch 593 generator Loss 4.0086 discriminator Loss 0.0054\n","Epoch 95 Batch 1186 generator Loss 4.0081 discriminator Loss 0.0054\n","Epoch 95 Batch 1779 generator Loss 4.0075 discriminator Loss 0.0054\n","Epoch 95 Batch 2372 generator Loss 4.0070 discriminator Loss 0.0054\n","Saving checkpoint for epoch 95 at checkpoints\\ckpt-19\n","Epoch 95 generator Loss 4.0068 discriminator Loss 0.0054\n","Time taken for 1 epoch: 865.5463438034058 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 96 Batch 0 generator Loss 4.0068 discriminator Loss 0.0054\n","Epoch 96 Batch 593 generator Loss 4.0063 discriminator Loss 0.0054\n","Epoch 96 Batch 1186 generator Loss 4.0057 discriminator Loss 0.0054\n","Epoch 96 Batch 1779 generator Loss 4.0052 discriminator Loss 0.0054\n","Epoch 96 Batch 2372 generator Loss 4.0047 discriminator Loss 0.0054\n","Epoch 96 generator Loss 4.0045 discriminator Loss 0.0054\n","Time taken for 1 epoch: 865.5548408031464 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 97 Batch 0 generator Loss 4.0045 discriminator Loss 0.0054\n","Epoch 97 Batch 593 generator Loss 4.0040 discriminator Loss 0.0054\n","Epoch 97 Batch 1186 generator Loss 4.0035 discriminator Loss 0.0054\n","Epoch 97 Batch 1779 generator Loss 4.0029 discriminator Loss 0.0054\n","Epoch 97 Batch 2372 generator Loss 4.0024 discriminator Loss 0.0054\n","Epoch 97 generator Loss 4.0022 discriminator Loss 0.0054\n","Time taken for 1 epoch: 864.6892116069794 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 98 Batch 0 generator Loss 4.0022 discriminator Loss 0.0054\n","Epoch 98 Batch 593 generator Loss 4.0017 discriminator Loss 0.0054\n","Epoch 98 Batch 1186 generator Loss 4.0012 discriminator Loss 0.0053\n","Epoch 98 Batch 1779 generator Loss 4.0007 discriminator Loss 0.0053\n","Epoch 98 Batch 2372 generator Loss 4.0002 discriminator Loss 0.0053\n","Epoch 98 generator Loss 4.0000 discriminator Loss 0.0053\n","Time taken for 1 epoch: 865.0482807159424 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 99 Batch 0 generator Loss 4.0000 discriminator Loss 0.0053\n","Epoch 99 Batch 593 generator Loss 3.9995 discriminator Loss 0.0053\n","Epoch 99 Batch 1186 generator Loss 3.9990 discriminator Loss 0.0053\n","Epoch 99 Batch 1779 generator Loss 3.9985 discriminator Loss 0.0053\n","Epoch 99 Batch 2372 generator Loss 3.9980 discriminator Loss 0.0053\n","Epoch 99 generator Loss 3.9978 discriminator Loss 0.0053\n","Time taken for 1 epoch: 865.8709738254547 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 100 Batch 0 generator Loss 3.9978 discriminator Loss 0.0053\n","Epoch 100 Batch 593 generator Loss 3.9973 discriminator Loss 0.0053\n","Epoch 100 Batch 1186 generator Loss 3.9968 discriminator Loss 0.0053\n","Epoch 100 Batch 1779 generator Loss 3.9963 discriminator Loss 0.0053\n","Epoch 100 Batch 2372 generator Loss 3.9958 discriminator Loss 0.0053\n","Saving checkpoint for epoch 100 at checkpoints\\ckpt-20\n","Epoch 100 generator Loss 3.9956 discriminator Loss 0.0053\n","Time taken for 1 epoch: 866.1018273830414 secs\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\AppData\\Local\\Temp\\ipykernel_53832\\3551557269.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n","  report = report.append(row_to_add)\n"]}],"source":["training_Report = train(train_dataset, EPOCHS,training_Report)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bn7Ysz2BGXVm","outputId":"b7aa95c7-4a3c-4e38-dd7e-5b515135ac9c"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Epoch</th>\n","      <th>Time</th>\n","      <th>Generator_Loss</th>\n","      <th>Discriminator_Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>880.751694</td>\n","      <td>tf.Tensor(6.6429667, shape=(), dtype=float32)</td>\n","      <td>tf.Tensor(0.05097658, shape=(), dtype=float32)</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>861.41881</td>\n","      <td>tf.Tensor(5.884248, shape=(), dtype=float32)</td>\n","      <td>tf.Tensor(0.040350184, shape=(), dtype=float32)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>862.45771</td>\n","      <td>tf.Tensor(5.5072002, shape=(), dtype=float32)</td>\n","      <td>tf.Tensor(0.032122757, shape=(), dtype=float32)</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>861.404111</td>\n","      <td>tf.Tensor(5.275274, shape=(), dtype=float32)</td>\n","      <td>tf.Tensor(0.02695147, shape=(), dtype=float32)</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>862.355448</td>\n","      <td>tf.Tensor(5.116778, shape=(), dtype=float32)</td>\n","      <td>tf.Tensor(0.023360746, shape=(), dtype=float32)</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>96</td>\n","      <td>865.537837</td>\n","      <td>tf.Tensor(4.0044947, shape=(), dtype=float32)</td>\n","      <td>tf.Tensor(0.0053741145, shape=(), dtype=float32)</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>97</td>\n","      <td>864.669207</td>\n","      <td>tf.Tensor(4.00223, shape=(), dtype=float32)</td>\n","      <td>tf.Tensor(0.0053570457, shape=(), dtype=float32)</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>98</td>\n","      <td>865.030275</td>\n","      <td>tf.Tensor(3.9999886, shape=(), dtype=float32)</td>\n","      <td>tf.Tensor(0.005343776, shape=(), dtype=float32)</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>99</td>\n","      <td>865.84897</td>\n","      <td>tf.Tensor(3.9977763, shape=(), dtype=float32)</td>\n","      <td>tf.Tensor(0.0053263833, shape=(), dtype=float32)</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>100</td>\n","      <td>866.082823</td>\n","      <td>tf.Tensor(3.9955955, shape=(), dtype=float32)</td>\n","      <td>tf.Tensor(0.0053078183, shape=(), dtype=float32)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 4 columns</p>\n","</div>"],"text/plain":["   Epoch        Time                                 Generator_Loss  \\\n","0      1  880.751694  tf.Tensor(6.6429667, shape=(), dtype=float32)   \n","1      2   861.41881   tf.Tensor(5.884248, shape=(), dtype=float32)   \n","2      3   862.45771  tf.Tensor(5.5072002, shape=(), dtype=float32)   \n","3      4  861.404111   tf.Tensor(5.275274, shape=(), dtype=float32)   \n","4      5  862.355448   tf.Tensor(5.116778, shape=(), dtype=float32)   \n","..   ...         ...                                            ...   \n","95    96  865.537837  tf.Tensor(4.0044947, shape=(), dtype=float32)   \n","96    97  864.669207    tf.Tensor(4.00223, shape=(), dtype=float32)   \n","97    98  865.030275  tf.Tensor(3.9999886, shape=(), dtype=float32)   \n","98    99   865.84897  tf.Tensor(3.9977763, shape=(), dtype=float32)   \n","99   100  866.082823  tf.Tensor(3.9955955, shape=(), dtype=float32)   \n","\n","                                  Discriminator_Loss  \n","0     tf.Tensor(0.05097658, shape=(), dtype=float32)  \n","1    tf.Tensor(0.040350184, shape=(), dtype=float32)  \n","2    tf.Tensor(0.032122757, shape=(), dtype=float32)  \n","3     tf.Tensor(0.02695147, shape=(), dtype=float32)  \n","4    tf.Tensor(0.023360746, shape=(), dtype=float32)  \n","..                                               ...  \n","95  tf.Tensor(0.0053741145, shape=(), dtype=float32)  \n","96  tf.Tensor(0.0053570457, shape=(), dtype=float32)  \n","97   tf.Tensor(0.005343776, shape=(), dtype=float32)  \n","98  tf.Tensor(0.0053263833, shape=(), dtype=float32)  \n","99  tf.Tensor(0.0053078183, shape=(), dtype=float32)  \n","\n","[100 rows x 4 columns]"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["training_Report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l7MQ4eeUGXVm"},"outputs":[],"source":["#saving the cleaned Dataset as a CSV file\n","training_Report.to_csv(\"training_Report_for_100_epochs.csv\")"]},{"cell_type":"markdown","metadata":{"id":"gZCzkYO-GXVm"},"source":["## Plot Tranining Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PBoYVWBaGXVm"},"outputs":[],"source":["training_Report['Generator_Loss'] = training_Report['Generator_Loss'].apply(lambda x:float(x))\n","training_Report['Discriminator_Loss'] = training_Report['Discriminator_Loss'].apply(lambda x: float(x))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T_6ZHaoqGXVm","outputId":"58746aa5-413f-47a2-c42a-a35678fc4814"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Epoch</th>\n","      <th>Time</th>\n","      <th>Generator_Loss</th>\n","      <th>Discriminator_Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>880.751694</td>\n","      <td>6.642967</td>\n","      <td>0.050977</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>861.41881</td>\n","      <td>5.884248</td>\n","      <td>0.040350</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>862.45771</td>\n","      <td>5.507200</td>\n","      <td>0.032123</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>861.404111</td>\n","      <td>5.275274</td>\n","      <td>0.026951</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>862.355448</td>\n","      <td>5.116778</td>\n","      <td>0.023361</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>96</td>\n","      <td>865.537837</td>\n","      <td>4.004495</td>\n","      <td>0.005374</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>97</td>\n","      <td>864.669207</td>\n","      <td>4.002230</td>\n","      <td>0.005357</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>98</td>\n","      <td>865.030275</td>\n","      <td>3.999989</td>\n","      <td>0.005344</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>99</td>\n","      <td>865.84897</td>\n","      <td>3.997776</td>\n","      <td>0.005326</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>100</td>\n","      <td>866.082823</td>\n","      <td>3.995595</td>\n","      <td>0.005308</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 4 columns</p>\n","</div>"],"text/plain":["   Epoch        Time  Generator_Loss  Discriminator_Loss\n","0      1  880.751694        6.642967            0.050977\n","1      2   861.41881        5.884248            0.040350\n","2      3   862.45771        5.507200            0.032123\n","3      4  861.404111        5.275274            0.026951\n","4      5  862.355448        5.116778            0.023361\n","..   ...         ...             ...                 ...\n","95    96  865.537837        4.004495            0.005374\n","96    97  864.669207        4.002230            0.005357\n","97    98  865.030275        3.999989            0.005344\n","98    99   865.84897        3.997776            0.005326\n","99   100  866.082823        3.995595            0.005308\n","\n","[100 rows x 4 columns]"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["training_Report"]},{"cell_type":"markdown","metadata":{"id":"FkvXnaTTGXVm"},"source":["### Discriminator Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nxTxeaMrGXVm","outputId":"cbcf9049-358d-4f53-f25a-bd4482af8c74"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\anaconda3\\envs\\summarization_v2\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6982: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n","  return Index(sequences[0], name=names)\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 864x720 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# plot multiple columns such as population and year from dataframe\n","training_Report.plot(x=\"Epoch\", y=\"Discriminator_Loss\",\n","        kind=\"line\", figsize=(12, 10))\n"," \n","# display plot\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"RHrfsEKcGXVm"},"source":["### Generator Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KJ3KJb0vGXVn","outputId":"96aa9155-a4c6-4d8d-fe07-c7eebb9cb494"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\anaconda3\\envs\\summarization_v2\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6982: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n","  return Index(sequences[0], name=names)\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 864x720 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# plot multiple columns such as population and year from dataframe\n","training_Report.plot(x=\"Epoch\", y=\"Generator_Loss\",\n","        kind=\"line\", figsize=(12, 10))\n"," \n","# display plot\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"DFkVbfFbGXVn"},"source":["### Both Loss in one plot "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FOi7a67XGXVn","outputId":"5aab6184-e890-4ba3-c0d0-9df9f00d2268"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Thanveer\\anaconda3\\envs\\summarization_v2\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6982: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n","  return Index(sequences[0], name=names)\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 864x720 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n"," \n","# plot multiple columns such as population and year from dataframe\n","training_Report.plot(x=\"Epoch\", y=[\"Generator_Loss\", \"Discriminator_Loss\"],\n","        kind=\"line\", figsize=(12, 10))\n"," \n","# display plot\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["EiWya1nCOWOQ","GA4bp8QaOwnk","NhCmxtmiw-A1","ndUaHprIxTXt","v1kaVWWNzbD5","OckZxkZRzdd6","Hwi6J4_Jz7it","3qleZo790alE","KOSqCxJtPFsP","gG-RpvO_HwNw","db_KhInXHis4","ZVjC0-8SIUel","xrgAPieOPrUr","UXGF8mfRIw9Z","qqlQHWLPPwlD","nh2OPhippZAE","YW31T4uwpdDF","DPoVsJ7-QgeU","f7IJVB_RNAlc","TXV3-exjNpjO","lMi4A917Py_o","gZCzkYO-GXVm"],"name":"Transformer_and_GAN_based_Summarizer_Training.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}